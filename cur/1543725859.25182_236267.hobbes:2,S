Date: Mon, 26 Jul 2004 21:43:24 +1000
From: Nick Piggin <>
Subject: Re: OOM-killer going crazy.
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2004/7/26/52

Jan-Frode Myklebust wrote:
> On Mon, Jul 26, 2004 at 08:55:03PM +1000, Nick Piggin wrote:
> 
>>Can you just check you CONFIG_SWAP is on and /proc/sys/vm/laptop_mode is 0,
>>and that you have some swap enabled.
> 
> 
> # grep CONFIG_SWAP .config
> CONFIG_SWAP=y
> # cat /proc/sys/vm/laptop_mode
> 0
> # free
>              total       used       free     shared    buffers     cached
> Mem:       2074708    1223324     851384          0        296     258376
> -/+ buffers/cache:     964652    1110056
> Swap:      2040244          0    2040244
> 
Good. Just making sure.
> 
> 
>>If the problem persists, can you send a copy each of 
>>/proc/sys/fs/dentry-state,
>>/proc/slabinfo and /proc/vmstat before and after you run dsmc until it goes
>>OOM please?
> 
> 
> I turned of a option (MEMORYEFFICIENTBACKUP) in 'dsmc', and then it uses a bit 
> more memory, and crashes quicker.
> 
Thanks. Let's see.
dentry-state before
> 644923  572300  45      0       0       0
after
 > 570734  495922  45      0       0       0
slabinfo before
> # name            <active_objs> <num_objs> <objsize> <objperslab> <pagesperslab> : tunables <batchcount> <limit> <sharedfactor> : slabdata <active_slabs> <num_slabs> <sharedavail>
> xfs_inode         927591 980848    368   11    1 : tunables   54   27    8 : slabdata  89168  89168      0
> linvfs_icache     927591 980810    384   10    1 : tunables   54   27    8 : slabdata  98081  98081      0
> dentry_cache      645063 703566    144   27    1 : tunables  120   60    8 : slabdata  26058  26058      0
after
 > xfs_inode         828633 980507    368   11    1 : tunables   54   27    8 : slabdata  89137  89137    216
 > linvfs_icache     828629 980220    384   10    1 : tunables   54   27    8 : slabdata  98022  98022    216
 > dentry_cache      571383 703458    144   27    1 : tunables  120   60    8 : slabdata  26054  26054    480
So you're basically drowning in mostly reclaimable slab here. These three entries
are consuming over 800MB of zone_normal alone.
vmstat before
> pginodesteal 36508
> slabs_scanned 56099472
> kswapd_inodesteal 317433
after
> pginodesteal 36536
> slabs_scanned 56443602
> kswapd_inodesteal 317433
The things are being slowly scanned and freed, but it is being pretty lethargic.
Can you try echo 10000 > /proc/sys/vm/vfs_cache_pressure, and see how that goes?
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/