Date: Tue, 31 Oct 2006 22:10:39 -0500
From: "Holden Karau" <>
Subject: Re: [PATCH 1/1] fat: improve sync performance by grouping writes revised
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2006/10/31/422

I was thinking about the issue of running out of memory, while its not
particularly likely to happen except on devices with huge disks and
tiney amount of memory, it is a possibility. I can make it
fall-through to the previous way of doing things, does that sound like
a reasonable idea?
On 10/31/06, Holden Karau <holden@pigscanfly.ca> wrote:
> On 10/31/06, Matthew Wilcox <matthew@wil.cx> wrote:
> > On Tue, Oct 31, 2006 at 10:03:08AM -0500, Holden Karau wrote:
> > > @@ -343,52 +344,65 @@ int fat_ent_read(struct inode *inode, st
> > >       return ops->ent_get(fatent);
> > >  }
> > >
> > > -/* FIXME: We can write the blocks as more big chunk. */
> > > -static int fat_mirror_bhs(struct super_block *sb, struct buffer_head **bhs,
> > > -                       int nr_bhs)
> > > +
> > > +static int fat_mirror_bhs_optw(struct super_block *sb, struct buffer_head **bhs,
> > > +                            int nr_bhs , int wait)
> > >  {
> > >       struct msdos_sb_info *sbi = MSDOS_SB(sb);
> > > -     struct buffer_head *c_bh;
> > > +     struct buffer_head *c_bh[nr_bhs*(sbi->fats)];
> > >       int err, n, copy;
> > >
> > > +     /* Always wait if mounted -o sync */
> > > +     if (sb->s_flags & MS_SYNCHRONOUS )
> > > +             wait = 1;
> > >       err = 0;
> > >       for (copy = 1; copy < sbi->fats; copy++) {
> > >               sector_t backup_fat = sbi->fat_length * copy;
> > > -
> > > -             for (n = 0; n < nr_bhs; n++) {
> > > -                     c_bh = sb_getblk(sb, backup_fat + bhs[n]->b_blocknr);
> > > -                     if (!c_bh) {
> > > +             for (n = 0 ; n < nr_bhs ;  n++ ) {
> > > +                     c_bh[(copy-1)*nr_bhs+n] = sb_getblk(sb, backup_fat + bhs[n]->b_blocknr);
> > > +                     if (!c_bh[(copy-1)*nr_bhs+n]) {
> > > +                             printk(KERN_CRIT "fat: out of memory while copying backup fat. possible data loss\n");
> >
> > I don't like that at all.
> Not much to be done about that. The amount of memory required is
> fairly small, but if its not there its not there.
> >
> > >                               err = -ENOMEM;
> > >                               goto error;
> > >                       }
> > > -                     memcpy(c_bh->b_data, bhs[n]->b_data, sb->s_blocksize);
> > > -                     set_buffer_uptodate(c_bh);
> > > -                     mark_buffer_dirty(c_bh);
> > > -                     if (sb->s_flags & MS_SYNCHRONOUS)
> > > -                             err = sync_dirty_buffer(c_bh);
> > > -                     brelse(c_bh);
> > > -                     if (err)
> > > -                             goto error;
> > > +             memcpy(c_bh[(copy-1)*nr_bhs+n]->b_data, bhs[n]->b_data, sb->s_blocksize);
> > > +             set_buffer_uptodate(c_bh[(copy-1)*nr_bhs+n]);
> > > +             mark_buffer_dirty(c_bh[(copy-1)*nr_bhs+n]);
> > >               }
> > >       }
> > > +
> > > +     if (wait) {
> > > +             for (n = 0 ; n < nr_bhs ; n++) {
> > > +                     printk("copying to %d to  %d\n" ,n,  nr_bhs*(sbi->fats-1)+n);
> >
> > Is this the right version of the patch?  The printk should never be left in.
> > Plus, as far as I can tell, that whole loop is actually just memcpy().
> whoops. That was in for debugging, I thought I took that out. The loop
> structure is how it was before, but I don't see a way to get rid of
> it, do you have an idea?
> >
>
>
> --
> Cell: 613-276-1645
>
-- 
Cell: 613-276-1645
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/