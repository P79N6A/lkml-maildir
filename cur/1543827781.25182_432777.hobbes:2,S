Date: Tue, 13 Jun 2006 18:03:35 -0700 (PDT)
From: Christoph Lameter <>
Subject: [PATCH 11/21] swap_prefetch: Conversion of nr_slab to ZVC
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2006/6/13/323

swap_prefetch: Use NR_SLAB
This removes a potential problem for swap_prefetch. Use NR_SLAB
and remove the comment stating the problem.
Signed-off-by: Christoph Lameter <clameter@sgi.com>
Index: linux-2.6.17-rc6-cl/mm/swap_prefetch.c
===================================================================
--- linux-2.6.17-rc6-cl.orig/mm/swap_prefetch.c	2006-06-12 11:30:59.995187077 -0700
+++ linux-2.6.17-rc6-cl/mm/swap_prefetch.c	2006-06-12 11:55:06.458392224 -0700
@@ -389,14 +389,11 @@ static int prefetch_suitable(void)
 		/*
 		 * >2/3 of the ram on this node is mapped, slab, swapcache or
 		 * dirty, we need to leave some free for pagecache.
-		 * Note that currently nr_slab is innacurate on numa because
-		 * nr_slab is incremented on the node doing the accounting
-		 * even if the slab is being allocated on a remote node. This
-		 * would be expensive to fix and not of great significance.
 		 */
 		limit = node_page_state(node, NR_MAPPED) +
 			node_page_state(node, NR_ANON) +
-			ps.nr_slab + ps.nr_dirty +
+			node_page_state(node, NR_SLAB) +
+			ps.nr_dirty +
 			ps.nr_unstable + total_swapcache_pages;
 		if (limit > ns->prefetch_watermark) {
 			node_clear(node, sp_stat.prefetch_nodes);
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/