Date: Thu, 21 Nov 2002 11:23:04 -0500
From: "Robert L. Harris" <>
Subject: MD Raid+devfs?
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2002/11/21/95

Situation:
Built a filesystem, raid5 on a server running devfs with:
/dev/sdb2
/dev/sdc2
/dev/sde2
/dev/sdf2
/dev/sdd2 was out for RMA.  
Devfs remapped the drives at boot time as b-d.  I just had an
unscheduled downtime, unrelated to this, and took the opportunity to
re-install the drive.
Luckily as raid 5 it came back up because it remapped them b-f again
stickingm y disk in sdd.  This pushed the 4th disk back one spot too
many and out of the array, stuck an unformatted disk in the middle.
Figured it was going to completely trash my filesystem since the 3rd
disk was 4th and 4th was gone, but it recovered nicely (nice work MD
guys).
At any rate though I'm looking and wondering how bad it would be to put
in scsi/host0/bus0/target0/lun0/part2 instead of sdb2 for example.
Thoughts, theories, the "best practice" way to do this with devfs?
Robert
:wq!
---------------------------------------------------------------------------
Robert L. Harris                     | PGP Key ID: FC96D405
                               
DISCLAIMER:
      These are MY OPINIONS ALONE.  I speak for no-one else.
FYI:
 perl -e 'print $i=pack(c5,(41*2),sqrt(7056),(unpack(c,H)-2),oct(115),10);'
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/