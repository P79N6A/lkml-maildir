Date: Mon, 10 Nov 2008 22:18:19 -0500 (EST)
From: Steven Rostedt <>
Subject: Re: [PATCH 1/2] ftrace: disable tracing on resize
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/11/10/398

Pekka,
I forgot to add you to the Cc list. Could you test this patch to see if it 
fixes the bug you reported. It fixed a bug I was able to reproduce, but I 
was never able to reproduce the exact same bug you have seen.
-- Steve
On Mon, 10 Nov 2008, Steven Rostedt wrote:
> Impact: fix for bug on resize
> 
> This patch addresses the bug found here:
> 
> 
http://bugzilla.kernel.org/show_bug.cgi?id=11996
> 
> When ftrace converted to the new unified trace buffer, the resizing of
> the buffer was not protected as much as it was originally. If tracing
> is performed while the resize occurs, then the buffer can be corrupted.
> 
> This patch disables all ftrace buffer modifications before a resize
> takes place.
> 
> Signed-off-by: Steven Rostedt <srostedt@redhat.com>
> ---
>  kernel/trace/trace.c |   17 ++++++++++++++++-
>  1 files changed, 16 insertions(+), 1 deletions(-)
> 
> diff --git a/kernel/trace/trace.c b/kernel/trace/trace.c
> index 9f3b478..abfa810 100644
> --- a/kernel/trace/trace.c
> +++ b/kernel/trace/trace.c
> @@ -2676,7 +2676,7 @@ tracing_entries_write(struct file *filp, const char __user *ubuf,
>  {
>  	unsigned long val;
>  	char buf[64];
> -	int ret;
> +	int ret, cpu;
>  	struct trace_array *tr = filp->private_data;
> 
>  	if (cnt >= sizeof(buf))
> @@ -2704,6 +2704,14 @@ tracing_entries_write(struct file *filp, const char __user *ubuf,
>  		goto out;
>  	}
> 
> +	/* disable all cpu buffers */
> +	for_each_tracing_cpu(cpu) {
> +		if (global_trace.data[cpu])
> +			atomic_inc(&global_trace.data[cpu]->disabled);
> +		if (max_tr.data[cpu])
> +			atomic_inc(&max_tr.data[cpu]->disabled);
> +	}
> +
>  	if (val != global_trace.entries) {
>  		ret = ring_buffer_resize(global_trace.buffer, val);
>  		if (ret < 0) {
> @@ -2735,6 +2743,13 @@ tracing_entries_write(struct file *filp, const char __user *ubuf,
>  	if (tracing_disabled)
>  		cnt = -ENOMEM;
>   out:
> +	for_each_tracing_cpu(cpu) {
> +		if (global_trace.data[cpu])
> +			atomic_dec(&global_trace.data[cpu]->disabled);
> +		if (max_tr.data[cpu])
> +			atomic_dec(&max_tr.data[cpu]->disabled);
> +	}
> +
>  	max_tr.entries = global_trace.entries;
>  	mutex_unlock(&trace_types_lock);
> 
> -- 
> 1.5.6.5
> 
> -- 
> 
> 