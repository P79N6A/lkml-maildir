Date: Fri, 10 Feb 2006 11:56:08 +1100
From: Con Kolivas <>
Subject: Re: [PATCH] mm: Implement Swap Prefetching v22
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2006/2/9/303

On Friday 10 February 2006 11:51, KAMEZAWA Hiroyuki wrote:
> Hi,
>
> Con Kolivas wrote:
> > +void add_to_swapped_list(struct page *page)
> > +{
> > +	struct swapped_entry *entry;
> > +	unsigned long index;
> > +
> > +	spin_lock(&swapped.lock);
> > +	if (swapped.count >= swapped.maxcount) {
>
> Assume x86 system with 8G memory, swapped_maxcount is maybe 5G+ here.
> Then, swapped_entry can consume 5G/PAGE_SIZE * 16bytes = 10 M byte more
> slabs from ZONE_NORMAL. Could you add check like this?
> ==
> void add_to_swapped_list(struct page *page)
> {
> 	<snip>
> 	if (!swap_prefetch)
> 		return;
> 	spin_lcok(&spwapped.lock);
> }
> ==
Sure why not. It made testing easier to not stop adding entries to the swapped 
list when it was disabled, but for release your idea makes sense. Thanks for 
the suggestion.
Cheers,
Con
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/