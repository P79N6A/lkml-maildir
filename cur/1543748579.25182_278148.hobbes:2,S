Date: Fri, 10 Dec 2004 17:27:22 -0600
From: Robin Holt <>
Subject: Re: [RFC] Limit the size of the IPV4 route hash.
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2004/12/10/176

On Fri, Dec 10, 2004 at 01:09:47PM -0800, Andrew Morton wrote:
> Robin Holt <holt@sgi.com> wrote:
> >  Can we agree that a linear calculation based on num_physpages is probably
> >  not the best algorithm.  If so, should we make it a linear to a limit or
> >  a logarithmically decreasing size to a limit?  How do we determine that
> >  limit point?
> 
> An initial default of N + M * log2(num_physpages) would probably give a
> saner result.
> 
> The big risk is that someone has a too-small table for some specific
> application and their machine runs more slowly than it should, but they
> never notice.  I wonder if it would be possible to put a little once-only
> printk into the routing code: "warning route-cache chain exceeded 100
> entries: consider using the rhash_entries boot option".
Since the hash gets flushed every 10 seconds, what if we kept track of
the maximum depth reached and when we reach a certain threshold, just
allocate a larger hash and replace the old with the new.  I do like the
printk idea so the admin can prevent inconsistent performance early in
the run cycle for the system.  We could even scale the hash size up based
upon demand.
Thanks,
Robin
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/