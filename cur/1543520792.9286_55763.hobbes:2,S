Date: Fri, 31 Dec 1999 00:55:29 +0100
From: Manfred Spraul <>
Subject: Re: spin_unlock optimization
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/12/30/131

Steve Dodd wrote:
> 
> On Thu, Dec 30, 1999 at 04:06:04AM +0100, Oliver Henning wrote:
> 
> > well, not necessarily. If you would modify the spin_unlock asm sequence at
> > boot time, there would be no performance loss. But self-modifying code is
> > not very desirable, so...
> 
> Erm, spin_unlock is inlined isn't it? So that won't work unless you want to
> grep for the code sequence all over the kernel and modules;
Lets ignore the modules, start with the main kernel. What about the
following idea:
* by default, "lock;btrl %0" is used.
* a new section for "self-modifying code pointer". The table could be
discarded after boot.
* each spin_unlock-macro adds an entry to the that section.
spin_unlock():
__asm__ __volatile__(
	"1: lock; btrl %0"
	".section .text.selfmodtable,ax"
	".long &1" <<<<<<< pseudo code, but that should be possible
	".previous"
	...);
During early init, we walk through the .text.selfmodtable pointer table
and exchange all instructions with the optimal version. The only
limitation is that we cannot change the instruction length.
> also, the binary
> module people would be forced to brutally murder you :-)
> 
Why? Their .text.selfmodtable section would be empty, i.e. no problems.
--
	Manfred
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/