Date: Wed, 23 Jan 2008 13:04:46 +0100
From: Andrea Arcangeli <>
Subject: Re: [kvm-devel] [PATCH] export notifier #1
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/1/23/90

On Wed, Jan 23, 2008 at 04:52:47AM -0600, Robin Holt wrote:
> But 100 callouts holding spinlocks will not work for our implementation
> and even if the callouts are made with spinlocks released, we would very
> strongly prefer a single callout which messages the range to the other
> side.
But you take the physical address and turn into mm+va with your rmap...
> > Also, our rmap key for finding the spte is keyed on (mm, va).  I imagine
> > most RDMA cards are similar.
> 
> For our RDMA rmap, it is based upon physical address.
so why do you turn it into mm+va?
> >> There is only the need to walk twice for pages that are marked Exported.
> >> And the double walk is only necessary if the exporter does not have its
> >> own rmap. The cross partition thing that we are doing has such an rmap and
> >> its a matter of walking the exporters rmap to clear out the external
> >> references and then we walk the local rmaps. All once.
> >>
> >
> > The problem is that external mmus need a reverse mapping structure to
> > locate their ptes.  We can't expand struct page so we need to base it on mm
> > + va.
> 
> Our rmap takes a physical address and turns it into mm+va.
Why don't you stick to mm+va and use get_user_pages and let the VM do
the swapins etc...?
> > Can they wait on that bit?
> 
> PageLocked(page) should work, right?  We already have a backoff
> mechanism so we expect to be able to adapt it to include a
> PageLocked(page) check.
It's not PageLocked but wait_on_page___not___exported() called on the
master node. Plus nothing in the VM of the master node calls
SetPageExported... good luck to make it work (KVM swapping OTOH works
like a charm already w/o the backwards secondary-TLB-flushing order).