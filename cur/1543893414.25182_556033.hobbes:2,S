Date: Mon, 11 Jun 2007 11:32:33 -0700 (PDT)
From: Christoph Lameter <>
Subject: Re: kernel BUG at mm/slub.c:3689!
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2007/6/11/211

On Mon, 11 Jun 2007, HÃ¥vard Skinnemoen wrote:
> > Note that I do not get why you would be aligning the objects to 32 bytes.
> > Increasing the smallest cache size wastes a lot of memory. And it is
> > usually advantageous if multiple related objects are in the same cacheline
> > unless you have heavy SMP contention.
> 
> It's not about performance at all, it's about DMA buffers allocated
> using kmalloc() getting corrupted. Imagine this:
Uhhh... How about using a separate slab for the DMA buffers?
> Maybe there are other solutions to this problem, but the old SLAB
> allocator did guarantee 32-byte alignment as long as SLAB debugging
> was turned off, so setting ARCH_KMALLOC_MINALIGN seemed like the
> easiest way to get back to the old, known-working behaviour.
SLABs mininum object size is 32 thus you had no problems. I see. SLAB 
does not guarantee 32 byte alignment. It just happened to work. If you 
switch on CONFIG_SLAB_DEBUG you will likely get into trouble.
So I'd suggest to set up a special slab for your DMA buffers.