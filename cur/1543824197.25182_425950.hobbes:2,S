Date: 22 May 2006 13:12:54 +0200
From: Andi Kleen <>
Subject: Re: FW: cmpxchg hard lockup on AMD64 - ASUS(A8V-MX)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2006/5/22/90

"chaitanya Huilgol" <chaitanya@tidaldata.com> writes:
> {
>         __asm__ __volatile__ (
>                 "# LFPUSH \n\t"
>                 "1:\t"
>                 "movl %2, (%1) \n"
>                 LOCK "cmpxchg %1, %0 \n\t"
>                 "jnz 1b \n\t"
>                 :
>                 :"m" (*lf), "r" (cl), "a" (lf->top)
You don't tell gcc *lf is modified.
>                 );
> }
> 
> cell* pop (lifo * lf)
> {
>         cell* v=0;
>         __asm__ __volatile__ (
>                 "# LFPOP \n\t"
>                 "testl %%eax, %%eax \n\t"
>                 "jz 20f \n"
>                 "10:\t"
>                 "movl (%%eax), %%ebx \n\t"
>                 "movl %%edx, %%ecx \n\t"
>                 "incl %%ecx \n\t"
Nothing uses the incremented %ecx
>                 LOCK "cmpxchg8b %1 \n\t"
>                 "jz 20f \n\t"
>                 "testl %%eax, %%eax \n\t"
>                 "jnz 10b \n"
>                 "20:\t"
>                 :"=a" (v)
>                 :"m" (*lf),
And you don't tell *lf is modified again.
It could be just a miscompilation caused by your wrong asm constraints.
-Andi
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/