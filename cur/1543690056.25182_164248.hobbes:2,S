Date: Mon, 08 Sep 2003 20:34:15 -0400
From: Timothy Miller <>
Subject: Re: Use of AI for process scheduling
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2003/9/8/311

David Lang wrote:
> 
> the scheduler is by definition a real-time entity, if it takes twice as
> long to make a decision that in itself alters what the correct decision
> should be.
> 
My idea is to have the AI work in real-time just like the expert system 
would.  And I realize that this alters the situation, but it alters the 
situation in a constant way.  For a given number of context switches, 
the same number of scheduling decisions will be made.  That means that 
if the scheduler takes 100 times as long to decide, then all it will do 
is affect both the throughput and the latency in a constant way.
The only time it really matters is when the scheduler decision time 
makes something which would APPEAR to be interactive in the compiled 
case appear to be non-interactive in the AI case.  But that is no 
different from using a slower CPU.  There are LOTS of things that will 
feel smoother on a faster CPU.
So, if we can get a good interactive feel out of the AI case, then you 
will only get better results out of the compiled case.  Furthermore, 
good interactive results out of a fast CPU with the AI would imply good 
results out of a slower CPU in the compiled case.
I do realize that the balance is shifted.  The proportion of scheduler 
computation to user computation is thrown off.  (Still, same as using a 
slower CPU.)  But I don't think it matters.  If the scheduler were 100 
times slower, it would still require far far less than timeslice 
granularity to compute!
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/