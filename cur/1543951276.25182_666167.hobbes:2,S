Date: Tue, 11 Mar 2008 20:41:09 +1100
From: Nick Piggin <>
Subject: Re: [RFC PATCH] Implement slub fastpath with sequence number
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/3/11/115

On Tuesday 11 March 2008 20:31, Mathieu Desnoyers wrote:
> Here is a new version that works. tested on x86. tweaked the bitmasks
> into unions to remove operations from the critical path, but I tried to
> keep that clean. It applies on vm.git HEAD.
>
> It allows the cmpxchg_local to detect object re-use by keeping a counter in
> the freeoffset MSBs.
>
> Whenever an object is freed in the cpu slab cache, the counter is
> incremented. Whenever the alloc/free slow paths are modifying the offset or
> freebase, the sequence counter is also incremented. It is used to make sure
> we know if freebase has been modified in an interrupt nested over the fast
> path.
Wow. I applaud the effort to micro optimise things ;)
But I hope this doesn't get merged until macro-regressions in SLUB
are verified to be fixed. It's pretty clear that SLUB's problem is
not fastpath performance, so I think this would be premature
optimisation.