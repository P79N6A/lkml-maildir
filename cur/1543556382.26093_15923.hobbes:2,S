Date: 2 Dec 2000 23:19:39 -0800
From: "H. Peter Anvin" <>
Subject: Re: /dev/random probs in 2.4test(12-pre3)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/12/3/10

Followup to:  <Pine.LNX.4.21.0012022233440.11907-100000@server.serve.me.nl>
By author:    Igmar Palsenberg <maillist@chello.nl>
In newsgroup: linux.dev.kernel
> 
> Hmm.. Some came to mind :
> 
> Making /dev/random block if the amount requirements aren't met makes sense
> to me. If I request x bytes of random stuff, and get less, I probably
> reread /dev/random. If it's entropy pool is exhausted it makes sense to be
> to block.
> 
Yes, it does, but it doesn't make any sense to block if there are data
to be read.  If you need a larger read then you should advance your
pointer and try again with the residual size, or use fread() which
does this for you.
	-hpa
-- 
<hpa@transmeta.com> at work, <hpa@zytor.com> in private!
"Unix gives you enough rope to shoot yourself in the foot."
http://www.zytor.com/~hpa/puzzle.txt
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
Please read the FAQ at 
http://www.tux.org/lkml/