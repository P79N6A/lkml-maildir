Date: Thu, 15 Jan 2009 12:53:37 -0600
From: Jayson King <>
Subject: Re: Performance regression of specjbb2005/aim7 with 2.6.29-rc1
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2009/1/15/384

Peter Zijlstra wrote:
> On Thu, 2009-01-15 at 10:30 +0800, Lin Ming wrote:
> 
>> Below patch fixes aim7 regression and specjbb2005 regression becomes
>> less than 1.5% on 8-core stokley.
> 
> Ingo, please apply the below.
> 
> Ming, would you also provide a S-o-b line?
> 
> ---
> Subject: sched_slice fixlet
> From: Lin Ming <ming.m.lin@intel.com>
> Date: Thu Jan 15 17:10:02 CET 2009
> 
> Mike's change: 0a582440f -- sched: fix sched_slice())
> Broke group scheduling by forgetting to reload cfs_rq on each loop.
> 
> Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
> ---
>  kernel/sched_fair.c |    5 ++++-
>  1 file changed, 4 insertions(+), 1 deletion(-)
> 
> Index: linux-2.6/kernel/sched_fair.c
> ===================================================================
> --- linux-2.6.orig/kernel/sched_fair.c
> +++ linux-2.6/kernel/sched_fair.c
> @@ -429,7 +429,10 @@ static u64 sched_slice(struct cfs_rq *cf
>  	u64 slice = __sched_period(cfs_rq->nr_running + !se->on_rq);
> 
>  	for_each_sched_entity(se) {
> -		struct load_weight *load = &cfs_rq->load;
> +		struct load_weight *load;
> +
> +		cfs_rq = cfs_rq_of(se);
> +		load = &cfs_rq->load;
> 
>  		if (unlikely(!se->on_rq)) {
>  			struct load_weight lw = cfs_rq->load;
> 
> 
> 
That still works for me. You may add:
Tested-by: Jayson King <dev@jaysonking.com>