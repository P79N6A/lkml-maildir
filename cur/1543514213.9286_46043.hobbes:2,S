Date: Tue, 26 Oct 1999 17:35:35 -0500
From: Shawn Leas <>
Subject: RE: Question on FFS support
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/10/26/158

There was a NetApp dud here at the Oracle User's Group pitching there
solutions. I asked regarding white papers on their underlying OS as well as
their FS, and they said they would email me some links, but never did...
They had some interesting features such as snapshots, which basically
preserves FS metadata at some point in time, and given the FS is a log
structured one, the blocks pointed to by the old metadata never gets
overwritten.
This thread has given me some insight into their stuff. Thanks dudes!
-Shawn
-----Original Message-----
From: Theodore Y. Ts'o [mailto:tytso@mit.edu]
Sent: Tuesday, October 26, 1999 5:06 PM
To: Brian Grayson
Cc: Anthony Barbachan; Alexander Viro; linux-kernel@vger.rutgers.edu
Subject: Re: Question on FFS support
   Date:   Tue, 26 Oct 1999 15:24:25 -0500
   From: Brian Grayson <bgrayson@ibmoto.com>
     I don't know, but the original FreeBSD responder may have meant
   LFS, the log-structured filesystem, which the BSDs have
   recently revamped.  It is a true journaling file system distinct
   from FFS/UFS, and not merely soft-updates on top of a
   traditional block-structured file system.  With LFS, you always
   append on writes, rather than overwrite.  Thus, writes are
   fast, and if the machine crashes, since the previous data has
   not been overwritten, you can recover quite quickly.  Of
   course, with finite disks you need to do some
   garbage-collecting, but LFS does all of that for you, and also
   has some optimizations so that reads are still fast.
The latter has been the traditional failing of LFS filesystems over
update-in-place filesystems (i.e., FFS, and ext2) --- because you never
write over an existing disk block, files and directories tend to get
scattered all over the disk.  There are ways things can be improved
(intelligent log cleaners, and huge amounts of memory to cache data so
you don't have to go disk for reads in the first place), but it's very
difficult to make a log structured filesystem work as well as an
update-in-place filesystem.  
There is a fairly widely held belief that LFS systems don't work well on
smaller systems --- especially ones without a lot of memory --- because
of the huge amounts of cache needed to make things reasonably fast.  And
there will be certain application access patterns which will be quite
pessimal for LFS.  There are systems where LFS works quite well, though.
NetApp boxes use a log structured filesystem, for example.  They've
spent a lot of effort, using both hardware and software techniques, to
make their boxes go *fast*.
						- Ted
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/