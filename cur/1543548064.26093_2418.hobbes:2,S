Date: Thu, 7 Sep 2000 19:24:13 +0200
From: Jamie Lokier <>
Subject: Re: spin_lock forgets to clobber memory and other smp fixes [was
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/9/7/147

Andrea Arcangeli wrote:
> >Well, now GCC does CSE across "asm" and will eliminate memory loads,
> 
> What is "CSE"?
Common Subexpression Elimination.
If the compiler sees an expression equivalent to one it evaluated
earlier, there is no need to evaluate it a second time.
So "a = x+x; b = x+x" will evaluate "x+x" just once and store it twice.
This applies to memory reads too.  If you read from memory once, and
read it again later, the later read can be eliminated.  You have the
right value in a register already.
Memory CSE depends on proving that no intermediate operation clobbers
the data at that address.  That is why "memory" clobbers are important.
They indicate that the data at that address _may_ have been clobbered,
so it must be read again after the clobbering operation.
Sometimes, after you've forced the second read, you can eliminate the
first one :-) That's why "memory" appears to just move the read in our
test case.  It's really forcing a read after the "asm", which in turn
allows the read before the "asm" to be eliminated.
In more complicated cases, where the result of the first read is
actually used before the "asm", the "memory" clobber causes the second
read to occur as well as the first.
-- Jamie
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
Please read the FAQ at 
http://www.tux.org/lkml/