Date: Tue, 20 Jul 1999 17:52:10 +0100 (BST)
From: "Stephen C. Tweedie" <>
Subject: Re: OOM
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/7/20/95

Hi,
On Tue, 20 Jul 1999 07:58:20 -0700 (PDT), Claus Fischer
<claus.fischer@intel.com> said:
> On Tue, 20 Jul 1999, Stephen C. Tweedie wrote:
>   [good explanation of VMS behaviour]
> Does the "working set" specify the pages in physical RAM or the
> pages of total virtual memory (RAM + swap) used?
Neither.  Like I said, it is the total number of resident (in RAM) pages
which are directly mapped into the process's page tables.  If you
overflow that, the surplus pages get swapped out, but they can still
stay in physical memory if there is enough memory to cache that extra
swap.  
As long as the cached memory is not needed for anything else, the
process can get the pages back by taking a soft page fault which just
reattaches the physical memory to the page tables.  However, the cache
memory can be reclaimed rapidly by the OS if it needs it for something
else (much more rapidly than it can reclaim pages which are still
directly referenced by process page tables).
> (My 'typical' OOM situation is one where all virtual memory is full,
> i.e. paging out to the swap partitions cannot help since they are
> full.)
In that case, killing tasks is the only way forward.  That's really an
orthogonal issue (although an important one).  Btw, there was a nasty
bug in the out-of-VM code fixed recently: with large swap files we could
miscalculate the amount of free swap and get into knots trying to
allocate unavailable swap pages.
--Stephen
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/