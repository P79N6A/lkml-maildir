Date: Fri, 5 Apr 2002 22:37:29 +0200
From: Dieter Nützel <>
Subject: Re: some more nifty benchmarks
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2002/4/5/180

On Freitag, 5. April 2002 :22, Ed Sweetman wrote:
> On Thu, 2002-04-04 at 22:49, Dieter Nützel wrote:
> > On Tuesday, March 2002-04-02 17:15:40, Ed Sweetman wrote:
[-]
> > Yep, FOUND it.
> > Ingo`s latest sched-O1-2.4.18-pre8-K3 is the culprit!!!
> > Even with -ac (2.4.19-pre2-ac2) and together with -aa (latest here is
> > 2.4.18-pre8-K3-VM-24-preempt-lock).
> >
> > Below are the number for 2.4.18+sched-O1-2.4.18-pre8-K3.
> > Have a look into the attachment, too.
> >
> > Hopefully you or Ingo will find something out.
>
> I seem to have lost your earlier emails.  Did you get a max latency of
> around <2 before this 0(1) scheduler patch?
In short:
YES with 2.4 and with preemption+lock-break
I repeated it for 2.4.19-pre5+vm33. See results below.
It is NOT in any case an -aa VM or preemption+lock-break bug.
Ingo's latest sched-O1-2.4.18-pre8-K3.patch for 2.4 is the culprit. So all 
latest -ac kernels are broken in this sense, too.
> 2.2 with low latency patch gets that.  2.4 with low latency patch is many
> many times worse.  The high latency areas of the kernel are already known.
I know :-)
Bad we badly need a newer lock-break for 2.4 from Robert (sorry Andrew :-).
I will do some "stats data collection" with my next boot.
>  It's just a matter of deciding how to deal with them that's the problem.
> It seems that it might be a general consensus that it can't be dealt with
> in 2.4 mainstream.
No I think it is not.
If we can eliminate the remaining bugs from O(1) and use preemption everything 
should be smooth.
> As you've implied before though,  the scheduler is much more important
> than latency is to the average user.
The O(1)-scheduler is great but broken (latency wise) in the current 2.4 
version. Have anyone of you some older versions from Ingo around?
> As most people would know from
> 2.2, audio would skip unless it was running -20 nice and the highest
> priority etc.  With 2.4's scheduler and preempt, well you dont have to
> worry about skips and you can leave the player at a normal nice and
> priority value.
That's not true with the O(1)-scheduler.
In most of my tests (Ingo got my results) you have to renice the audio daemon 
to something like -16 (first "real time" class) and X to -10 (for good 
interactivity) during "heavy" background stuff (40 gcc and 40 g++ processes 
reniced +19 for example). This load resulting in ~350 processes, 80~85 
running in parallel and sound playing on my "old" 1 GHz Athlon II with 640 
MB...;-)
But that's not so good for the "normal" user. We need some "auto renicing".
BTW My former 2.4.17/2.4.18-pre numbers were much better for throughput and 
somewhat for latency.
I used Andrea's -aa VM and Robert's preemption and lock-break on ReiserFS all 
the time. But together with bootmem-2.4.17-pre6 and waitq-2.4.17-mainline-1.
Anyone know where I can get newer versions of them?
Best dbench 32 numbers were:
Throughput:	~55 MB/sec
real			~1:15
Last one:
Were is Ingo? --- I hope he is fine!
Regards,
	Dieter
2.4.19-pre5-vm33
32 clients started
..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................+..............+......................+........+...................................................................................................................+..+...........++.+....+++..+++++.+++++++..++++++++********************************
Throughput 40.4878 MB/sec (NB=50.6098 MB/sec  404.878 MBit/sec)
14.440u 50.650s 1:45.35 61.7%   0+0k 0+0io 939pf+0w
SunWave1 dbench/latencytest0.42-png# time ./do_tests none 3 256 0 350000000
x11perf - X11 performance program, version 1.5
The XFree86 Project, Inc server version 40200000 on :0.0
from SunWave1
Fri Apr  5 20:06:34 2002
Sync time adjustment is 0.2107 msecs.
   3000 reps @   2.2644 msec (   442.0/sec): Scroll 500x500 pixels
   3000 reps @   2.2663 msec (   441.0/sec): Scroll 500x500 pixels
   3000 reps @   2.2635 msec (   442.0/sec): Scroll 500x500 pixels
   3000 reps @   2.2654 msec (   441.0/sec): Scroll 500x500 pixels
   3000 reps @   2.2714 msec (   440.0/sec): Scroll 500x500 pixels
  15000 trep @   2.2662 msec (   441.0/sec): Scroll 500x500 pixels
    800 reps @  11.6017 msec (    86.2/sec): ShmPutImage 500x500 square
    800 reps @  11.6358 msec (    85.9/sec): ShmPutImage 500x500 square
    800 reps @  11.6463 msec (    85.9/sec): ShmPutImage 500x500 square
    800 reps @  11.6122 msec (    86.1/sec): ShmPutImage 500x500 square
    800 reps @  11.6322 msec (    86.0/sec): ShmPutImage 500x500 square
   4000 trep @  11.6257 msec (    86.0/sec): ShmPutImage 500x500 square
fragment latency = 1.451247 ms
cpu latency = 1.160998 ms
  4.2ms (  0)|
1MS num_time_samples=63551 num_times_within_1ms=61215 factor=96.324212
2MS num_time_samples=63551 num_times_within_2ms=63546 factor=99.992132
PIXEL_PER_MS=103
fragment latency = 1.451247 ms
cpu latency = 1.160998 ms
  3.8ms (  0)|
1MS num_time_samples=20758 num_times_within_1ms=19668 factor=94.749012
2MS num_time_samples=20758 num_times_within_2ms=20693 factor=99.686868
PIXEL_PER_MS=103
fragment latency = 1.451247 ms
cpu latency = 1.160998 ms
 30.0ms (  3)|
1MS num_time_samples=17604 num_times_within_1ms=16825 factor=95.574869
2MS num_time_samples=17604 num_times_within_2ms=17591 factor=99.926153
PIXEL_PER_MS=103
-rw-r--r--    1 root     root     350000000 Apr  5 20:09 tmpfile
fragment latency = 1.451247 ms
cpu latency = 1.160998 ms
 14.8ms ( 12)|
1MS num_time_samples=24448 num_times_within_1ms=23863 factor=97.607166
2MS num_time_samples=24448 num_times_within_2ms=24425 factor=99.905923
PIXEL_PER_MS=103
-rw-r--r--    1 root     root     350000000 Apr  5 20:09 tmpfile
-rw-r--r--    1 root     root     350000000 Apr  5 20:10 tmpfile2
fragment latency = 1.451247 ms
cpu latency = 1.160998 ms
  4.5ms (  1)|
1MS num_time_samples=16142 num_times_within_1ms=15463 factor=95.793582
2MS num_time_samples=16142 num_times_within_2ms=16134 factor=99.950440
PIXEL_PER_MS=103
-rw-r--r--    1 root     root     350000000 Apr  5 20:09 tmpfile
-rw-r--r--    1 root     root     350000000 Apr  5 20:10 tmpfile2
122.970u 18.150s 4:09.80 56.4%  0+0k 0+0io 10418pf+0w
*******************************************************************************
2.4.19-pre5-vm33-rml
32 clients started
...........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................++.....+.........+.........+....+.++.....+.+.+...+.+.....++.+...+++++...++.+.++++++++********************************
Throughput 39.637 MB/sec (NB=49.5463 MB/sec  396.37 MBit/sec)
14.370u 53.580s 1:47.59 63.1%   0+0k 0+0io 939pf+0w
SunWave1 dbench/latencytest0.42-png# time ./do_tests none 3 256 0 350000000
x11perf - X11 performance program, version 1.5
The XFree86 Project, Inc server version 40200000 on :0.0
from SunWave1
Fri Apr  5 21:29:15 2002
Sync time adjustment is 0.2172 msecs.
   3000 reps @   2.2866 msec (   437.0/sec): Scroll 500x500 pixels
   3000 reps @   2.2899 msec (   437.0/sec): Scroll 500x500 pixels
   3000 reps @   2.2885 msec (   437.0/sec): Scroll 500x500 pixels
   3000 reps @   2.2847 msec (   438.0/sec): Scroll 500x500 pixels
   3000 reps @   2.2958 msec (   436.0/sec): Scroll 500x500 pixels
  15000 trep @   2.2891 msec (   437.0/sec): Scroll 500x500 pixels
    400 reps @  11.7923 msec (    84.8/sec): ShmPutImage 500x500 square
    400 reps @  11.8264 msec (    84.6/sec): ShmPutImage 500x500 square
    400 reps @  11.8240 msec (    84.6/sec): ShmPutImage 500x500 square
    400 reps @  11.8370 msec (    84.5/sec): ShmPutImage 500x500 square
    400 reps @  11.8484 msec (    84.4/sec): ShmPutImage 500x500 square
   2000 trep @  11.8256 msec (    84.6/sec): ShmPutImage 500x500 square
fragment latency = 1.451247 ms
cpu latency = 1.160998 ms
  4.2ms (  0)|
1MS num_time_samples=48986 num_times_within_1ms=47284 factor=96.525538
2MS num_time_samples=48986 num_times_within_2ms=48979 factor=99.985710
PIXEL_PER_MS=103
fragment latency = 1.451247 ms
cpu latency = 1.160998 ms
  3.8ms (  0)|
1MS num_time_samples=20764 num_times_within_1ms=20537 factor=98.906762
2MS num_time_samples=20764 num_times_within_2ms=20762 factor=99.990368
PIXEL_PER_MS=103
fragment latency = 1.451247 ms
cpu latency = 1.160998 ms
  3.8ms (  0)|
1MS num_time_samples=20603 num_times_within_1ms=20109 factor=97.602291
2MS num_time_samples=20603 num_times_within_2ms=20602 factor=99.995146
PIXEL_PER_MS=103
-rw-r--r--    1 root     root     350000000 Apr  5 21:31 tmpfile
fragment latency = 1.451247 ms
cpu latency = 1.160998 ms
  6.8ms (  2)|
1MS num_time_samples=25283 num_times_within_1ms=24655 factor=97.516118
2MS num_time_samples=25283 num_times_within_2ms=25280 factor=99.988134
PIXEL_PER_MS=103
-rw-r--r--    1 root     root     350000000 Apr  5 21:31 tmpfile
-rw-r--r--    1 root     root     350000000 Apr  5 21:32 tmpfile2
fragment latency = 1.451247 ms
cpu latency = 1.160998 ms
  5.3ms (  1)|
1MS num_time_samples=16210 num_times_within_1ms=15669 factor=96.662554
2MS num_time_samples=16210 num_times_within_2ms=16203 factor=99.956817
PIXEL_PER_MS=103
-rw-r--r--    1 root     root     350000000 Apr  5 21:31 tmpfile
-rw-r--r--    1 root     root     350000000 Apr  5 21:32 tmpfile2
116.600u 19.040s 3:54.15 57.9%  0+0k 0+0io 10418pf+0w
[unhandled content-type:application/x-tgz][unhandled content-type:application/x-tgz]