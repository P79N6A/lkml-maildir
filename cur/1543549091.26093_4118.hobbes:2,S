Date: Mon, 18 Sep 2000 19:20:57 +1000
From: Robert Cohen <>
Subject: Re: Terrible elevator performance in Linux 2.4.0-test8
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/9/18/98

From: Andrea Arcangeli (andrea@suse.de)
Date: Thu Sep 14 2000 - 09:30:52 EST 
On Thu, Sep 14, 2000 at 07:40:12PM +1000, Robert Cohen wrote: 
>> With kernel version 2.4.0-test1-ac22, I saw adequate performance. 
>In 2.4.0-test1-ac22 there were a latency-driven elevator (the one we have 
>now since test2 can't provide good latency anymore). 
>So if something it should be the other way around, the elevator that we 
>have since test2 should provide _better_ throghput and _less_ seeks. Thus 
>it can't be the elevator algorithm but maybe as Ingo said something in >the 
>plugging that broke during the test2 changes. 
> In 2.4.0-test3 - test6, the default max_bombs value became 0. And the 
> performance with this setting was terrible. 
>It's zero because in reality is not limited anymore, this just mean it 
>should provide better performance and worse latency. 
Your correct, I thought for a while I was seeing performance
improvements by changing max_bombs with elvtune in test6, but it seems
that was just random fluctuation.
>> Although I still saw a tendency for a client to get write starved. 
>Are you doing synchronous writes, right? 
>> Unfortunately, the benchmarks don't show any improvement. 
>tiotest should provide better numbers with the elevator from test2 
(>compared to the test1 one). 
Ive done some tiotest benchmarks. Tiotest doesnt show any significant
performance problems. In kernel versions test1- test6 I see roughly
comparable performance. Write 8Meg/sec, read 5 Meg/sec.
So performance didnt change when the elevator was rewritten in test2.
In test9pre2 I see a jump in read perforance from 5 Meg/sec to 10
Meg/sec.
While write stays the same.
While that is all well and good, the fact remains that the netatalk
benchmark remains terrible. With 2.4.0-test9pre2, throughput drops from
2000 blocks/5 seconds (according to vmstat) with 2 clients  to 100
blocks/ 5 secs with 4 clients.
Ive double checked, the test is not using Sync writes.
I'm also seeing a tendency for clients to get write starved.
Also while the benchmark is running the machine is basically unusable
for other actions. Programs can't be started from the command prompt.
They just hang, presumably waiting on disk IO.
Sometimes top and vmstat stop updating. I saw this to some extent while
running tiotest as well.
The only kernel I have been able to find with good performance on this
benchmark was 2.4.0-test1-ac22.
Ingo's patch for test9pre1 didnt seem to make any difference.
--
Robert Cohen
TLTSU, Australian National University.
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
Please read the FAQ at 
http://www.tux.org/lkml/