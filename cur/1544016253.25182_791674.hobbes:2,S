Date: Wed, 14 Jan 2009 03:20:08 +0300
From: Evgeniy Polyakov <>
Subject: Re: [0/7] Distributed storage for drivers/staging merge request
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2009/1/13/542

On Wed, Jan 14, 2009 at 03:15:46AM +0300, Evgeniy Polyakov (zbr@ioremap.net) wrote:
> > Whereas the "do we need this" case for new filesystems isn't this simple.
> 
> More on this, it is a block device which does not work with hardware.
> And yes, question is serious. And you may not believe, but it is not me
> to answer this. I'm happy to provide any needed information.
> In a nutshell, it is a network block device on really huge steroids.
And according to POHMELFS which is a parallel very high-performance
(forget nfs) network filesystem with coherent local cache of data
and metadata.
The only change expected to be done is one additional network command
to parse the data currently sent via netlink. We want to connect to the
new servers by another server request and not by admin steps.
Patch will be somewhat 10-50 lines. And while you at it, please shed a
light on this exports for POHMELFS:
--- a/mm/filemap.c
+++ b/mm/filemap.c
@@ -513,6 +513,7 @@ int add_to_page_cache_lru(struct page *page, struct address_space *mapping,
 	}
 	return ret;
 }
+EXPORT_SYMBOL_GPL(add_to_page_cache_lru);
 
 #ifdef CONFIG_NUMA
 struct page *__page_cache_alloc(gfp_t gfp)
@@ -627,6 +628,7 @@ int __lock_page_killable(struct page *page)
 	return __wait_on_bit_lock(page_waitqueue(page), &wait,
 					sync_page_killable, TASK_KILLABLE);
 }
+EXPORT_SYMBOL_GPL(__lock_page_killable);
 
 /**
  * __lock_page_nosync - get a lock on the page, without calling sync_page()
-- 
	Evgeniy Polyakov