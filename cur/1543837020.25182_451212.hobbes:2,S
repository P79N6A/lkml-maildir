Date: Tue, 8 Aug 2006 12:10:39 +0200
From: Eric Dumazet <>
Subject: Re: [RFC] NUMA futex hashing
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2006/8/8/91

On Tuesday 08 August 2006 11:57, Andi Kleen wrote:
> Ravikiran G Thirumalai <kiran@scalex86.org> writes:
> > Current futex hash scheme is not the best for NUMA.   The futex hash
> > table is an array of struct futex_hash_bucket, which is just a spinlock
> > and a list_head -- this means multiple spinlocks on the same cacheline
> > and on NUMA machines, on the same internode cacheline.  If futexes of two
> > unrelated threads running on two different nodes happen to hash onto
> > adjacent hash buckets, or buckets on the same internode cacheline, then
> > we have the internode cacheline bouncing between nodes.
>
> When I did some testing with a (arguably far too lock intensive) benchmark
> on a bigger box I got most bouncing cycles not in the futex locks itself,
> but in the down_read on the mm semaphore.
This is true, even with a normal application (not a biased benchmark) and 
using oprofile. mmap_sem is the killer.
We may have special case for PRIVATE futexes (they dont need to be chained in 
a global table, but a process private table)
POSIX thread api already can let the application tell glibc/kernel a 
mutex/futex ahe a process scope.
For this private futexes, I think we would not need to down_read(mmap_sem) at 
all. (only a/some lock/s protecting the process private table)
Eric
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/