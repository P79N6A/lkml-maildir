Date: Sat, 17 Apr 1999 20:04:19 -0400 (EDT)
From: "Richard B. Johnson" <>
Subject: Linux version 2.2.5 memory management
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/4/17/91

There is a serious problem with V2.2.5 memory management.
When the machine is first booted (single-user, no swap, only root mounted)
I can acquire about 50 megabyte of free pages from a 132 megabyte machine.
Whether or not this is appropriate is another matter. I acquire pages
until the 'low_on_memory' flag is true. If I acquire pages until the
return value is NULL, the machine will hang forever with processes being
killed off including init.
If I dirty the pages, then give them all back -- and I promise that I
did give them all back (source-code is available), on subsequent attempts
to acquire pages, I can only get about a megabyte.
Once in this new state, I acquire and give back the same low amount
consistantly. In other words, there is an initial gigantic leak, followed
by no aparent additional leak.
The test-code implements a device module which can be configured as
a FIFO, i.e., you write to it until it's full, then you can read back
what has been written. This is not the 'Unix' notion of a FIFO, but
a FIFO that can be read and written as a device. This device can initially
acquire about 50 megabytes of pages before it is 'full'. It is emptied
by reading from it, at which time it returns pages to the kernel.
Therefore the testing can be done with a simple script, the results are
attached. 
If I do the tests in single-user mode, then restart multi-user,
eventually (after several hours), the kernel recovers most of the pages
that have been lost. I can speed up the recovery by executing `ls -R /`,
i.e., exercising the directory cache.
At that time, I can consistently get 30 or more megabytes of pages without
any apparent additional leaks.
I believe that there is something very wrong with the heuistics in
returning free pages to the free list. Free pages have to go on the
free list before they have been sorted out to see what makes continuous
areas of various sizes. It looks from the code that recently freed
pages are not used again until they have been 'coalased' because somebody
needed some continuous ones via kmalloc.
Cheers,
Dick Johnson
                 ***** FILE SYSTEM WAS MODIFIED *****
Penguin : Linux version 2.2.5 on an i686 machine (400.59 BogoMips).
Warning : It's hard to remain at the trailing edge of technology.
[unhandled content-type:application/octet-stream]