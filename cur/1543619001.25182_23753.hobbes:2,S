Date: Tue, 29 Jan 2002 18:43:23 +0530
From: "Rajasekhar Inguva" <>
Subject: [PATCH]:net/ipv4/route.c
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2002/1/29/98

Hello,
The patch applies to net/ipv4/route.c , Kernel version 2.5.2
Please find a detailed description of my patch below. Firstly I would like
to apologize if my patch is
In a wrong format
Already submitted by someone and rejected by you guys.
Non-conformance to kernel coding style.
The problem:
When neighbour tables are full, an attempt is made from rt_intern_hash to
release a few neighbour entries that the route cache might still be
referring to. This is achieved by calling rt_garbage_collect.
rt_garbage_collect does fail sometimes to release some entries as it checks
not only for reference counts, but also some expiry timers. This ends up in
the infamous 'Neighbour table overflow' message being displayed.
The patch:
My patch solves this problem. The approach was to write a new routine
rt_delete_now, which unlike rt_garbage_collect, deletes the route cache
entries based only on reference counts and not on expiry timers.
rt_delete_now is called from rt_intern_hash instead of rt_garbage_collect.
The reason of this approach is to act as per demand. The call to
rt_garbage_collect from rt_intern_hash is made in emergency situations
(Neighbour tables are full). At this juncture, it is better IMHO, to delete
'un-referred' entries rather than finding garbage entries (un-referred &&
expired) and deleting them. The patch is actually a copy of
rt_garbage_collect code minus expiry time checking code.
I would be glad to receive your comments and feedback on this patch.
Regards,
Raj
(See attached file: neigh.patch)
--- /usr/src/linux/net/ipv4/route.c     Tue Jan 29 17:24:15 2002
+++ /usr/src/linux/net/patches/route.c  Tue Jan 29 17:26:22 2002
@@ -471,6 +471,37 @@
        mod_timer(&rt_flush_timer, now+delay);
        spin_unlock_bh(&rt_flush_lock);
 }
+/*
+       Called by rt_intern_hash. Deletes unused entries immediately
+       in emergency situations.
+*/
+static void rt_delete_now()
+{
+       int i;
+       struct rtable *rth, **rthp;
+
+       for(i=rt_hash_mask; i>=0; i--) {
+
+       rthp = &rt_hash_table[i].chain;
+       write_lock_bh(&rt_hash_table[i].lock);
+
+               while((rth=*rthp) != NULL) {
+               if(atomic_read(&rth->u.dst.__refcnt)) {
+               rthp = &rth->u.rt_next;
+               continue;
+               }
+
+       *rthp = rth->u.rt_next;
+       rt_free(rth);
+
+       }
+
+       write_unlock_bh(&rt_hash_table[i].lock);
+
+       }
+
+}
+
 /*
    Short description of GC goals.
@@ -646,13 +677,7 @@
                           it is most likely it holds some neighbour
records.
                         */
                        if (attempts-- > 0) {
-                               int saved_elasticity = ip_rt_gc_elasticity;
-                               int saved_int = ip_rt_gc_min_interval;
-                               ip_rt_gc_elasticity     = 1;
-                               ip_rt_gc_min_interval   = 0;
-                               rt_garbage_collect();
-                               ip_rt_gc_min_interval   = saved_int;
-                               ip_rt_gc_elasticity     = saved_elasticity;
+                               rt_delete_now();
                                goto restart;
                        }[unhandled content-type:application/octet-stream]