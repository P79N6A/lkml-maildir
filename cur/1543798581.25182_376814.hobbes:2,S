Date: Thu, 15 Dec 2005 22:30:44 -0500
From: Lee Revell <>
Subject: Re: severe jitter experienced with "select()" in linux 2.6.14-rt22
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2005/12/15/448

On Thu, 2005-12-15 at 20:06 -0500, Gautam Thaker wrote:
> 
> /proc/latency trace is full of lines such as these:
> 
>    <...>-3     0.... 20317us : __down_mutex (rt_run_flush)
>    <...>-3     0.... 20317us : __up_mutex_savestate (rt_run_flush)
>    <...>-3     0.... 20317us : __down_mutex (rt_run_flush)
>    <...>-3     0.... 20317us : __up_mutex_savestate (rt_run_flush)
>    <...>-3     0.... 20317us : __down_mutex (rt_run_flush)
>    <...>-3     0.... 20317us : __up_mutex_savestate (rt_run_flush)
>    <...>-3     0.... 20318us : __down_mutex (rt_run_flush)
>    <...>-3     0.... 20318us : __up_mutex_savestate (rt_run_flush)
>    <...>-3     0.... 20318us : __down_mutex (rt_run_flush)
>    <...>-3     0.... 20318us : __up_mutex_savestate (rt_run_flush)
>    <...>-3     0.... 20318us : __down_mutex (rt_run_flush)
>    <...>-3     0.... 20318us : __up_mutex_savestate (rt_run_flush)
>    <...>-3     0.... 20319us : __down_mutex (rt_run_flush)
> 
> and
> 
> "dmesg" says somethign like this:
> 
> (        ubersock-4032 |#0): new 131 us user-latency.
> (        ubersock-4032 |#0): new 131 us user-latency.
> (        ubersock-4032 |#0): new 133 us user-latency.
> (        ubersock-4032 |#0): new 221 us user-latency.
> (        ubersock-4032 |#0): new 223 us user-latency.
> (        ubersock-4032 |#0): new 20629 us user-latency.
> root@blade8>
> 
> When tracing I exit my test when a large latency is observed (in the
> case above a 20,629 usec value was observed by the "select()" test. 
> 
AI've seen this in my tests too, I think it's still a problem that
rt_run_flush can cause a 20ms+ non preemptible section.
Ingo mentioned that he may push softirq preemption upstream which would
fix this.  You can also try tweaking these sysctls:
net.ipv4.route.gc_elasticity = 8
net.ipv4.route.gc_interval = 60
net.ipv4.route.gc_timeout = 300
net.ipv4.route.gc_min_interval_ms = 500
net.ipv4.route.gc_min_interval = 0
net.ipv4.route.gc_thresh = 4096
which AFAICT should let you tune the route cache garbage collection to
run more often and hopefully process fewer routes per run.
Lee
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/