Date: Thu, 21 Feb 2008 08:07:33 +0100
From: Ingo Molnar <>
Subject: Re: Make yield_task_fair more efficient
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/2/21/25

* Balbir Singh <balbir@linux.vnet.ibm.com> wrote:
> I disagree. The cost is only adding a field to cfs_rq [...]
wrong. The cost is "only" of adding a field to cfs_rq and _updating it_, 
in the hottest paths of the scheduler:
@@ -256,6 +257,7 @@ static void __enqueue_entity(struct cfs_
                 */
                if (key < entity_key(cfs_rq, entry)) {
                        link = &parent->rb_left;
+                       rightmost = 0;
                } else {
                        link = &parent->rb_right;
                        leftmost = 0;
@@ -268,6 +270,8 @@ static void __enqueue_entity(struct cfs_
         */
        if (leftmost)
                cfs_rq->rb_leftmost = &se->run_node;
+       if (rightmost)
+               cfs_rq->rb_rightmost = &se->run_node;
> [...] For a large number of tasks - say 10000, we need to walk 14 
> levels before we reach the node (each time). [...]
10,000 yield-ing tasks is not a common workload we care about. It's not 
even a rare workload we care about. _Especially_ we dont care about it 
if it slows down every other workload (a tiny bit).
> [...] Doesn't matter if the data is cached, we are still spending CPU 
> time looking through pointers and walking to the right node. [...]
have you actually measured how much it takes to walk the tree that deep
on recent hardware? I have.
	Ingo