Date: Wed, 9 Jun 1999 03:04:40 +0200 (MEST)
From: Ricardo Galli Granada <>
Subject: [OFFTOPIC] Re: Preparations for ZD's upcoming Apache/Linux benchmark - Why not Squid?
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/6/8/239

On Tue, 8 Jun 1999, Alex Belits wrote:
> 
>   OTOH, I can't see why it's impossible to do it completely transparent
> for the userspace server -- if request is recognized as not usable for the
> in-kernel processing, HTTP server just receives it like if nothing
> happened. And, in more "advanced" model, userspace process can do some
> "special" shutdown/close operation on its socket, transferring further
> control over it to the in-kernel server (but then future accept() will be 
> able to receive the same TCP connection again, and it will look like 
> different fd).
> 
Yes, the proposal should go to web server developers, not to linux-kernel.
There is many problems, not only regarding HTTP1.1, but also virtual
servers. These cannot be solved with just socket's pushing and shutdown.
They need a more complex communication semantics among in-kernel and
userland processes. Perhaps, especially for HTTP1.1, all
client communication tasks must be dealt by the khttpd with further "ipcs"
to user processes. In these case they have to agree at least in basic
configuration options (documents directories, directory
user authentification, mime-types, follow-links, log files, log formats,
put and post processing, etc., etc.). 
Anyway, this might be a work to web server developers and not related to
linux kernel itself. From a "relaxed" point of view, perhaps it's better
to put Squid in the kernel and to make it work in "accelerator mode" with
no disk caching and using the original files in the local file system
instead. We will get the same result with a more general and smarter
solution without touching a single line in any web server.
----- disclaimer: nothing important beyond this line (neither above) -----
IMHO, this is only useful for unreal benchmarking and small web server
black boxes (Cisco tried and failed to introduce these gears to the
market, the cost in Spain was almost twice of a well configured PII). I do
not know any web site in Europe with a 100 mbps connection to
Internet. Finland is years ahead than other european countries
regarding Internet infraestructure. I am convinced their bigger pipes
(most) to Internet do not pass a 34 mbps ATM connection (although there
are other well known linux hackers that can have a deeper knowledge of
the country). 
Also, if they exist, communication costs should be bigger than $ 50.000 a
month, which justify the price of a couple of high-end  PCs for load
balancing. I did not hear Altavista, Yahoo, Amazon, Excite or Netscape
IT managers complaining of the lack of scalability of their servers, they
just add new computers and "load splitters"* or they do clustering.
If a company claims their customers/audience can fullfill a 100 mbps pipe
to Internet (or even Intranet) and they try to solve the problem with
_only one_ Xeon Quad with NT because "Linux does not scale well", they are
cheating you or the IT manager must fired inmediately.
* Sorry, I don't remember the commercial names of these products but they
exist and are very common in big web sites with lots of CGIs and
databases.
--ricardo
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/