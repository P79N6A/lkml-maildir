Date: Mon, 28 Nov 2005 21:31:29 +0530
From: Dipankar Sarma <>
Subject: Re: [PATCH] Allow lockless traversal of notifier lists
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2005/11/28/67

On Mon, Nov 28, 2005 at 02:37:57PM +0100, Andi Kleen wrote:
> 
> As discussed in other thread.
> 
> Just needed an additional write barrier, so that a parallel
> running lockup can never see inconsistent state. As long as there
> is no unregistration or the unregistration is done using
> locking or RCU in the caller they should be ok now.
> 
> This only makes a difference on non i386/x86-64 architectures.
> x86 was already ok because it never reorders writes.
> 
>   *
>   *	Currently always returns zero.
>   */
> @@ -116,6 +119,7 @@
>  		list= &((*list)->next);
>  	}
>  	n->next = *list;
> +	wmb();
>  	*list=n;
>  	write_unlock(&notifier_lock);
Shouldn't this be smp_wmb() ?
Also, not all archs have strong ordering for data dependent reads.
So, you would probably need an smp_read_barrier_depends() between
the load of the pointer and actual dereferencing.
Thanks
Dipankar
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/