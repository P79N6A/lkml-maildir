Date: Wed, 09 Feb 2000 12:10:00 -0800
From: John Hawkes <>
Subject: Re: [PATCH] spinlock metering (2.3.42)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/2/9/130

Linus Torvalds wrote:
> 
> On Tue, 8 Feb 2000, John Hawkes wrote:
> >
> > Please consider this SMP i386 patch against 2.3.42 to add a "spinlock
> > metering" enhancement.  This patch is also found at:
> >     
http://oss.sgi.com/projects/lockmeter/download/
> 
> Mind showing us an example of real-world usage and results? I'm loathe to
> apply this along with all the other changes I have pending, but I'd like
> to know how it looks and what the results are under some real usage, just
> as an example..?
I take a 4x500MHz Xeon running 2.3.28 and exercise it with what I call
a "modified AIM7" workload -- without three disk subtests that otherwise
produce 90% idle time because these synchronous subtests saturate my
single
disk spindle.  My system thus becomes compute-bound, roughly 75% user
and
25% system.
Spinlock metering tells me that 4% of the available CPU cycles (160msec
per
the total of 4,000msec on the four CPUs, per second) are spent waiting
on
spinlocks, with the longest wait-time being over 14msec and the longest
hold-time being 15msec.  This 4% is an improvement over the 8% exhibited
by 2.2.13.
The kernel_flag is still the biggest culprit in 2.3.28 and it accounts
for
almost all of the witnessed wait-time cycles (157msec of the 160msec
total).  A call in ext2_get_block() accounts for 45msec of this 157msec.
The largest hold-time occurs in do_close() -- that 15msec mentioned
earlier -- with a mean hold-time of 59usec (microsec).  Other long holds
are done by sys_unlink() (10msec max), sys_open() (5.5msec), and
sys_execvs() (2msec).
-- 
John Hawkes
hawkes@engr.sgi.com
http://oss.sgi.com/projects
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/