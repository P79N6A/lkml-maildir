Date: Fri, 10 Mar 2000 11:36:31 -0600 (CST)
From: Jesse Pollard <>
Subject: Re: Help in DSM design
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/3/10/84

Horst von Brand <vonbrand@pincoya.inf.utfsm.cl>:
>Paul Jakma <paul.jakma@compaq.com> said:
>
>[...]
>
>> correct me if i'm wrong, but aren't all the SysVR4 derived unices
>> (T64/IRIX/Solaris/Unixware) using Mach based kernels? And MacOS X too?
>
>All monolytic, except possibly MacOS X (don't know that one, and I remember
>Apple's Linux was on Mach, because they wanted to build their OS based on
>Mach, so it could be). WinNT was based on Mach, but is going to monolytic
>step by step too. The OS of the huge multiprocessor CRAYs was a microkernel
>OS running on what was essentially a cluster of machines with a very fast
>internal network, dunno what became of that.
Still there and running fine. The T3E can have up to 2048 cpus (possibly
more but I don't know of any ... ours has over 1024 in 4 cabinets).
It uses (or was originally based on) Chorous rather than Mach. Part of
the reason it was microkernel at all was to distribute copies of the core
OS, then distribute user scheduling over a limited number (40 or so), IO
over 5-10, depending on the number of gigaring conectiors purchased, and
the communication processors used at the remote side of the gigaring. The
gigaring itself is sort of like a token ring - but about 100 times faster.
Drivers communicate with specific devices over the gigagring, there may only
be 4 gigaring connections, with 15-20 devices that get fed through the 
ring. These drivers provide the low level device access - FDDI, disk...etc.
Scheduling is done via 3 classes of processors - one class dedicated to
operating system details (device IO type of thing), one class to command
processing (interactive scheduling), and application processing
(non-interactive gang scheduling). A cpu may be in more than one class, but
that tends to make it a poor performer. There is even a set of "hot spare"
cpus available to cover for errors (10-15 out of 1000). CPU counts do
not inlude "hot spares", or operating system units. This slightly inflates
the number of cpus - a 1024 cpu unit actually has about 1048 to 1072 cpus.
The numbers given are not accurate - there are 4 cpus per board so the numbers
should be multiples of 4; they are only to give an idea of whats done.
The internal network is fully implemented in hardware/firmware - I believe
each cpu is connected to four others.. odd geometries can result. At the
edges of the array are connected to the other side. This forms the torus
geometry of the net.
-------------------------------------------------------------------------
Jesse I Pollard, II
Email: pollard@navo.hpc.mil
Any opinions expressed are solely my own.
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/