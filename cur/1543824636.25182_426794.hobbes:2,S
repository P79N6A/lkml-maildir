Date: Thu, 25 May 2006 16:15:53 +1000
From: David Chinner <>
Subject: Re: [PATCH]  Per-superblock unused dentry LRU lists V2
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2006/5/25/35

On Thu, May 25, 2006 at 09:36:04AM +0530, Balbir Singh wrote:
> > +/*
> > + * Shrink the dentry LRU on Ã¦ given superblock.
> 			      ^^^
> This character (ae) looks strange.
Fixed. It slipped through when I switched to the -mm tree.
> The other changes look fine. Do you have any performance numbers, any
> results from stress tests (for version 2 of the patch)?
Not yet - I've just started the stress tests now. I had to wait for
the storage and then reconfigure it which took some time.  It's
currently running a create/unlink workload across 8 filesystems in
parallel.  I'll run some dbench loads after this has run for a few
hours.
FWIW, this create/unlink load has been triggering reliable "Busy
inodes after unmount" errors that I've slowly been tracking down.
After I fixed the last problem in XFS late last week, I've
been getting a failure that i think is the unmount/prune_dcache
races that you and Neil have recently fixed.
Basically, I'm seeing a transient elevated reference  count on
the root inode of the XFS filesystem during the final put_super()
in generic_shutdown_super(). If I trigger a BUG_ON() when that
elevated reference count is detected, byt he time al the cpus
are stopped and I'm in kdb, the reference count on the root inode
is only 1. The next thing I was going to track was where the dentry
for the root inodes was.
I'll know if this really is the same race soon, as the create/unlink
test would trip it under an hour.....
Cheers,
Dave.
-- 
Dave Chinner
R&D Software Enginner
SGI Australian Software Group
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/