Date: Thu, 20 May 1999 19:43:19 +0400
From: "Alexander V. Lukyanov" <>
Subject: large directory handling speed
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/5/21/19

I have noticed that ext2 handles large directory much better than vfat
or iso9660.
A directory containing 10000 files was processed by a program doing
readdir/lstat in order of half hour, with high system load - obviously
for each file system spent a lot of time in lstat, I could see that with
strace. The further from directory beginning the files were, the slower
lstat worked (linear search, it seems).
The same program handled similar directory on ext2 filesystem in several
seconds.
So the question is how can it be sped up?
I know that vfat is not of very smart design, but windows handled the
directory better. I also know that it could be better to split the
files into several directories, but one can see such directories on
cdrom's occasionally.
   Alexander.
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/