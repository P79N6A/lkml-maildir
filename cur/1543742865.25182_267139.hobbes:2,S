Date: Mon, 1 Nov 2004 13:51:27 +0100
From: Ingo Molnar <>
Subject: Re: [Fwd: Re: [patch] Real-Time Preemption, -RT-2.6.9-mm1-V0.4]
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2004/11/1/63

* Thomas Gleixner <tglx@linutronix.de> wrote:
> I'm doing some tests from my RT environment on 0.6.2. I'm quite sure,
> that interrupts are sporadically disabled for > 200Âµs. Did you change
> anything relevant to this between 0.6.2 and 0.6.4 ?
hm, i changed the task-exit schedule() to be called with irqs-off and
__schedule() - but that should be fine. I've attached the delta diff -
there's nothing suspicious at first sight. Maybe -V0.6.4 just made some
already existing bug more likely to trigger? I am too seeing rtc_wakeup
weirdnesses that were not present in earlier -V0.6 kernels.
	Ingo
--- linux.old/Makefile	
+++ linux.new/Makefile	
@@ -1,7 +1,7 @@
 VERSION = 2
 PATCHLEVEL = 6
 SUBLEVEL = 9
-EXTRAVERSION = -mm1-RT-V0.6.2
+EXTRAVERSION = -mm1-RT-V0.6.4
 NAME=Zonked Quokka
 
 # *DOCUMENTATION*
--- linux.old/kernel/exit.c	
+++ linux.new/kernel/exit.c	
@@ -840,9 +840,9 @@ asmlinkage NORET_TYPE void do_exit(long 
 #endif
 	check_no_held_locks(tsk);
 	/* PF_DEAD causes final put_task_struct after we schedule. */
-	wmb();
+	local_irq_disable();
 	tsk->flags |= PF_DEAD;
-	schedule();
+	__schedule();
 	BUG();
 	/* Avoid "noreturn function does return".  */
 	for (;;) ;
--- linux.old/kernel/sched.c	
+++ linux.new/kernel/sched.c	
@@ -599,13 +599,11 @@ static inline void enqueue_task_head(str
  *
  * Both properties are important to certain workloads.
  */
-static int effective_prio(task_t *p)
+
+static inline int __effective_prio(task_t *p)
 {
 	int bonus, prio;
 
-	if (rt_task(p))
-		return p->prio;
-
 	bonus = CURRENT_BONUS(p) - MAX_BONUS / 2;
 
 	prio = p->static_prio - bonus;
@@ -616,6 +614,13 @@ static int effective_prio(task_t *p)
 	return prio;
 }
 
+static int effective_prio(task_t *p)
+{
+	if (rt_task(p))
+		return p->prio;
+	return __effective_prio(p);
+}
+
 /*
  * __activate_task - move a task to the runqueue.
  */
@@ -3540,8 +3545,7 @@ int mutex_getprio(task_t *p)
 	if (p->policy != SCHED_NORMAL)
 		return MAX_USER_RT_PRIO-1 - p->rt_priority;
 	else
-//		return effective_prio(p);
-		return p->static_prio;
+		return __effective_prio(p);
 }
 
 /*
@@ -3559,15 +3563,14 @@ void mutex_setprio(task_t *p, int prio)
 
 	rq = task_rq_lock(p, &flags);
 
+	oldprio = p->prio;
 	array = p->array;
 	if (array)
-		deactivate_task(p, rq);
-	oldprio = p->prio;
-
+		dequeue_task(p, array);
 	p->prio = prio;
 
 	if (array) {
-		__activate_task(p, rq);
+		enqueue_task(p, array);
 		/*
 		 * Reschedule if we are currently running on this runqueue and
 		 * our priority decreased, or if we are not currently running on
--- linux.old/kernel/timer.c	
+++ linux.new/kernel/timer.c	
@@ -956,23 +956,25 @@ EXPORT_SYMBOL(xtime_lock);
  */
 static inline void update_times(void)
 {
+	unsigned long ticks = 0;
 	/*
 	 * First test outside the lock for performance reasons:
 	 */
-	if (jiffies - wall_jiffies) {
+	if (jiffies != wall_jiffies) {
 		unsigned long flags;
 
 		write_seqlock_irqsave(&xtime_lock, flags);
-		while (jiffies - wall_jiffies) {
+		while (jiffies != wall_jiffies) {
 			wall_jiffies++;
+			ticks++;
 			update_wall_time(1);
-			calc_load(1);
 			if (seqlock_need_resched(&xtime_lock)) {
 				write_sequnlock_irqrestore(&xtime_lock, flags);
 				cond_resched();
 				write_seqlock_irqsave(&xtime_lock, flags);
 			}
 		}
+		calc_load(ticks);
 		write_sequnlock_irqrestore(&xtime_lock, flags);
 	}
 }
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/