Date: Sat, 4 Mar 2000 14:42:15 +0100
From: Davide Libenzi <>
Subject: Re: Help in DSM design
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/3/4/38

On Sat, 04 Mar 2000, Manfred Spraul wrote:
> Larry McVoy wrote:
> > 
> > Cache line miss, around 200ns.
> 
> I know this is of-topic, but I read that cache-line ping-pong is a
> problem for our spinlocks. Has anyone tried to move the spinlocks (*)
> into a special page, and mark that page as "write-trough"?
> 
> It should be possible to add a new ELF section, and mark the global
> spinlocks with __spinlockdata [like __initdata].
> 
> (*) I know that many spinlocks are located within other structures, but
> some (important) spinlocks are not:
> 
> * kernel_flag
> * tasklist_lock
> * runqueue_lock
> * global_bh_lock
> * pagecache_lock
> * pagemap_lru_lock
> * inode_lock
> * lru_list_lock
> * hash_table_lock
> * console_lock
> * kmap_lock
> * semaphore_lock [i386]
> * tlbstate_lock [i386]
I think that can be a good idea coz it avoid the probability that two spinlock
fall into the same cacheline.
union align_lock {
	spinlock_t lock;
	char filler[CACHE_LINE_SIZE];
};
union align_lock locks[PAGE_SIZE / sizeof(CACHE_LINE_SIZE)];
enum locks_ids {
	lck_kernel,
	lck_tasklist,
	...
};
Davide.
-- 
Feel free, feel Debian !
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/