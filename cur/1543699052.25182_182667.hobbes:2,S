Date: Mon, 8 Dec 2003 19:21:14 +0100 (CET)
From: Ingo Molnar <>
Subject: Re: [patch] sched-HT-2.6.0-test11-A5
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2003/12/8/153

On Mon, 8 Dec 2003, William Lee Irwin III wrote:
> This appears to either leak migration threads or not set
> rq->cpu[x].migration_thread basically ever for x > 0. Or if they are
> shut down, how? Also, what makes sure cpu_idx is initialized before they
> wake? They'll all spin on cpu_rq(0)->lock, no?
yep, it just leaks migration threads. Not a big problem right now, but for
hotplug CPU support this needs to be fixed.
> Furthermore, sched_map_runqueue() is performed after all the idle
> threads are running and all the notifiers have kicked the migration
> threads, but does no locking whatsoever.
yep - at this point nothing else is really supposed to run but you are
right it must be locked properly.
> Also, does init_idle() need to move into rest_init()? It should be
> equivalent to its current placement.
this is a leftover of a change that went into 2.6 already. I've removed
this change.
> Why not per_cpu for __rq_idx[] and __cpu_idx[]? This would have the
> advantage of residing on node-local memory for sane architectures (and
> perhaps in the future, some insane ones).
agreed, i've changed them to be per-cpu.
new patch with all your suggestions included is at:
  redhat.com/~mingo/O(1)-scheduler/sched-SMT-2.6.0-test11-C1
it also includes the bounce-to-cpu1 fix from/for Anton.
	Ingo
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/