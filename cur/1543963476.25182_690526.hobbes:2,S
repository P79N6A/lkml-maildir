Date: Fri, 9 May 2008 00:01:24 +0100
From: Alan Cox <>
Subject: Re: Deleting large files
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/5/8/464

> user experience.  Forking a process to do the deletion (a) is pathetic,
> (b) is not currently done, and (c) does not work: you cannot get a result
> right away, i.e., you lose error handling.
I wouldn't call it pathetic. Quite a few big media file tools create a
thread to do deletions of big objects.
The error handling isn't usually a problem. You know any error you can do
anything meaningful with actually occurs immediately or close to it. If
you get errors because of I/O problems in a minutes time there isn't a
sensible response and recovery anyway - nor would a kernel side
asynchronous delete be able to recover any better.
In theory you can push some kind of asynchronous delete threads into the
kernel or extent the AIO interfaces we have to do AIO_delete but at the
end of the day the implementation would effectively be create thread,
unlink, exit - and you can do that neatly and sanely in user space.