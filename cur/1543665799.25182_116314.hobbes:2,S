Date: Tue, 11 Mar 2003 17:02:49 +0300
From: Andrey Panin <>
Subject: [PATCH] kernel/rcupdate.c microcleanup
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2003/3/11/57

Hi all,
attached patch (2.5.64) contains small cleanup of RCU code:
    - move smp_processor_id() outside of irq disabled region in call_rcu();
    - consolidate multiple spin_unlock() in the rcu_check_quiescent_state(),
      remove some unneeded {} and make this function inline.
Tested and works (at least doesn't crash). Please consider applying.
Best regards.
-- 
Andrey Panin		| Embedded systems software developer
pazke@orbita1.ru	| PGP key: wwwkeys.pgp.net
diff -urN -X /usr/share/dontdiff linux-2.5.64.vanilla/kernel/rcupdate.c linux-2.5.64/kernel/rcupdate.c
--- linux-2.5.64.vanilla/kernel/rcupdate.c	Thu Nov 28 01:35:46 2002
+++ linux-2.5.64/kernel/rcupdate.c	Mon Mar 10 20:18:48 2003
@@ -67,13 +67,12 @@
  */
 void call_rcu(struct rcu_head *head, void (*func)(void *arg), void *arg)
 {
-	int cpu;
+	int cpu = smp_processor_id();
 	unsigned long flags;
 
 	head->func = func;
 	head->arg = arg;
 	local_irq_save(flags);
-	cpu = smp_processor_id();
 	list_add_tail(&head->list, &RCU_nxtlist(cpu));
 	local_irq_restore(flags);
 }
@@ -117,13 +116,12 @@
  * switch). If so and if it already hasn't done so in this RCU
  * quiescent cycle, then indicate that it has done so.
  */
-static void rcu_check_quiescent_state(void)
+static inline void rcu_check_quiescent_state(void)
 {
 	int cpu = smp_processor_id();
 
-	if (!test_bit(cpu, &rcu_ctrlblk.rcu_cpu_mask)) {
+	if (!test_bit(cpu, &rcu_ctrlblk.rcu_cpu_mask))
 		return;
-	}
 
 	/* 
 	 * Races with local timer interrupt - in the worst case
@@ -134,23 +132,22 @@
 		RCU_last_qsctr(cpu) = RCU_qsctr(cpu);
 		return;
 	}
-	if (RCU_qsctr(cpu) == RCU_last_qsctr(cpu)) {
+	if (RCU_qsctr(cpu) == RCU_last_qsctr(cpu))
 		return;
-	}
 
 	spin_lock(&rcu_ctrlblk.mutex);
-	if (!test_bit(cpu, &rcu_ctrlblk.rcu_cpu_mask)) {
-		spin_unlock(&rcu_ctrlblk.mutex);
-		return;
-	}
+	if (!test_bit(cpu, &rcu_ctrlblk.rcu_cpu_mask))
+		goto out_unlock;
+
 	clear_bit(cpu, &rcu_ctrlblk.rcu_cpu_mask);
 	RCU_last_qsctr(cpu) = RCU_QSCTR_INVALID;
-	if (rcu_ctrlblk.rcu_cpu_mask != 0) {
-		spin_unlock(&rcu_ctrlblk.mutex);
-		return;
-	}
+	if (rcu_ctrlblk.rcu_cpu_mask != 0)
+		goto out_unlock;
+
 	rcu_ctrlblk.curbatch++;
 	rcu_start_batch(rcu_ctrlblk.maxbatch);
+
+out_unlock:
 	spin_unlock(&rcu_ctrlblk.mutex);
 }
 