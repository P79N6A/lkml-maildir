Date: Fri, 09 Jul 2004 02:24:20 +1000
From: Con Kolivas <>
Subject: [PATCH] Autotune swappiness
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2004/7/8/131

Here is another try at providing feedback to tune the vm_swappiness.
This patch tries to tune it dynamically according to the mapped_ratio. 
After some consideration I thought it would be easiest to simply remove 
the vm_swappiness tunable entirely, since that is the point of this patch.
Some in the field modelling and testing showed a biased downwards 
feedback based on the mapped ratio provided good performance under 
different workloads especially improving the desktop experience. The 
practical upshot of this is the machine will only ever swap very lightly 
while the percentage of mapped pages is low and allow more generous 
swapping as the percentage rises within the higher ranges.
The earlier design of this patch was much more complicated and the 
practical upshot of it was that it would make
vm_swappiness = mapped_ratio * mapped_ratio / 100
This had it's effect on the swappiness value in the setting of 
swap_tendency which was:
swap_tendency = mapped_ratio / 2 + distress + vm_swappiness
A close approximation was to make vm_swappiness a range of 0-150 instead 
of 100 and simplify swap tendency to be equal to this:
swap_tendency = distress + vm_swappiness
A follow up patch will use the vm_swappiness value to alter the rate of 
page inactivation as well, but for the moment I'll offer this one change 
for comments.
Patch applies to 2.6.7-mm6
Signed-off-by: Con Kolivas <kernel@kolivas.org>
  include/linux/swap.h   |    1 -
  include/linux/sysctl.h |   15 +++++++--------
  kernel/sysctl.c        |   11 -----------
  mm/vmscan.c            |   15 ++++++++-------
  4 files changed, 15 insertions(+), 27 deletions(-)
Index: linux-2.6.7-mm6/include/linux/swap.h
===================================================================
--- linux-2.6.7-mm6.orig/include/linux/swap.h	2004-07-09 02:15:07.509902884 +1000
+++ linux-2.6.7-mm6/include/linux/swap.h	2004-07-09 02:15:10.949349575 +1000
@@ -174,7 +174,6 @@
 /* linux/mm/vmscan.c */
 extern int try_to_free_pages(struct zone **, unsigned int, unsigned int);
 extern int shrink_all_memory(int);
-extern int vm_swappiness;
 
 #ifdef CONFIG_MMU
 /* linux/mm/shmem.c */
Index: linux-2.6.7-mm6/include/linux/sysctl.h
===================================================================
--- linux-2.6.7-mm6.orig/include/linux/sysctl.h	2004-07-09 02:15:07.509902884 +1000
+++ linux-2.6.7-mm6/include/linux/sysctl.h	2004-07-09 02:15:10.950349415 +1000
@@ -157,14 +157,13 @@
 	VM_OVERCOMMIT_RATIO=16, /* percent of RAM to allow overcommit in */
 	VM_PAGEBUF=17,		/* struct: Control pagebuf parameters */
 	VM_HUGETLB_PAGES=18,	/* int: Number of available Huge Pages */
-	VM_SWAPPINESS=19,	/* Tendency to steal mapped memory */
-	VM_LOWER_ZONE_PROTECTION=20,/* Amount of protection of lower zones */
-	VM_MIN_FREE_KBYTES=21,	/* Minimum free kilobytes to maintain */
-	VM_MAX_MAP_COUNT=22,	/* int: Maximum number of mmaps/address-space */
-	VM_LAPTOP_MODE=23,	/* vm laptop mode */
-	VM_BLOCK_DUMP=24,	/* block dump mode */
-	VM_HUGETLB_GROUP=25,	/* permitted hugetlb group */
-	VM_VFS_CACHE_PRESSURE=26, /* dcache/icache reclaim pressure */
+	VM_LOWER_ZONE_PROTECTION=19,/* Amount of protection of lower zones */
+	VM_MIN_FREE_KBYTES=20,	/* Minimum free kilobytes to maintain */
+	VM_MAX_MAP_COUNT=21,	/* int: Maximum number of mmaps/address-space */
+	VM_LAPTOP_MODE=22,	/* vm laptop mode */
+	VM_BLOCK_DUMP=23,	/* block dump mode */
+	VM_HUGETLB_GROUP=24,	/* permitted hugetlb group */
+	VM_VFS_CACHE_PRESSURE=25, /* dcache/icache reclaim pressure */
 };
 
 
Index: linux-2.6.7-mm6/kernel/sysctl.c
===================================================================
--- linux-2.6.7-mm6.orig/kernel/sysctl.c	2004-07-09 02:15:07.496904975 +1000
+++ linux-2.6.7-mm6/kernel/sysctl.c	2004-07-09 02:15:10.951349254 +1000
@@ -700,17 +700,6 @@
 		.mode		= 0444 /* read-only*/,
 		.proc_handler	= &proc_dointvec,
 	},
-	{
-		.ctl_name	= VM_SWAPPINESS,
-		.procname	= "swappiness",
-		.data		= &vm_swappiness,
-		.maxlen		= sizeof(vm_swappiness),
-		.mode		= 0644,
-		.proc_handler	= &proc_dointvec_minmax,
-		.strategy	= &sysctl_intvec,
-		.extra1		= &zero,
-		.extra2		= &one_hundred,
-	},
 #ifdef CONFIG_HUGETLB_PAGE
 	 {
 		.ctl_name	= VM_HUGETLB_PAGES,
Index: linux-2.6.7-mm6/mm/vmscan.c
===================================================================
--- linux-2.6.7-mm6.orig/mm/vmscan.c	2004-07-09 02:15:07.495905136 +1000
+++ linux-2.6.7-mm6/mm/vmscan.c	2004-07-09 02:15:21.366673884 +1000
@@ -116,9 +116,9 @@
 #endif
 
 /*
- * From 0 .. 100.  Higher means more swappy.
+ * From 0 .. 150.  Higher means more swappy.
  */
-int vm_swappiness = 60;
+static int vm_swappiness = 0;
 static long total_memory;
 
 static LIST_HEAD(shrinker_list);
@@ -690,17 +690,18 @@
 	 * is mapped.
 	 */
 	mapped_ratio = (sc->nr_mapped * 100) / total_memory;
-
+	
 	/*
 	 * Now decide how much we really want to unmap some pages.  The mapped
-	 * ratio is downgraded - just because there's a lot of mapped memory
+	 * ratio effect is downgraded by biasing downwards the value of
+	 * vm_swappiness - just because there's a lot of mapped memory
 	 * doesn't necessarily mean that page reclaim isn't succeeding.
 	 *
 	 * The distress ratio is important - we don't want to start going oom.
-	 *
-	 * A 100% value of vm_swappiness overrides this algorithm altogether.
 	 */
-	swap_tendency = mapped_ratio / 2 + distress + vm_swappiness;
+	vm_swappiness = mapped_ratio * 150 / 100;
+	vm_swappiness = vm_swappiness * vm_swappiness / 150;
+	swap_tendency = distress + vm_swappiness;
 
 	/*
 	 * Now use this metric to decide whether to start moving mapped memory[unhandled content-type:application/pgp-signature]