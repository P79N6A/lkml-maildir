Date: Fri, 15 Jun 2007 17:06:18 +0200
From: Johannes Weiner <>
Subject: Re: PROBLEM: kernel BUG at mm/swap_state.c:78! (v2.6.21 under vmware)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2007/6/15/256

Hi,
I am not sure if this patch is a fix or a hiding (or leads to more trouble at
all), so, could PLEASE anyone with knowledge about the code see over it?
Thanks :)
shrink_page_list() should not pass a private page to add_to_swap().
Is it a bug if the page is private when reaching this point? I do not think
so, because a few lines below is a condition where private pages are handled
legally.
diff --git a/mm/vmscan.c b/mm/vmscan.c
index 1be5a63..92573b7 100644
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -489,7 +489,8 @@ static unsigned long shrink_page_list(struct list_head *page_list,
 		 * Anonymous process memory has backing store?
 		 * Try to allocate it some swap space here.
 		 */
-		if (PageAnon(page) && !PageSwapCache(page))
+		if (PageAnon(page) && !PageSwapCache(page) &&
+		    !PagePrivate(page))
 			if (!add_to_swap(page, GFP_ATOMIC))
 				goto activate_locked;
 #endif /* CONFIG_SWAP */