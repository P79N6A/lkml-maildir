Date: Mon, 20 Mar 2000 05:48:31 -0600
From: Jesse Pollard <>
Subject: Re: Overcommitable memory??
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/3/20/65

On Sun, 19 Mar 2000, Gerhard Mack wrote:
>On Sun, 19 Mar 2000, Jesse Pollard wrote:
>
>> It is part of the issue. The system would never go OOM, users would go
>> OOR (Out-Of-Resources). Out of resources is a manageable entity, that
>> can be adjusted from the results of performance analysis. OOM is a
>> catastrophic failure of the system. If the system doesn't provide a
>> way to control it, direct which user is at fault, and as directed by
>> management policy, then that system is considered buggy and not ready
>> for production use.
>> 
>> >Besides, the "random abort that may crash the system" is not the
>> >alternative. It is a choice of WHICH process gets the OOM error first
>> >- the "true culprit" (the memory hog), or any old process which
>> >happens to want memory?
>> 
>> Right now there is no way to determine which proces should get terminated.
>
>Why not set resource limmits?  It's just like any other resource .. if I
>allow users unlimmited access to it I can fully expect to have someone
>crash the system.
I do - they just are not enforced. Each time a process forks it gets the
same limits that the parent has. The sum of all processes then becomes >
than the system.
-------------------------------------------------------------------------
Jesse I Pollard, II
Email: pollard@cats-chateau.net
Any opinions expressed are solely my own.
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/