Date: Tue, 29 Dec 1998 16:34:21 +0100
From: Kurt Garloff <>
Subject: Re: Reading few large blocks instead of many small when executing a file?
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1998/12/29/124

On Mon, Dec 28, 1998 at 06:28:33PM +0100, Hans Lofving wrote:
> I was reading "The Linux Kernel" (
> 
http://metalab.unc.edu/LDP/LDP/tlk/tlk.html
 ) and, please correct me if
> I'm wrong, but as far as I understood the mm part of tlk, linux only
> reads the size of one memory page from an executable file when it is
> run, and then, each time more of  the file needs to be read from the
> hard drive, only one page at a time will be read.
> It struck me that reading for example 16kb at once is a lot faster than
> reading 4kb 4 times. So why not read 4 or 8 pages at every segfault (and
> when the program ? I am very uncertain about if this is a good idea or
> not, I understand that this would not be a good idea for systems with
> not so much memory, but will it not be a performance boost for systems
> that can "afford" this memory waste? Perhaps the number of pages that
> Linux should read at a time could be configurable at compile time or
> even when Linux is running through the /proc filesystem? Or perhaps the
> amount of pages read at a time could be decided by looking at the size
> of the executable? If this is just a very stupid idea please let me
> know, so that i can forget about it as soon as possible =)
Well, the executable is mmaped on execution, and on a pagefault, the handler
will ask the buffer cache code to give that page. The buffer cache however
is clever enough to read more than one page (4k) at a time, so it might
already have the needed page. Then we only need to add a page table entry
(minor pagefault), otherwise we have to read it from disk first (major
pagefault).
[That's the reason, why you are not allowed to change it on disk when it's
running, BTW]
There were some discussions about the readahead strategy of the buffer cache
when invoked by mmap some time ago on this list. It does much less readahead
than for normal file operations, which are assumed to be sequential.
For executables with a somewhat random access pattern, it seems to be quite
well not to readahead a lot, but some programs (like grep) use mmap to
sequentially read a file and are slower because of this.
Now, this is what I understood from the discussions here and there might be
I misunderstood something.
-- 
Kurt Garloff <kurt@garloff.de>                           [Dortmund, FRG]  
Plasma physics, high perf. computing              [Linux-ix86,-axp, DUX]
PGP key on 
http://www.garloff.de/kurt/
        [Linux SCSI driver: DC390]
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/