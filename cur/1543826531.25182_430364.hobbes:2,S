Date: Tue, 06 Jun 2006 13:28:59 +0400
From: Kirill Korotaev <>
Subject: Re: [ckrm-tech] [RFC 3/5] sched: Add CPU rate hard caps
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2006/6/6/55

>>>Yes but interactive admin processes will still get a large bonus
>>>relative to the apache processes so you can still log in and kill the
>>>apache storm off even with very large loads.
>>
>>And how do you plan to manage it: to log in every time when apache works
>>too much and kill processes? The managabiliy of such solutions sucks..
> 
> What a strange discussion. I simply impose limits on processes and connections 
> on my grossly underpowered server.
this works when you are an administrator of a single linux machine. Now 
imagine, you can run Virtual Environments (VE) each with it's own root 
and users. You can't and don't want to control what and how people are 
running. Sure, you limit the number of processes, but usually this won't 
be less then 50-100 processes per VE, so a single VE can lead to 50 
tasks in a running state and the total number of tasks in the system can 
be as high as 10,000. People can run setiathome or any other sh$t which 
consumes CPU, but the result is always the same - huge amount of running 
tasks leads to overall slowdown. So this is the case when you want to 
limits _users_ or VE, not _single_ tasks. I don't think you will succeed 
in managing 10,000 tasks when 100 active users change the load on the 
day basis.
Hope, it become more clear.
Thanks,
Kirill
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/