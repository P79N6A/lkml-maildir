Date: Fri, 3 Sep 1999 19:14:09 +0200 (CEST)
From: Andrea Arcangeli <>
Subject: Re: CONFIG_BIGMEM and rawio
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/9/3/93

On Fri, 3 Sep 1999, Stephen C. Tweedie wrote:
>the IO for write, after the IO for read.  Nobody else has to know.  We
>already implement bounce buffers underneath the ll_rw_block interface
>for some ISA devices and it works just fine.
If I understood well you want to do the copy of only of the current
req->bh and not of all the list of bh queued following the
req->bh->b_reqnext pointer. I think this because you said you need to do a
copy in the IO-completation callback.
So you are supposing that only the DMA lowlevel drivers are following
the b_reqnext pointer. The DMA ones are allowed to follow the b_reqnext
list because they don't need the bounce buffer thing in first place.
So if a driver not DMA driven will follow the link and will work on the
other bh then such driver will break badly with your buffer-bounce. It
doesn't seems a very robust design to me. Or maybe following the b_reqnext
list is explicitly allowed to DMA drivers and forbidden to not-DMA ones?
Basically to avoid this problem you should allocate a bounce buffers every
time a buffer gets queued in ll_rw_block in make_request. And what will
happens if you won't have enough memory? We are not used to fail in
ll_rw_block. If you'll wait some free memory you must think about all
possible new deadlock conditions.
Andrea
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/