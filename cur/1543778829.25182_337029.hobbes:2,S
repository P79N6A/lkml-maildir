Date: Thu, 28 Jul 2005 19:10:41 +0200
From: Eric Dumazet <>
Subject: [PATCH] x86_64 : prefetchw() can fall back to prefetch() if !3DNOW
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2005/7/28/249

[PATCH] x86_64 : prefetchw() can fall back to prefetch() if !3DNOW
If the cpu lacks 3DNOW feature, we can use a normal prefetcht0 instruction instead of NOP5.
"prefetchw (%rxx)" and "prefetcht0 (%rxx)" have the same length, ranging from 3 to 5 bytes
depending on the register. So this patch even helps AMD64, shortening the length of the code.
Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
--- linux-2.6.13-rc3/include/asm-x86_64/processor.h	2005-07-13 06:46:46.000000000 +0200
+++ linux-2.6.13-rc3-ed/include/asm-x86_64/processor.h	2005-07-28 18:47:39.000000000 +0200
@@ -398,7 +398,7 @@
 #define ARCH_HAS_PREFETCHW 1
 static inline void prefetchw(void *x) 
 { 
-	alternative_input(ASM_NOP5,
+	alternative_input("prefetcht0 (%1)",
 			  "prefetchw (%1)",
 			  X86_FEATURE_3DNOW,
 			  "r" (x));