Date: Mon, 31 Dec 2007 10:15:36 -0800
From: "H. Peter Anvin" <>
Subject: Re: asm-x86/msr.h for sanitized headers: clean it or punt it
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2007/12/31/102

Mike Frysinger wrote:
>> ---
> Use __asm__ and __volatile__ in code that is exported to userspace.  Wrap
> kernel functions with __KERNEL__ so they get scrubbed.
> 
> Signed-off-by: Mike Frysinger <vapier@gentoo.org>
> ---
> diff --git a/include/asm-x86/msr.h b/include/asm-x86/msr.h
> index ba4b314..ffb9319 100644
> --- a/include/asm-x86/msr.h
> +++ b/include/asm-x86/msr.h
> @@ -193,7 +193,7 @@ static inline int wrmsr_safe_on_cpu(unsigned int cpu, u32 msr_no, u32 l, u32 h)
> 
>  /* wrmsr with exception handling */
>  #define wrmsr_safe(msr,a,b) ({ int ret__;			\
> -	asm volatile("2: wrmsr ; xorl %0,%0\n"			\
> +	__asm__ __volatile__("2: wrmsr ; xorl %0,%0\n"			\
>  		     "1:\n\t"					\
>  		     ".section .fixup,\"ax\"\n\t"		\
>  		     "3:  movl %4,%0 ; jmp 1b\n\t"		\
rdmsr_safe/wrmsr_safe are definitely kernel-only.
	-hpa