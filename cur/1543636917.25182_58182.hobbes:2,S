Date: Sun, 21 Jul 2002 22:20:12 -0700
From: Andrew Morton <>
Subject: Re: [PATCH] low-latency zap_page_range
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2002/7/22/45

Pete Zaitcev wrote:
> 
> > The lock hold time in zap_page_range is horrid.  This patch breaks the
> > work up into chunks and relinquishes the lock after each iteration.
> > This drastically lowers latency by creating a preemption point, as well
> > as lowering lock contention.
> 
> >  void zap_page_range(struct vm_area_struct *vma, unsigned long address, unsigned long size)
> 
> Arjan sent me something similar, done by AKPM, only he did this a
> little differently. He added an argument to zap_page_range
> which allowed to work it in the old way, if set. Then, he set it so
> all places would use low latency EXCEPT a reading from /dev/zero.
> I assume it was some locking somewhere in devices/char/mem.c,
> though I was unable to figure which in particular.
> 
There are actually quite a few places in the ll patch which don't
pass ZPR_COND_RESCHED into zap_page_range.  Places which are
themselves called under locks, places where not enough pages
are being zapped to make it necessary, etc. vmtruncate_list,
some mremap code, others.
Plus some historical notes: there used to be a couple more
flags which could be passed into zap_page_range() to tell
it whether to run flush_cache_range and flush_tlb_range.  That
was an irrelevant cleanup.  But those calls were later unconditionally
sucked into zap_page_range() anyway.
-
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/