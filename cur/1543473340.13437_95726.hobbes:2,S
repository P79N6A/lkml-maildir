Date: Tue, 29 Dec 1998 06:39:41 -0500 (EST)
From: "Mark H. Wood" <>
Subject: Re: Reading few large blocks instead of many small when executing a file?
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1998/12/29/64

On Mon, 28 Dec 1998, Hans Lofving wrote:
> I was reading "The Linux Kernel" (
> 
http://metalab.unc.edu/LDP/LDP/tlk/tlk.html
 ) and, please correct me if
> I'm wrong, but as far as I understood the mm part of tlk, linux only
> reads the size of one memory page from an executable file when it is
> run, and then, each time more of  the file needs to be read from the
> hard drive, only one page at a time will be read.
> It struck me that reading for example 16kb at once is a lot faster than
> reading 4kb 4 times. So why not read 4 or 8 pages at every segfault (and
> when the program ? I am very uncertain about if this is a good idea or
> not, I understand that this would not be a good idea for systems with
> not so much memory, but will it not be a performance boost for systems
> that can "afford" this memory waste? Perhaps the number of pages that
> Linux should read at a time could be configurable at compile time or
> even when Linux is running through the /proc filesystem? Or perhaps the
> amount of pages read at a time could be decided by looking at the size
> of the executable? If this is just a very stupid idea please let me
> know, so that i can forget about it as soon as possible =)
Not stupid at all, though its value might be affected by other details of
Linux memory management.  Actually your description is so much like VMS
pagefault clustering that it's scary.  (The VAX architecture specifies
tiny 512-byte pages, so PFC is a real win on that hardware.  The factory
default on OpenVMS/VAX is 32 pages per fault.  The aXp architecture calls 
for page sizes between 4kB and 64kB so clustering is less needful there.
I don't know what the default cluster size is on an Alpha.)
IIRC the default cluster size is a SYSGEN parameter (somewhat like
/proc/sys/somethingorother) but another value can be set in the header of
an executable file at link time.  I think the per-image PFC size is one
of the least-used features of VMS, but someone will surely recall an
application if I say it could be omitted.
Since programs' memory use patterns differ, I think a good deal of
performance measurement would be required to determine whether clustering
actually helps enough to be worth the added complexity, and whether making
the cluster size tunable is worthwhile.  If we're reading 4kB/fault now
then there may not be much to be gained from clustering.
-- 
Mark H. Wood, Lead System Programmer   mwood@IUPUI.Edu
Innovation is only valuable if it improves one's life; otherwise it's
just one more silly change to cope with.
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/