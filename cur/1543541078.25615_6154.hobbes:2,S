Date: Wed, 9 Aug 2000 09:37:27 +1200
From: Chris Wedgwood <>
Subject: Re: can't mlockall() more than 128MB, is this a kernel limitation?
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/8/8/132

On Tue, Aug 08, 2000 at 01:10:36PM -0700, David Hinds wrote:
    Actually, since the present test is only done on the number of pages
    to be locked at the time of the system call, it is nearly worthless.
    You can already mlock more pages than the "limit": just do mlockall()
    with MCL_FUTURE, and allocate your big block of memory afterwards.
Long term we need to track this properly and send a signal to the
process as it grows... I actually like the idea of using ulimits for
locked pages so we can have soft and hard limits, it also means we
can allow idividual processes to lock one of two pages -- something
that can be very useful.
That said, we also need to make sure we have global settings, lest I
do something like:
	for(;;){
		mlock(buf,ps);
		if(fork())
			sleep(60);
		touch_me(buf,ps);	/* touch memory */
	}
and lock down gobs of memory
  --cw
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/