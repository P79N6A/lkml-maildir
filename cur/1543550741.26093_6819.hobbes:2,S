Date: Thu, 5 Oct 2000 09:39:34 +0200
From: Vojtech Pavlik <>
Subject: Re: Status of ReiserFS + Journalling
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/10/5/64

On Thu, Oct 05, 2000 at 01:54:59PM +1100, Neil Brown wrote:
> For RAID5 a 'stripe' is a set of blocks, one from each underlying
> device, which are all at the same offset within their device.
> For each stripe, one of the blocks is a "parity" block - though it is
> a different block for each stripe (parity is rotated).
> 
> Content of the parity block is computed from the xor of the content of
> all the other (data) blocks.
> 
> To update a data block, you must also update the parity block to keep
> it consistant.  For example, you can read old partity block, read old
> data block, compute
>    newparity = oldparity xor olddata xor newdata
> and then write out newparity and newdata.
> 
> It is not possible (on current hardware:-) to write both newparity and
> newdata to the different devices atomically.  If the system fails
> (e.g. power failure) between writing one and writing the other, then
> you have an inconsistant stripe.
Hmm, now that I think about it, this can be brought to data corruption
even easier ... Imagine a case where a stripe isn't written completely.
One of the drives (independently whether it's the xor one or one the
other one) has thus invalid data.
Now how do you decide, after boot, which drive of the set, including the
xor drive is it the one that contains the invalid data? I think this is
not possible.
So you're out of luck at a trivial power failure with RAID ...
-- 
Vojtech Pavlik
SuSE Labs
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
Please read the FAQ at 
http://www.tux.org/lkml/