Date: Fri, 24 Mar 2000 16:22:42 -0800
From: Linda Walsh <>
Subject: Re: Endless overcommit memory thread.
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/3/24/195

"Mike A. Harris" wrote:
> Can someone please explain to me how and why an app would
> allocate a large amount of memory and then not use it?  Please
> give specific examples since I can't fathom the reason.
---
    I'm running 'large app' -- uses 200M memory, 1M code, the rest data.  I have 256K memory and 128K swap.
Large app forks to do an exec of a shell.  Is the large app broken?  To not-overcommit you need to allocate 199M
memory (all data is writeable).  The app fails when obviously there is enough memory to run a shell.  But there
is no guarantee that large app is just going exec a shell.  It might be starting up another copy of 'large app'.  So
what do you do?  Overcommit and allow the 'sh', or just die.
    I think there should be a 2nd system call with semantics like 'vfork' or IRIX's sproc that explicitly allows
data segment sharing so only stack space needs to be allocated for the fork to work.  Current fork -- I lean
toward not overcommitting -- it seems more proper.
-linda
--
Linda Walsh @ SGI                | Core Linux - Trust Technology
1200 Crittenden Lane MS:30-3-802 | Voice: (650) 933-5338
Mountain View, CA 94043          | Email: law@sgi.com
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/