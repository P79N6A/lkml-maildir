Date: Fri, 3 Mar 2000 06:48:58 -0700
From:  yodaiken@chelm ...
Subject: Re: new IRQ scalability changes in 2.3.48
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/3/3/71

On Fri, Mar 03, 2000 at 03:25:23PM +0100, Ingo Molnar wrote:
> 
> On Fri, 3 Mar 2000 yodaiken@chelm.cs.nmt.edu wrote:
> 
> > On Sun, Feb 27, 2000 at 04:04:13PM +0100, Ingo Molnar wrote:
> > > 	- per-IRQ-source spinlocks and per-IRQ-controller spinlocks
> > > 	  increasing scalability: now two IRQ handlers on two CPUs
> > > 	  can run do_IRQ in parallel. Note that level-triggered PCI IRQ
> > > 	  handlers never actually take the IRQ-controller spinlock in the
> > > 	  'IRQ handling fast path'.
> > 
> > This change puts spinlock back into the low level irq code -- and I took 
> > them out specifically to make RTLinux work and to make Linus happy since
> > he was concerned about minimizing the number of spinlocks.  The 
> > "optimization" means that you can, in parallel run a tiny section of code
> > that is called infrequently -- [...]
> 
> it actually makes a huge difference as the _real_ optimization you missed
> is the lack of cacheline ping-pongs, which pingpong inevitably happens if
> globally shared spinlocks are used.
As in the spin lock in do_IRQ which is still there and now duplicated.
As far as I can see,  x86 now does
interrupt:
 do_IRQ
    spinlock desc->lock
    handler->ack
              spinlock again
The old code had a spinlock per controller, allowing for
parallel operation. The new code seems to simply duplicate 
spin locks.
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/