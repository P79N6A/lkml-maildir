Date: Thu, 27 Dec 2007 17:38:51 -0500
From: Loic Prylli <>
Subject: [PATCH] Fix x86 iounmap() calling ioremap_change_attr() with a size that's too big.
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2007/12/27/127

The get_vm_area() allocates one extra guard page, and stores the augmented
size in area->size. But the ioremap/iounmap code on x86 relies on finding
the original size in area->size (otherwise it does change the attribute
of some random device in the linear-map by using a wrong size in
ioremap_change_attr() ). The problem is avoided by not using an extra guard
page for VM_IOREMAP allocations (if somebody can think of an easy way to
store the original size across ioremap()/iounmap() calls, that could be
a more elegant solution).
Signed-off-by: Loic Prylli <loic@myri.com>
---
 mm/vmalloc.c |    5 +++--
 1 files changed, 3 insertions(+), 2 deletions(-)
diff --git a/mm/vmalloc.c b/mm/vmalloc.c
index af77e17..efd0093 100644
--- a/mm/vmalloc.c
+++ b/mm/vmalloc.c
@@ -196,9 +196,10 @@ static struct vm_struct *__get_vm_area_node(unsigned long size, unsigned long fl
 		return NULL;
 
 	/*
-	 * We always allocate a guard page.
+	 * We allocate a guard page (except for ioremap() which relies on area->size == size)
 	 */
-	size += PAGE_SIZE;
+	if (!(flags & VM_IOREMAP))
+	    size += PAGE_SIZE;
 
 	write_lock(&vmlist_lock);
 	for (p = &vmlist; (tmp = *p) != NULL ;p = &tmp->next) {
-- 
1.5.2.2