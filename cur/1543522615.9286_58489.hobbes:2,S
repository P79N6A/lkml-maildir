Date: Tue, 18 Jan 2000 23:31:20 -0600
From: Bill Wendling <>
Subject: Re: [patchp chunk-allocation in poll(2) (for nfds>1600 poll problem fix)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/1/19/78

Also sprach Tigran Aivazian:
}  
} -static int do_poll(unsigned int nfds, struct pollfd *fds, poll_table *wait,
} +#define POLL_PER_CHUNK	10000
} +#define POLL_NCHUNKS	16
} +
This seems to simply raise the bar of how many fds you can poll on, not
defeat the real problem which is that not enough memory can be allocated
to suffice the program...If you are going to do chunking, perhaps the
"linked list" approach is the best idea. It would have no "hard coded"
limits.
[...]
} +static int do_poll(unsigned int nfds, struct pollfd *fds[], poll_table *wait,
}  		   long timeout)
}  {
}  	int count = 0;
} +	int nchunks = nfds / POLL_PER_CHUNK;
} +	int nleft = nfds % POLL_PER_CHUNK;
Why recalculate these with "expensive" operations when you can pass them
in as parameters?
[...]
}  
}  	err = -ENOMEM;
} +	lock_kernel();
AFAIK, the locking only needs to be done for the do_poll() call. Is this
correct? Since you aren't doing a vmalloc() call, you might be able to
get away with moving this right before the do_poll() and the
unlock_kernel call right after it...
[...]
} +	nchunks = 0;
} +	nleft = nfds;
} +	while (nleft > POLL_PER_CHUNK) { /* allocate complete chunks */
This could be a for(nchunks = 0; nleft > POLL_PER_CHUNK; nchunks++)
loop...just a design issue :)
[...]
-- 
|| Bill Wendling			wendling@ganymede.isdn.uiuc.edu
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/