Date: Thu, 07 Apr 2005 03:11:12 +1000
From: Nick Piggin <>
Subject: Re: 2.6.12-rc2-mm1
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2005/4/6/143

Siddha, Suresh B wrote:
> On Tue, Apr 05, 2005 at 05:33:49PM +1000, Nick Piggin wrote:
> 
>>Lastly, I'd like to be a bit less intrusive with pinned task
>>handling improvements. I think we can do this while still being
>>effective in preventing livelocks.
> 
> 
> We want to see this fixed. Please post your patch and I can let you know
> the test results.
> 
Using the attached patch, a puny dual PIII-650 with ~400MB RAM swapped
itself to death after 20000 infinite loop tasks had been pinned to one
of the CPUs. See how you go.
-- 
SUSE Labs, Novell Inc.
Index: linux-2.6/kernel/sched.c
===================================================================
--- linux-2.6.orig/kernel/sched.c	2005-04-07 02:39:22.000000000 +1000
+++ linux-2.6/kernel/sched.c	2005-04-07 02:45:26.000000000 +1000
@@ -2041,6 +2041,12 @@ static runqueue_t *find_busiest_queue(st
 }
 
 /*
+ * Max backoff if we encounter pinned tasks. Pretty arbitrary value, but
+ * so long as it is large enough.
+ */
+#define MAX_PINNED_INTERVAL	1024
+
+/*
  * Check this_cpu to ensure it is balanced within domain. Attempt to move
  * tasks if there is an imbalance.
  *
@@ -2052,7 +2058,7 @@ static int load_balance(int this_cpu, ru
 	struct sched_group *group;
 	runqueue_t *busiest;
 	unsigned long imbalance;
-	int nr_moved, all_pinned;
+	int nr_moved, all_pinned = 0;
 	int active_balance = 0;
 
 	spin_lock(&this_rq->lock);
@@ -2143,7 +2149,8 @@ out_balanced:
 
 	sd->nr_balance_failed = 0;
 	/* tune up the balancing interval */
-	if (sd->balance_interval < sd->max_interval)
+	if ((all_pinned && sd->balance_interval < MAX_PINNED_INTERVAL) ||
+			(sd->balance_interval < sd->max_interval))
 		sd->balance_interval *= 2;
 
 	return 0;