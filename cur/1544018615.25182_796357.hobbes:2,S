Date: Sat, 24 Jan 2009 03:17:25 +1100
From: Nick Piggin <>
Subject: Re: [PATCH] SLUB: revert direct page allocator pass through
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2009/1/23/234

On Saturday 24 January 2009 02:59:17 Christoph Lameter wrote:
> On Sat, 24 Jan 2009, Nick Piggin wrote:
> > Page allocator is never going to be as fast as slab allocator, for
> > issues I explained a long time ago. Not to say it can't be improved,
> > just stating facts.
>
> Why not? Remember the discussion we had a while ago. You can bring the
> pages into a state where minimal manipulations are required for alloc free
> and avoid all the checks in the hot paths. The SLUB method could be used
> taking a big contiguous chunk and then issueing page size portions of it.
> That could be quite fast.
>
> Or if you prefer order-0. Do a single linked list like SLQB does.
The fundamental issues I guess are that slab pages are kernel mapped, and
within a given slab, the zone and movability are irrelevant.
Other ones which could be changed but could introduce regressions are
watermarks, buddy merging, and struct page error checking and setup.
I brought all this up when it was discussed. Did you find any ways to
improve anything?
(I did make that patch to enable refcounting to be avoided FWIW, which
avoids a couple of atomic operations, but I don't think it brought
performance up too much, but I still intend to dust it off at some
point).