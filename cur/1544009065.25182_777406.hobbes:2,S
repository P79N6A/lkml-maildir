Date: Fri, 5 Dec 2008 19:24:53 +0530
From: Balbir Singh <>
Subject: Re: [RFC][PATCH -mmotm 4/4] memcg: change try_to_free_pages to hierarchical_reclaim
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/12/5/171

* Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp> [2008-12-05 21:25:29]:
> mem_cgroup_hierarchicl_reclaim() works properly even when !use_hierarchy now,
> so, instead of try_to_free_mem_cgroup_pages(), it should be used in many cases.
>
Yes, that was by design. The design is such that use_hierarchy is set
for all children when the parent has it set and the resource counters
are also linked, such that the charge propagates to the root of the
current hierarchy and not any further.
> The only exception is force_empty. The group has no children in this case.
> 
> 
> Signed-off-by: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
> ---
>  mm/memcontrol.c |   12 ++++--------
>  1 files changed, 4 insertions(+), 8 deletions(-)
> 
> diff --git a/mm/memcontrol.c b/mm/memcontrol.c
> index ab04725..c0b4f37 100644
> --- a/mm/memcontrol.c
> +++ b/mm/memcontrol.c
> @@ -1399,8 +1399,7 @@ int mem_cgroup_shrink_usage(struct mm_struct *mm, gfp_t gfp_mask)
>  	rcu_read_unlock();
> 
>  	do {
> -		progress = try_to_free_mem_cgroup_pages(mem, gfp_mask, true,
> -							get_swappiness(mem));
> +		progress = mem_cgroup_hierarchical_reclaim(mem, gfp_mask, true);
>  		progress += mem_cgroup_check_under_limit(mem);
>  	} while (!progress && --retry);
> 
> @@ -1467,10 +1466,8 @@ static int mem_cgroup_resize_limit(struct mem_cgroup *memcg,
>  		if (!ret)
>  			break;
> 
> -		progress = try_to_free_mem_cgroup_pages(memcg,
> -							GFP_KERNEL,
> -							false,
> -							get_swappiness(memcg));
> +		progress = mem_cgroup_hierarchical_reclaim(memcg, GFP_KERNEL,
> +							   false);
>    		if (!progress)			retry_count--;
>  	}
> 
> @@ -1514,8 +1511,7 @@ int mem_cgroup_resize_memsw_limit(struct mem_cgroup *memcg,
>  			break;
> 
>  		oldusage = res_counter_read_u64(&memcg->memsw, RES_USAGE);
> -		try_to_free_mem_cgroup_pages(memcg, GFP_KERNEL, true,
> -					     get_swappiness(memcg));
> +		mem_cgroup_hierarchical_reclaim(memcg, GFP_KERNEL, true);
>  		curusage = res_counter_read_u64(&memcg->memsw, RES_USAGE);
>  		if (curusage >= oldusage)
>  			retry_count--;
> 
Looks good to me
Acked-by: Balbir Singh <balbir@linux.vnet.ibm.com>
-- 
	Balbir