Date: Thu, 18 May 2006 00:04:40 +1200
From: Reuben Farrelly <>
Subject: Re: [PATCH 000 of 3] md: Introduction - 3 bugfixs for -mm
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2006/5/17/83

On 16/05/2006 1:12 p.m., NeilBrown wrote:
> The first of these fixes issues with the new bmap based bitmap file
> access code, and possibly should be an -mm hotfix, and without it,
> 'internal' bitmaps don't work any more :-(
> 
> Others are minor and unrelated.
> 
> Thanks,
> NeilBrown
> 
> 
>  [PATCH 001 of 3] md: Change md/bitmap file handling to use bmap to file blocks-fix
>  [PATCH 002 of 3] md: Fix inverted test for 'repair' directive.
>  [PATCH 003 of 3] md: Calculate correct array size for raid10 in new offset mode.
Patch 1 fixes the problems I was having with RAID-1 arrays not able to start up 
on 2.6.17-rc4-mm1.  Thanks for that.
However things appear still not quite right on boot, as each mount works but 
displays as though it didn't work, ie:
md: considering sdc2 ...
md:  adding sdc2 ...
md:  adding sda2 ...
md: created md0
md: bind<sda2>
md: bind<sdc2>
md: running: <sdc2><sda2>
raid1: raid set md0 active with 0 out of 2 mirrors
0 out of 2 ?
cat /proc/mdstats  shows that everything does in fact seem to be working:
md0 : active raid1 sdc2[1] sda2[0]
       24410688 blocks [2/2] [UU]
       bitmap: 21/187 pages [84KB], 64KB chunk
The array otherwise seems to be fine.  I guess it's just a visual glitch.
reuben
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/