Date: Wed, 7 Apr 1999 15:49:36 -0400 (EDT)
From: Chuck Lever <>
Subject: [PFC]: hash instrumentation
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/4/7/127

[PFC] = patch for comments - not a bug fix or for general use
i've attached a diff to this message that contains the hash
instrumentation i'm using to analyze and improve hash functions.  i'd like
to instrument a couple of other hashes (dentry, inode, fib), and create a
new directory in /proc called /proc/cache, with files for each of the
important caches.  these may not contain the histogram information, since
it's just for testing, but they might contain important statistics about
hash performance, for example.
here's some sample output (from /var/log/messages) to show what
information you might be able to gather from the hash instrumentation:
for the page cache:
Apr  7 15:08:50 pillbox kernel: Total pages in hash: 4079  total buckets:
2048
Apr  7 15:08:50 pillbox kernel:  hash table histogram:
Apr  7 15:08:50 pillbox kernel:   size: 0   buckets: 379     pages: 0     
Apr  7 15:08:50 pillbox kernel:   size: 1   buckets: 462     pages: 462   
Apr  7 15:08:50 pillbox kernel:   size: 2   buckets: 507     pages: 1014  
Apr  7 15:08:50 pillbox kernel:   size: 3   buckets: 385     pages: 1155  
Apr  7 15:08:50 pillbox kernel:   size: 4   buckets: 178     pages: 712   
Apr  7 15:08:50 pillbox kernel:   size: 5   buckets: 94      pages: 470   
Apr  7 15:08:50 pillbox kernel:   size: 6   buckets: 36      pages: 216   
Apr  7 15:08:50 pillbox kernel:   size: 7   buckets: 6       pages: 42    
Apr  7 15:08:50 pillbox kernel:   size: 8   buckets: 1       pages: 8     
Apr  7 15:08:50 pillbox kernel:   size: 9   buckets: 0       pages: 0     
Apr  7 15:08:50 pillbox kernel:   size: 10  buckets: 0       pages: 0     
Apr  7 15:08:50 pillbox kernel:   size: 11  buckets: 0       pages: 0     
Apr  7 15:08:50 pillbox kernel:   size: 12  buckets: 0       pages: 0     
Apr  7 15:08:50 pillbox kernel:   size: 13  buckets: 0       pages: 0     
Apr  7 15:08:50 pillbox kernel:   size: 14  buckets: 0       pages: 0     
Apr  7 15:08:50 pillbox kernel:   size: 15  buckets: 0       pages: 0     
Apr  7 15:08:50 pillbox kernel:   size:>15  buckets: 0       pages: 0     
Apr  7 15:08:50 pillbox kernel: Max bucket size: 8
Apr  7 15:08:50 pillbox kernel: Total lookups: 58933  pages found: 52044
(hit rate: 88%)
Apr  7 15:08:50 pillbox kernel:  find_page loops: 53950  loops/lookup:
915/1000
notice that the bucket sizes are nicely distributed, and that most of the
buckets are used.  loops/lookup is really the number that matters here,
since it provides a good indication of how much average effort is required
to find a given page.  loops/lookup is the average number of times
__find_page (or find_buffer, below) had to loop during a lookup operation.
the histogram table is organized so that each row represents buckets of a
given size.  for instance, the row for empty buckets is "size:0" and the
number of buckets that were empty is 379.  the number of buckets that
contained only 2 pages is 507, and there were 1014 pages stored in buckets
that only contained 2 pages.  this allows us to clearly see the bucket
size distribution, and to easily tell when there are lots of large or
empty buckets (both bad situations).
here's the buffer cache:
Apr  7 15:08:50 pillbox kernel: total buffers in hash table: 2149
Apr  7 15:08:50 pillbox kernel:  total buckets: 32768  largest: 59
Apr  7 15:08:50 pillbox kernel:  times find_buffer looped: 53900
loops/lookup: 874/1000
Apr  7 15:08:50 pillbox kernel:  hash table histogram:
Apr  7 15:08:50 pillbox kernel:   size: 0   buckets: 31941   buffers: 0     
Apr  7 15:08:50 pillbox kernel:   size: 1   buckets: 648     buffers: 648   
Apr  7 15:08:50 pillbox kernel:   size: 2   buckets: 50      buffers: 100   
Apr  7 15:08:50 pillbox kernel:   size: 3   buckets: 26      buffers: 78    
Apr  7 15:08:50 pillbox kernel:   size: 4   buckets: 8       buffers: 32    
Apr  7 15:08:50 pillbox kernel:   size: 5   buckets: 16      buffers: 80    
Apr  7 15:08:50 pillbox kernel:   size: 6   buckets: 17      buffers: 102   
Apr  7 15:08:50 pillbox kernel:   size: 7   buckets: 18      buffers: 126   
Apr  7 15:08:50 pillbox kernel:   size: 8   buckets: 12      buffers: 96    
Apr  7 15:08:50 pillbox kernel:   size: 9   buckets: 3       buffers: 27    
Apr  7 15:08:50 pillbox kernel:   size: 10  buckets: 5       buffers: 50    
Apr  7 15:08:50 pillbox kernel:   size: 11  buckets: 4       buffers: 44    
Apr  7 15:08:50 pillbox kernel:   size: 12  buckets: 1       buffers: 12    
Apr  7 15:08:50 pillbox kernel:   size: 13  buckets: 0       buffers: 0     
Apr  7 15:08:50 pillbox kernel:   size: 14  buckets: 2       buffers: 28    
Apr  7 15:08:50 pillbox kernel:   size: 15  buckets: 0       buffers: 0     
Apr  7 15:08:50 pillbox kernel:   size:>15  buckets: 17      buffers: 726
the buffer hash function doesn't work well: bucket sizes are not nicely
distributed, there is a huge number of empty buckets, and there are more
than a few buckets that contain lots of buffers.  this is just after the
system was booted, but after some file system intensive activity, we have
this:
page hash:
Apr  7 15:36:20 pillbox kernel: Total pages in hash: 21854  total buckets:
2048
Apr  7 15:36:20 pillbox kernel:  hash table histogram:
Apr  7 15:36:20 pillbox kernel:   size: 0   buckets: 0       pages: 0     
Apr  7 15:36:20 pillbox kernel:   size: 1   buckets: 0       pages: 0     
Apr  7 15:36:20 pillbox kernel:   size: 2   buckets: 3       pages: 6     
Apr  7 15:36:20 pillbox kernel:   size: 3   buckets: 4       pages: 12    
Apr  7 15:36:20 pillbox kernel:   size: 4   buckets: 20      pages: 80    
Apr  7 15:36:20 pillbox kernel:   size: 5   buckets: 60      pages: 300   
Apr  7 15:36:20 pillbox kernel:   size: 6   buckets: 76      pages: 456   
Apr  7 15:36:20 pillbox kernel:   size: 7   buckets: 131     pages: 917   
Apr  7 15:36:20 pillbox kernel:   size: 8   buckets: 198     pages: 1584  
Apr  7 15:36:20 pillbox kernel:   size: 9   buckets: 247     pages: 2223  
Apr  7 15:36:20 pillbox kernel:   size: 10  buckets: 261     pages: 2610  
Apr  7 15:36:20 pillbox kernel:   size: 11  buckets: 284     pages: 3124  
Apr  7 15:36:20 pillbox kernel:   size: 12  buckets: 224     pages: 2688  
Apr  7 15:36:20 pillbox kernel:   size: 13  buckets: 185     pages: 2405  
Apr  7 15:36:20 pillbox kernel:   size: 14  buckets: 148     pages: 2072  
Apr  7 15:36:20 pillbox kernel:   size: 15  buckets: 82      pages: 1230  
Apr  7 15:36:20 pillbox kernel:   size:>15  buckets: 125     pages: 1427  
Apr  7 15:36:20 pillbox kernel: Max bucket size: 22
Apr  7 15:36:20 pillbox kernel: Total lookups: 5129003  pages found:
4590496  (hit rate: 89%)
Apr  7 15:36:20 pillbox kernel:  find_page loops: 28371900  loops/lookup:
507/1000
the loops/lookup is pretty low (less than one is good) and the hash
distribution is still nicely shaped.  it's clear that the hash table is
too small, though.  for buffers:
Apr  7 15:36:20 pillbox kernel: total buffers in hash table: 1767
Apr  7 15:36:20 pillbox kernel:  total buckets: 32768  largest: 25
Apr  7 15:36:20 pillbox kernel:  times find_buffer looped: 2314427
loops/lookup: 1078/1000
Apr  7 15:36:20 pillbox kernel:  hash table histogram:
Apr  7 15:36:20 pillbox kernel:   size: 0   buckets: 31866   buffers: 0     
Apr  7 15:36:20 pillbox kernel:   size: 1   buckets: 687     buffers: 687   
Apr  7 15:36:20 pillbox kernel:   size: 2   buckets: 109     buffers: 218   
Apr  7 15:36:20 pillbox kernel:   size: 3   buckets: 19      buffers: 57    
Apr  7 15:36:20 pillbox kernel:   size: 4   buckets: 11      buffers: 44    
Apr  7 15:36:20 pillbox kernel:   size: 5   buckets: 15      buffers: 75    
Apr  7 15:36:20 pillbox kernel:   size: 6   buckets: 9       buffers: 54    
Apr  7 15:36:20 pillbox kernel:   size: 7   buckets: 9       buffers: 63    
Apr  7 15:36:20 pillbox kernel:   size: 8   buckets: 4       buffers: 32    
Apr  7 15:36:20 pillbox kernel:   size: 9   buckets: 7       buffers: 63    
Apr  7 15:36:20 pillbox kernel:   size: 10  buckets: 4       buffers: 40    
Apr  7 15:36:20 pillbox kernel:   size: 11  buckets: 5       buffers: 55    
Apr  7 15:36:20 pillbox kernel:   size: 12  buckets: 4       buffers: 48    
Apr  7 15:36:20 pillbox kernel:   size: 13  buckets: 6       buffers: 78    
Apr  7 15:36:20 pillbox kernel:   size: 14  buckets: 1       buffers: 14    
Apr  7 15:36:20 pillbox kernel:   size: 15  buckets: 1       buffers: 15    
Apr  7 15:36:20 pillbox kernel:   size:>15  buckets: 11      buffers: 224
for buffers the story is quite different.  there's still a huge number of
empty buckets, and the size distribution is practically flat.
loops/lookup is greater than one.
	- Chuck Lever
--
corporate:	<chuckl@netscape.com>
personal:	<chucklever@netscape.net> or <cel@monkey.org>
The Linux Scalability project:
	
http://www.citi.umich.edu/projects/citi-netscape/
diff -ruN linux-2.2.5-reference/arch/i386/mm/init.c linux/arch/i386/mm/init.c
--- linux-2.2.5-reference/arch/i386/mm/init.c	Thu Jan 21 14:28:40 1999
+++ linux/arch/i386/mm/init.c	Wed Apr  7 12:49:43 1999
@@ -17,6 +17,7 @@
 #include <linux/swap.h>
 #include <linux/smp.h>
 #include <linux/init.h>
+#include <linux/pagemap.h>
 #ifdef CONFIG_BLK_DEV_INITRD
 #include <linux/blk.h>
 #endif
@@ -169,6 +170,7 @@
 	printk("%d pages shared\n",shared);
 	printk("%d pages swap cached\n",cached);
 	printk("%ld pages in page table cache\n",pgtable_cache_size);
+	show_page_hash();
 	show_buffers();
 #ifdef CONFIG_NET
 	show_net_buffers();
diff -ruN linux-2.2.5-reference/fs/buffer.c linux/fs/buffer.c
--- linux-2.2.5-reference/fs/buffer.c	Mon Mar 29 21:36:19 1999
+++ linux/fs/buffer.c	Wed Apr  7 15:11:18 1999
@@ -115,6 +115,29 @@
 int bdflush_min[N_PARAM] = {  0,  10,    5,   25,  0,   1*HZ,   1*HZ, 1, 1};
 int bdflush_max[N_PARAM] = {100,5000, 2000, 2000,100, 600*HZ, 600*HZ, 2047, 5};
 
+/* align the next struct */
+__asm__ ("       .align 16\n");
+
+struct totals {
+	unsigned long lookups;
+	unsigned long hits;
+	unsigned long fb_loops;
+	unsigned long ndirty_written;
+	unsigned long bdflush;
+	unsigned long bdflush_wait;
+	unsigned long wait_on_buffer;
+	unsigned long refills;
+	unsigned long grow_buffers;
+	unsigned long free_buffers;
+	unsigned long forgotten;
+	unsigned long freed_pages;
+	unsigned long breads; 
+	unsigned long breadas;
+	unsigned long readpage;
+	unsigned long brw_page;
+	unsigned long brw_read;
+} buffer_counters = {0, };
+
 void wakeup_bdflush(int);
 
 /*
@@ -131,6 +154,7 @@
 	struct task_struct *tsk = current;
 	struct wait_queue wait;
 
+	buffer_counters.wait_on_buffer++;
 	bh->b_count++;
 	wait.task = tsk;
 	add_wait_queue(&bh->b_wait, &wait);
@@ -220,6 +244,7 @@
 			bh->b_count++;
 			next->b_count++;
 			bh->b_flushtime = 0;
+			buffer_counters.ndirty_written++;
 			ll_rw_block(WRITE, 1, &bh);
 			bh->b_count--;
 			next->b_count--;
@@ -578,17 +603,20 @@
 {		
 	struct buffer_head * next;
 
+	buffer_counters.lookups++;
 	next = hash(dev,block);
 	for (;;) {
 		struct buffer_head *tmp = next;
 		if (!next)
-			break;
+			return next;
+		buffer_counters.fb_loops++;
 		next = tmp->b_next;
 		if (tmp->b_blocknr != block || tmp->b_size != size || tmp->b_dev != dev)
 			continue;
 		next = tmp;
 		break;
 	}
+	buffer_counters.hits++;
 	return next;
 }
 
@@ -853,6 +881,7 @@
 		__brelse(buf);
 		return;
 	}
+	buffer_counters.forgotten++;
 	buf->b_count = 0;
 	remove_from_queues(buf);
 	put_last_free(buf);
@@ -866,6 +895,7 @@
 {
 	struct buffer_head * bh;
 
+	buffer_counters.breads++;
 	bh = getblk(dev, block, size);
 	touch_buffer(bh);
 	if (buffer_uptodate(bh))
@@ -901,6 +931,7 @@
 	if (block < 0)
 		return NULL;
 
+	buffer_counters.breadas++;
 	bh = getblk(dev, block, bufsize);
 	index = BUFSIZE_INDEX(bh->b_size);
 
@@ -1243,6 +1274,10 @@
 	struct buffer_head *bh, *prev, *next, *arr[MAX_BUF_PER_PAGE];
 	int block, nr;
 
+	buffer_counters.brw_page++;
+	if (rw == READ)
+		buffer_counters.brw_read++;
+
 	if (!PageLocked(page))
 		panic("brw_page: page not locked for I/O");
 	clear_bit(PG_uptodate, &page->flags);
@@ -1359,6 +1394,7 @@
 	int *p, nr[PAGE_SIZE/512];
 	int i;
 
+	buffer_counters.readpage++;
 	atomic_inc(&page->count);
 	set_bit(PG_locked, &page->flags);
 	set_bit(PG_free_after, &page->flags);
@@ -1396,6 +1432,7 @@
 
 	if (!(page = __get_free_page(GFP_BUFFER)))
 		return 0;
+	buffer_counters.grow_buffers++;
 	bh = create_buffers(page, size, 0);
 	if (!bh) {
 		free_page(page);
@@ -1459,6 +1496,7 @@
 		return 0;
 	} while (tmp != bh);
 
+	buffer_counters.free_buffers++;
 	tmp = bh;
 	do {
 		struct buffer_head * p = tmp;
@@ -1472,6 +1510,7 @@
 	wake_up(&buffer_wait);
 
 	/* And free the page */
+	buffer_counters.freed_pages++;
 	buffermem -= PAGE_SIZE;
 	page_map->buffers = NULL;
 	__free_page(page_map);
@@ -1480,12 +1519,16 @@
 
 /* ================== Debugging =================== */
 
+#define HISTOGRAM_MAX 16
+
 void show_buffers(void)
 {
 	struct buffer_head * bh;
 	int found = 0, locked = 0, dirty = 0, used = 0, lastused = 0;
 	int protected = 0;
-	int nlist;
+	int nlist, nsize;
+	int max, maxsum;
+	unsigned hist[HISTOGRAM_MAX+1];
 	static char *buf_types[NR_LIST] = {"CLEAN","LOCKED","DIRTY"};
 
 	printk("Buffer memory:   %6dkB\n",buffermem>>10);
@@ -1493,6 +1536,68 @@
 	printk("Buffer blocks:   %6d\n",nr_buffers);
 	printk("Buffer hashed:   %6d\n",nr_hashed_buffers);
 
+	printk("cache hit rate: %d%% (%ld hits in %ld lookups)\n",
+		(unsigned) ((buffer_counters.hits * 100)/buffer_counters.lookups),
+		buffer_counters.hits, buffer_counters.lookups);
+	printk("total buffers flushed: %ld  forgotten: %ld\n",
+		buffer_counters.ndirty_written, buffer_counters.forgotten);
+	printk("bdflush runs: %ld  times we waited for it: %ld\n",
+		buffer_counters.bdflush, buffer_counters.bdflush_wait);
+	printk("total waits for a buffer: %ld\n",
+		buffer_counters.wait_on_buffer);
+	printk("requests to grow/shrink buffer cache: %ld/%ld\n",
+		buffer_counters.grow_buffers, buffer_counters.free_buffers);
+	printk("pages freed during shrink requests: %ld\n",
+		buffer_counters.freed_pages);
+	printk("free list refills: %ld\n", buffer_counters.refills);
+
+	printk("bread() calls: %ld  breada() calls: %ld\n",
+	buffer_counters.breads, buffer_counters.breadas);
+	printk("generic_readpage calls: %ld\n",
+		buffer_counters.readpage);
+	printk("brw_page() calls: %ld  read/write: %ld/%ld\n",
+		buffer_counters.brw_page, buffer_counters.brw_read,
+		(buffer_counters.brw_page - buffer_counters.brw_read));
+
+	for (nlist=0; nlist <= HISTOGRAM_MAX; nlist++)
+	  hist[nlist] = 0;
+	found = 0;
+	max = 0;
+	maxsum = 0;
+	for(nlist = 0; nlist <= bh_hash_mask; nlist++) {
+	  bh = hash_table[nlist];
+	  if (!bh) {
+		hist[0]++;
+		continue;
+	  }
+
+	  used = 0;
+	  do {
+		found++;
+		used++;
+		bh = bh->b_next;
+	  } while (bh);
+	  if (max < used) max = used;
+	  if (used < HISTOGRAM_MAX)
+		hist[used]++;
+	  else {
+		maxsum += used;
+		hist[HISTOGRAM_MAX]++;
+	  }
+	}
+	printk("total buffers in hash table: %d\n", found);
+	printk(" total buckets: %ld  largest: %d\n",
+	bh_hash_mask+1, max);
+	printk(" times find_buffer looped: %ld  loops/lookup: %ld/1000\n",
+		buffer_counters.fb_loops,
+		(buffer_counters.fb_loops * 1000) / buffer_counters.lookups);
+	printk(" hash table histogram:\n");
+	for (nlist = 0; nlist < HISTOGRAM_MAX; nlist++)
+	  printk("  size: %-2d  buckets: %-6d  buffers: %-6d\n",
+			nlist, hist[nlist], nlist*hist[nlist]);
+	printk("  size:>%-2d  buckets: %-6d  buffers: %-6d\n",
+			HISTOGRAM_MAX-1, hist[HISTOGRAM_MAX], maxsum);
+
 	for(nlist = 0; nlist < NR_LIST; nlist++) {
 	  found = locked = dirty = used = lastused = protected = 0;
 	  bh = lru_list[nlist];
@@ -1514,7 +1619,19 @@
 		 "%d locked, %d protected, %d dirty\n",
 		 buf_types[nlist], found, used, lastused,
 		 locked, protected, dirty);
-	};
+	}
+
+	for(nsize = 0; nsize < NR_SIZES; nsize++) {
+	  found = 0;
+	  bh = free_list[nsize];
+	  if(!bh) continue;
+
+	  do {
+		found++;
+		bh = bh->b_next_free;
+	  } while (bh != free_list[nsize]);
+	  printk("    FREE: %d %d-byte buffers\n", found, (nsize+1)<<9);
+	}
 }
 
 
@@ -1576,6 +1693,7 @@
 {
 	if (current == bdflush_tsk)
 		return;
+	if (wait) buffer_counters.bdflush_wait++;
 	wake_up(&bdflush_wait);
 	if (wait) {
 		run_task_queue(&tq_disk);
@@ -1649,6 +1767,7 @@
 #ifdef DEBUG
 				 if(nlist != BUF_DIRTY) ncount++;
 #endif
+				 buffer_counters.ndirty_written++;
 				 ll_rw_block(WRITE, 1, &bh);
 				 bh->b_count--;
 				 next->b_count--;
@@ -1753,6 +1872,7 @@
 #ifdef DEBUG
 		printk("bdflush() activated...");
 #endif
+		buffer_counters.bdflush++;
 
 		CHECK_EMERGENCY_SYNC
 
@@ -1798,6 +1918,7 @@
 					  next->b_count++;
 					  bh->b_count++;
 					  ndirty++;
+					  buffer_counters.ndirty_written++;
 					  bh->b_flushtime = 0;
 					  if (major == LOOP_MAJOR) {
 						  ll_rw_block(wrta_cmd,1, &bh);
diff -ruN linux-2.2.5-reference/include/linux/pagemap.h linux/include/linux/pagemap.h
--- linux-2.2.5-reference/include/linux/pagemap.h	Mon Mar 29 21:45:07 1999
+++ linux/include/linux/pagemap.h	Wed Apr  7 13:12:04 1999
@@ -24,6 +24,11 @@
 
 extern unsigned long page_cache_size; /* # of pages currently in the hash table */
 extern struct page * page_hash_table[PAGE_HASH_SIZE];
+extern unsigned long page_cache_lookups;
+extern unsigned long page_cache_loops;
+extern unsigned long page_cache_hits;
+
+extern void show_page_hash(void);
 
 /*
  * We use a power-of-two hash table to avoid a modulus,
@@ -46,9 +51,11 @@
 
 static inline struct page * __find_page(struct inode * inode, unsigned long offset, struct page *page)
 {
+	page_cache_lookups++;
 	goto inside;
 	for (;;) {
 		page = page->next_hash;
+		page_cache_loops++;
 inside:
 		if (!page)
 			goto not_found;
@@ -58,6 +65,7 @@
 			break;
 	}
 	/* Found the page. */
+	page_cache_hits++;
 	atomic_inc(&page->count);
 	set_bit(PG_referenced, &page->flags);
 not_found:
diff -ruN linux-2.2.5-reference/mm/filemap.c linux/mm/filemap.c
--- linux-2.2.5-reference/mm/filemap.c	Mon Mar 29 21:36:08 1999
+++ linux/mm/filemap.c	Wed Apr  7 15:04:21 1999
@@ -33,6 +33,57 @@
 
 unsigned long page_cache_size = 0;
 struct page * page_hash_table[PAGE_HASH_SIZE];
+unsigned long page_cache_lookups = 0;
+unsigned long page_cache_loops = 0;
+unsigned long page_cache_hits = 0;
+
+#define HIST_SIZE 16
+
+void show_page_hash(void)
+{
+	unsigned bucket, index;
+	unsigned long count, max, total, oversized;
+	unsigned long hist[HIST_SIZE+1];
+	struct page * p;
+
+	max = 0;
+	total = 0;
+	oversized = 0;
+	for (index=0; index<=HIST_SIZE; index++) hist[index] = 0;
+	for (bucket=0; bucket<PAGE_HASH_SIZE; bucket++) {
+		count = 0;
+		p = page_hash_table[bucket];
+		while (p) {
+			count++;
+			total++;
+			p = p->next_hash;
+		}
+		if (count > max)
+			max = count;
+		if (count > HIST_SIZE) {
+			oversized += count;
+			count = HIST_SIZE;
+		}
+		hist[count]++;
+	}
+
+	printk("Total pages in hash: %lu  total buckets: %d\n",
+		total, bucket);
+	printk(" hash table histogram:\n");
+	for (index=0; index<HIST_SIZE; index++) {
+		printk("  size: %-2d  buckets: %-6lu  pages: %-6lu\n",
+			index, hist[index], index * hist[index]);
+	}
+	printk("  size:>%-2d  buckets: %-6lu  pages: %-6lu\n",
+		index-1, hist[index], oversized);
+	printk("Max bucket size: %lu\n", max);
+	printk("Total lookups: %lu  pages found: %lu  (hit rate: %d%%)\n",
+		page_cache_lookups, page_cache_hits,
+		(unsigned) ((page_cache_hits * 100UL) / page_cache_lookups));
+	printk(" find_page loops: %lu  loops/lookup: %lu/1000\n",
+		page_cache_loops,
+		((page_cache_loops * 1000UL) / page_cache_lookups));
+}
 
 /*
  * Simple routines for both non-shared and shared mappings.