Date: Fri, 19 Feb 1999 13:19:07 +0100 (CET)
From: Ingo Molnar <>
Subject: Re: 2.2.1 scheduler behavior
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/2/19/40

On 18 Feb 1999, Claude Gamache wrote:
> We have an application made up of 15 processes that interact through
> shared memories and sockets. Each process computes for a few
> milliseconds and then pass its data to the next one (a pipeline
> computation scheme). When a process is done with its computation, it
> calls pause() to release the CPU, it resumes its computation when its
> timer interrupt wakes it every 10 milliseconds, if the computation
> were not completed, we log this as an overrun.
could you try the attached patch? It's a fixed/cleaned up version of Paul
Campbell <paul@chromatic.com>'s 2.2.0 patch, with this patch we
immediately send signal events to other CPUs too. It's against recent
2.2.[01] kernels.
-- mingo
--- linux/kernel/signal.c.orig	Tue Dec 29 16:37:02 1998
+++ linux/kernel/signal.c	Fri Feb 19 13:14:20 1999
@@ -363,8 +363,27 @@
 	}
 
 	sigaddset(&t->signal, sig);
-	if (!sigismember(&t->blocked, sig))
+	if (!sigismember(&t->blocked, sig)) {
 		t->sigpending = 1;
+#ifdef __SMP__
+		/*
+		 * If the task is running on a different CPU 
+		 * force a reschedule on the other CPU - note that
+		 * the code below is a tad loose and might occasionally
+		 * kick the wrong CPU if we catch the process in the
+		 * process of changing - but no harm is done by that
+		 * other than doing an extra (lightweight) IPI interrupt.
+		 *
+		 * note that we rely on the previous spin_lock to
+		 * lock interrupts for us! No need to set need_resched
+		 * since signal event passing goes through ->blocked.
+		 */
+		spin_lock(&runqueue_lock);
+		if (t->has_cpu && t->processor != smp_processor_id())
+			smp_send_reschedule(t->processor);
+		spin_unlock(&runqueue_lock);
+#endif /* __SMP__ */
+	}
 
 out:
 	spin_unlock_irqrestore(&t->sigmask_lock, flags);
--- linux/include/linux/sched.h.orig	Fri Feb 19 13:07:51 1999
+++ linux/include/linux/sched.h	Fri Feb 19 13:08:38 1999
@@ -112,6 +112,7 @@
  * a separate lock).
  */
 extern rwlock_t tasklist_lock;
+extern spinlock_t runqueue_lock;
 extern spinlock_t scheduler_lock;
 
 extern void sched_init(void);
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/