Date: Fri, 18 Apr 2003 10:31:20 -0400
From: Timothy Miller <>
Subject: Re: [BK+PATCH] remove __constant_memcpy
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2003/4/18/63

Jeff Garzik wrote:
[snip]
>-		case 20:
>-			*(unsigned long *)to = *(const unsigned long *)from;
>-			*(1+(unsigned long *)to) = *(1+(const unsigned long *)from);
>-			*(2+(unsigned long *)to) = *(2+(const unsigned long *)from);
>-			*(3+(unsigned long *)to) = *(3+(const unsigned long *)from);
>-			*(4+(unsigned long *)to) = *(4+(const unsigned long *)from);
>-			return to;
>-	}
>+	if (n <= 128)
>+		return __builtin_memcpy(to, from, n);
>+
> #define COMMON(x) \
> __asm__ __volatile__( \
> 	"rep ; movsl" \
> 
>
Ignorant questions since I haven't been following the discussion:  Does 
this work with unaligned copies?  Does it work well?  What's better, 
letting the CPU do realignment, or writing the code to do bit shifts so 
that both reads and writes are aligned?
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/