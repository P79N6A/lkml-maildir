Date: Tue, 11 Mar 2008 08:07:34 +0300
From: Alexey Dobriyan <>
Subject: Re: [patch 1/2] x86, fpu: split FPU state from task struct - v5
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/3/11/29

On Mon, Mar 10, 2008 at 03:28:04PM -0700, Suresh Siddha wrote:
> Split the FPU save area from the task struct. This allows easy migration
> of FPU context, and it's generally cleaner. It also allows the following
> two optimizations:
> 
> 1) only allocate when the application actually uses FPU, so in the first
> lazy FPU trap. This could save memory for non-fpu using apps. Next patch
> does this lazy allocation.
> 
> 2) allocate the right size for the actual cpu rather than 512 bytes always.
> Patches enabling xsave/xrstor support (coming shortly) will take advantage
> of this.
Ugh, not seeing patch, but judging from description it will make
"choose wrong CONFIG_M* and fxsave will corrupt random FPU state" situation
likely?
> --- linux-2.6-x86.orig/arch/x86/kernel/process_64.c
> +++ linux-2.6-x86/arch/x86/kernel/process_64.c
> @@ -634,7 +634,7 @@
> 
>  	/* we're going to use this soon, after a few expensive things */
>  	if (next_p->fpu_counter>5)
> -		prefetch(&next->i387.fxsave);
> +		prefetch(next->xstate);
Can we please give it better name, like fpu_state? It's a member of
task_struct after all.
> --- linux-2.6-x86.orig/arch/x86/kernel/traps_64.c
> +++ linux-2.6-x86/arch/x86/kernel/traps_64.c
> @@ -1157,6 +1157,10 @@
>  #endif
> 
>  	/*
> +	 * initialize the per thread extended state:
> +	 */
> +        init_thread_xstate();
Useless comment after xstate renaming :)
> --- linux-2.6-x86.orig/kernel/fork.c
> +++ linux-2.6-x86/kernel/fork.c
> @@ -144,6 +148,9 @@
>  			ARCH_MIN_TASKALIGN, SLAB_PANIC | SLAB_NOTRACK, NULL);
>  #endif
> 
> +	/* do the arch specific task caches init */
> +	arch_task_cache_init();
Useless comment.
> --- linux-2.6-x86.orig/arch/x86/kernel/i387.c	2008-03-07 10:24:09.000000000 -0800
> +++ linux-2.6-x86/arch/x86/kernel/i387.c	2008-03-10 10:42:04.000000000 -0700
> @@ -61,10 +74,6 @@
>  void __cpuinit fpu_init(void)
>  {
>  	unsigned long oldcr0 = read_cr0();
> -	extern void __bad_fxsave_alignment(void);
> -
> -	if (offsetof(struct task_struct, thread.i387.fxsave) & 15)
> -		__bad_fxsave_alignment();
I think removal of such checks needs giving necessary alignment to cache.
Previously it worked because of __aligned((16)) and L1_CACHE_SHIFT
combo.
> Index: linux-2.6-x86/include/asm-x86/i387.h
> ===================================================================
> --- linux-2.6-x86.orig/include/asm-x86/i387.h	2008-03-07 10:24:11.000000000 -0800
> +++ linux-2.6-x86/include/asm-x86/i387.h	2008-03-10 10:42:04.000000000 -0700
> @@ -324,25 +323,25 @@
>  static inline unsigned short get_fpu_cwd(struct task_struct *tsk)
>  {
>  	if (cpu_has_fxsr) {
> -		return tsk->thread.i387.fxsave.cwd;
> +		return tsk->thread.xstate->fxsave.cwd;
>  	} else {
> -		return (unsigned short)tsk->thread.i387.fsave.cwd;
> +		return (unsigned short) tsk->thread.xstate->fsave.cwd;
				      ^^^
>  	}
>  }
> 
>  static inline unsigned short get_fpu_swd(struct task_struct *tsk)
>  {
>  	if (cpu_has_fxsr) {
> -		return tsk->thread.i387.fxsave.swd;
> +		return tsk->thread.xstate->fxsave.swd;
>  	} else {
> -		return (unsigned short)tsk->thread.i387.fsave.swd;
> +		return (unsigned short) tsk->thread.xstate->fsave.swd;
				      ^^^
> --- linux-2.6-x86.orig/include/asm-x86/processor.h	2008-03-07 10:24:11.000000000 -0800
> +++ linux-2.6-x86/include/asm-x86/processor.h	2008-03-10 10:42:04.000000000 -0700
> @@ -355,7 +355,7 @@
>  	u32			entry_eip;
>  };
> 
> -union i387_union {
> +union thread_xstate {
thread_fpu_state.
> Index: linux-2.6-x86/arch/x86/kernel/process.c
> ===================================================================
> --- /dev/null	1970-01-01 00:00:00.000000000 +0000
> +++ linux-2.6-x86/arch/x86/kernel/process.c	2008-03-10 10:42:04.000000000 -0700
> +void free_thread_info(struct thread_info *ti)
> +{
> +	kmem_cache_free(task_xstate_cachep, ti->task->thread.xstate);
> +	ti->task->thread.xstate = NULL;
> +
> +	free_pages((unsigned long)(ti), get_order(THREAD_SIZE));
Uselesss ()			  ^  ^