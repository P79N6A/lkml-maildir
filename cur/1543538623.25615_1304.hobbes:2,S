Date: Tue, 11 Jul 2000 19:01:19 +1000
From: Andrew Morton <>
Subject: Re: [linux-audio-dev] lowish-latency patch and toolchain
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/7/11/27

Juhana Sadeharju wrote:
> 
> Now the latency jumped from 2.3 ms to 7 ms
7 ms was when starting the X server.
With "typical workloads" I'm currently showing the following latency
distribution:
0-1 msec    99.994%
1-2 msec     0.003%
2-3 msec     0.002%
4-5 msec     0.001%
This is with the previously-posted six conditional_schedule()s and a
kinder, gentler zap_page_range().
Progress is currently bogged down chasing irrelevant bogosity in the
memory manager.  Unless magic happens I'll shelve that and get something
less ambitious out.
But audio guys, please comprehend this: there is _no point_ in
submitting this work for inclusion unless you can stand in front of
Linus with your hands on your hearts and say "This works for us".
I am quite mystified as to why you're putting so much effort into joint
letters and such, and so little into testing a purported solution.  I've
had two emails which said "cool for me", an apology from Paul B-D who is
travelling and that's all.
For your convenience I have attached here Saturday's patch against
2.4.0-test3-pre4.  Go compile.--- linux-2.4.0-test3-pre4/mm/filemap.c	Thu Jul  6 20:23:47 2000
+++ linux-akpm/mm/filemap.c	Sat Jul  8 14:33:54 2000
@@ -160,6 +160,7 @@
 	start = (lstart + PAGE_CACHE_SIZE - 1) >> PAGE_CACHE_SHIFT;
 
 repeat:
+	conditional_schedule();		/* sys_unlink() */
 	head = &mapping->pages;
 	spin_lock(&pagecache_lock);
 	curr = head->next;
@@ -450,6 +451,7 @@
 
 		page_cache_get(page);
 		spin_unlock(&pagecache_lock);
+		conditional_schedule();		/* sys_sync() */
 		lock_page(page);
 
 		/* The buffers could have been free'd while we waited for the page lock */
@@ -1081,6 +1083,8 @@
 		 * "pos" here (the actor routine has to update the user buffer
 		 * pointers and the remaining count).
 		 */
+		conditional_schedule();		/* sys_read() */
+
 		nr = actor(desc, page, offset, nr);
 		offset += nr;
 		index += offset >> PAGE_CACHE_SHIFT;
@@ -1533,6 +1537,7 @@
 	 * vma/file is guaranteed to exist in the unmap/sync cases because
 	 * mmap_sem is held.
 	 */
+	conditional_schedule();		/* sys_msync() */
 	return page->mapping->a_ops->writepage(file, page);
 }
 
@@ -2486,6 +2491,8 @@
 	while (count) {
 		unsigned long bytes, index, offset;
 		char *kaddr;
+
+		conditional_schedule();		/* sys_write() */
 
 		/*
 		 * Try to find the page in the cache. If it isn't there,
--- linux-2.4.0-test3-pre4/fs/buffer.c	Thu Jul  6 20:23:47 2000
+++ linux-akpm/fs/buffer.c	Sat Jul  8 14:34:08 2000
@@ -2123,6 +2123,7 @@
 				__wait_on_buffer(p);
 		} else if (buffer_dirty(p))
 			ll_rw_block(WRITE, 1, &p);
+		conditional_schedule();		/* sys_msync() */
 	} while (tmp != bh);
 }
 
--- linux-2.4.0-test3-pre4/include/linux/sched.h	Thu Jul  6 20:23:47 2000
+++ linux-akpm/include/linux/sched.h	Sat Jul  8 15:15:03 2000
@@ -146,6 +146,8 @@
 extern signed long FASTCALL(schedule_timeout(signed long timeout));
 asmlinkage void schedule(void);
 
+#define conditional_schedule() do { if (current->need_resched) schedule(); } while (0)
+
 /*
  * The default fd array needs to be at least BITS_PER_LONG,
  * as this is the granularity returned by copy_fdset().
@@ -348,6 +350,8 @@
    	u32 self_exec_id;
 /* Protection of (de-)allocation: mm, files, fs, tty */
 	spinlock_t alloc_lock;
+
+	int curr_syscall;
 };
 
 /*
@@ -423,6 +427,7 @@
     blocked:		{{0}},						\
     sigqueue:		NULL,						\
     sigqueue_tail:	&tsk.sigqueue,					\
+    curr_syscall:	0,						\
     alloc_lock:		SPIN_LOCK_UNLOCKED				\
 }
 