Date: Tue, 15 Jan 2008 17:01:30 -0500 (EST)
From: Steven Rostedt <>
Subject: Re: [RFC PATCH 16/22 -v2] add get_monotonic_cycles
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/1/15/371

On Tue, 15 Jan 2008, Mathieu Desnoyers wrote:
> >
> > Signed-off-by: Steven Rostedt <srostedt@redhat.com>
> > ---
> >  include/linux/clocksource.h |    3 ++
> >  kernel/time/timekeeping.c   |   48 ++++++++++++++++++++++++++++++++++++++++++++
> >  2 files changed, 51 insertions(+)
> >
> > Index: linux-compile-i386.git/kernel/time/timekeeping.c
> > ===================================================================
> > --- linux-compile-i386.git.orig/kernel/time/timekeeping.c	2008-01-09 14:27:26.000000000 -0500
> > +++ linux-compile-i386.git/kernel/time/timekeeping.c	2008-01-09 14:34:40.000000000 -0500
> > @@ -103,6 +103,54 @@ static inline void __get_realtime_clock_
> >  	timespec_add_ns(ts, nsecs);
> >  }
> >
> > +cycle_t notrace get_monotonic_cycles(void)
> > +{
> > +	cycle_t cycle_now, cycle_delta, cycle_raw, cycle_last;
> > +
> > +	do {
> > +		/*
> > +		 * cycle_raw and cycle_last can change on
> > +		 * another CPU and we need the delta calculation
> > +		 * of cycle_now and cycle_last happen atomic, as well
> > +		 * as the adding to cycle_raw. We don't need to grab
> > +		 * any locks, we just keep trying until get all the
> > +		 * calculations together in one state.
> > +		 *
> > +		 * In fact, we __cant__ grab any locks. This
> > +		 * function is called from the latency_tracer which can
> > +		 * be called anywhere. To grab any locks (including
> > +		 * seq_locks) we risk putting ourselves into a deadlock.
> > +		 */
>
> I wonder what makes the compiler read the clock->cycle_raw and
> clock->cycle_last variables twice ? I guess some memory barriers could
> be welcome here ?
We need both cycle_raw and cycle_last to be the same from the time we read
the clock source to the time we calculate cycle_delta. If either one
changes then delta is bogus.
Also, it just occurred to me that this is an old patch. I thought I
renamed cycle_raw to cycle_monotonic. But I must have lost that patch :-/
>
> > +		cycle_raw = clock->cycle_raw;
> > +		cycle_last = clock->cycle_last;
> > +
> > +		/* read clocksource: */
> > +		cycle_now = clocksource_read(clock);
> > +
> > +		/* calculate the delta since the last update_wall_time: */
> > +		cycle_delta = (cycle_now - cycle_last) & clock->mask;
> > +
> > +	} while (cycle_raw != clock->cycle_raw ||
> > +		 cycle_last != clock->cycle_last);
> > +
> > +	return cycle_raw + cycle_delta;
> > +}
-- Steve