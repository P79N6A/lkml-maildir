Date: Thu, 14 Oct 2004 20:04:27 +0200
From: Andi Kleen <>
Subject: Re: [PATCH] General purpose zeroed page slab
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2004/10/14/230

On Thu, Oct 14, 2004 at 12:50:43PM -0400, Martin K. Petersen wrote:
> 
> A while back Bill Irwin converted the page table code on ppc64 to use
> a zeroed page slab.  I recently did the same on ia64 and got a
> significant performance improvement in terms of fault time (4 usec ->
> 700 nsec).
> 
> This cache needs to be initialized fairly early on and so far we've
> called it from pgtable_cache_init() on both archs.  However, Tony Luck
> thought it might be useful to have a general purpose slab cache with
> zeroed pages.  And other architectures might decide to use it for
> their page tables too.
> 
> Consequently here's a patch that puts this functionality in slab.c.
> 
> Signed-off-by: Martin K. Petersen <mkp@wildopensource.com>
> 
> -- 
> Martin K. Petersen	Wild Open Source, Inc.
> mkp@wildopensource.com	
http://www.wildopensource.com/
> 
> diff -urN -X /usr/people/mkp/bin/dontdiff linux-pristine/include/linux/slab.h zero-slab/include/linux/slab.h
> --- linux-pristine/include/linux/slab.h	2004-10-11 14:57:20.000000000 -0700
> +++ zero-slab/include/linux/slab.h	2004-10-13 17:49:29.000000000 -0700
> @@ -115,6 +115,7 @@
>  extern kmem_cache_t	*signal_cachep;
>  extern kmem_cache_t	*sighand_cachep;
>  extern kmem_cache_t	*bio_cachep;
> +extern kmem_cache_t	*zero_page_cachep;
> 
>  extern atomic_t slab_reclaim_pages;
> 
> diff -urN -X /usr/people/mkp/bin/dontdiff linux-pristine/mm/slab.c zero-slab/mm/slab.c
> --- linux-pristine/mm/slab.c	2004-10-11 14:57:20.000000000 -0700
> +++ zero-slab/mm/slab.c	2004-10-13 17:49:57.000000000 -0700
> @@ -716,6 +716,13 @@
> 
>  static struct notifier_block cpucache_notifier = { &cpuup_callback, NULL, 0 };
> 
> +kmem_cache_t *zero_page_cachep;
> +
> +static void zero_page_ctor(void *pte, kmem_cache_t *cache, unsigned long flags)
> +{
> +	memset(pte, 0, PAGE_SIZE);
> +}
The means every user has to memset it to zero before free.
Add a comment for that at least.
Also that's pretty dumb. How about keeping track how much of the
page got non zeroed (e.g. by using a few free words in struct page
for a coarse grained dirty bitmap)
Then you could memset on free only the parts that got actually
changed, and never waste cache lines for anything else.
-Andi
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/