Date: Wed, 19 Dec 2007 23:42:44 -0800 (PST)
From: David Miller <>
Subject: Re: [PATCH 2/5] dma_map_sg_ring() helper
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2007/12/20/25

From: FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>
Date: Thu, 20 Dec 2007 16:06:31 +0900
> On Thu, 20 Dec 2007 16:49:30 +1100
> Rusty Russell <rusty@rustcorp.com.au> wrote:
> 
> > +/**
> > + * dma_map_sg_ring - Map an entire sg ring
> > + * @dev: Device to free noncoherent memory for
> > + * @sg: The sg_ring
> > + * @direction: DMA_TO_DEVICE, DMA_FROM_DEVICE or DMA_BIDIRECTIONAL.
> > + *
> > + * This returns -ENOMEM if mapping fails.  It's not clear that telling you
> > + * it failed is useful though.
> > + */
> > +int dma_map_sg_ring(struct device *dev, struct sg_ring *sg,
> > +		     enum dma_data_direction direction)
> > +{
> > +	struct sg_ring *i;
> > +	unsigned int num;
> > +
> > +	for (i = sg; i; i = sg_ring_next(i, sg)) {
> > +		BUG_ON(i->num > i->max);
> > +		num = dma_map_sg(dev, i->sg, i->num, direction);
> > +		if (num == 0 && i->num != 0)
> > +			goto unmap;
> > +	}
> > +	return 0;
> 
> I don't think that this works for IOMMUs that could merge sg entries.
Right, it won't work at all.
The caller has to be told how many DMA entries it really did use to
compose the mapping, and there has to be a way to properly iterate
over them.  The assumption that the IOMMU will map the SG entries
1-to-1 is invalid.
The IOMMU code can and will map thousands of pages all to one linear
DMA address+length pair of all the segments start and end on page
boundaries, since it can virtually remap those pages however it
chooses.