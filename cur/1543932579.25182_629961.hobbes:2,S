Date: Wed, 19 Dec 2007 20:39:49 +0300
From: Cyrill Gorcunov <>
Subject: [PATCH] lockdep: tiny code cleanup according to checkpatch
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2007/12/19/165

This patch makes a tiny code cleanup over lockdep.c
according to checkpatch. Nothing serious - space
cleanup, noninline keyword moved in between of
storage class and type.
Signed-Off-By: Cyrill Gorcunov <gorcunov@gmail.com>
---
 kernel/lockdep.c |   23 +++++++++--------------
 1 files changed, 9 insertions(+), 14 deletions(-)
diff --git a/kernel/lockdep.c b/kernel/lockdep.c
index 723bd9f..397bfd0 100644
--- a/kernel/lockdep.c
+++ b/kernel/lockdep.c
@@ -274,14 +274,12 @@ void lockdep_off(void)
 {
 	current->lockdep_recursion++;
 }
-
 EXPORT_SYMBOL(lockdep_off);
 
 void lockdep_on(void)
 {
 	current->lockdep_recursion--;
 }
-
 EXPORT_SYMBOL(lockdep_on);
 
 /*
@@ -427,7 +425,7 @@ static const char *usage_str[] =
 	[LOCK_ENABLED_HARDIRQS_READ] =	"hardirq-on-R",
 };
 
-const char * __get_key_name(struct lockdep_subclass_key *key, char *str)
+const char *__get_key_name(struct lockdep_subclass_key *key, char *str)
 {
 	return kallsyms_lookup((unsigned long)key, NULL, NULL, NULL, str);
 }
@@ -543,7 +541,7 @@ static void print_lock_class_header(struct lock_class *class, int depth)
 	}
 	printk("%*s }\n", depth, "");
 
-	printk("%*s ... key      at: ",depth,"");
+	printk("%*s ... key      at: ", depth, "");
 	print_ip_sym((unsigned long)class->key);
 }
 
@@ -565,7 +563,7 @@ static void print_lock_dependencies(struct lock_class *class, int depth)
 
 		print_lock_dependencies(entry->class, depth + 1);
 
-		printk("%*s ... acquired at:\n",depth,"");
+		printk("%*s ... acquired at:\n", depth, "");
 		print_stack_trace(&entry->trace, 2);
 		printk("\n");
 	}
@@ -724,7 +722,7 @@ register_lock_class(struct lockdep_map *lock, unsigned int subclass, int force)
 
 	/*
 	 * Debug-check: all keys must be persistent!
- 	 */
+	 */
 	if (!static_obj(lock->key)) {
 		debug_locks_off();
 		printk("INFO: trying to register non-static key.\n");
@@ -941,7 +939,7 @@ static noinline int print_circular_bug_tail(void)
 
 #define RECURSION_LIMIT 40
 
-static int noinline print_infinite_recursion_bug(void)
+static noinline int print_infinite_recursion_bug(void)
 {
 	if (!debug_locks_off_graph_unlock())
 		return 0;
@@ -1575,7 +1573,7 @@ static int validate_chain(struct task_struct *curr, struct lockdep_map *lock,
 }
 #else
 static inline int validate_chain(struct task_struct *curr,
-	       	struct lockdep_map *lock, struct held_lock *hlock,
+		struct lockdep_map *lock, struct held_lock *hlock,
 		int chain_head, u64 chain_key)
 {
 	return 1;
@@ -1792,7 +1790,7 @@ static int mark_lock_irq(struct task_struct *curr, struct held_lock *this,
 {
 	int ret = 1;
 
-	switch(new_bit) {
+	switch (new_bit) {
 	case LOCK_USED_IN_HARDIRQ:
 		if (!valid_state(curr, this, new_bit, LOCK_ENABLED_HARDIRQS))
 			return 0;
@@ -2051,7 +2049,6 @@ void trace_hardirqs_on(void)
 	curr->hardirq_enable_event = ++curr->irq_events;
 	debug_atomic_inc(&hardirqs_on_events);
 }
-
 EXPORT_SYMBOL(trace_hardirqs_on);
 
 /*
@@ -2340,7 +2337,6 @@ void lockdep_init_map(struct lockdep_map *lock, const char *name,
 	if (subclass)
 		register_lock_class(lock, subclass, 1);
 }
-
 EXPORT_SYMBOL_GPL(lockdep_init_map);
 
 /*
@@ -2705,7 +2701,6 @@ void lock_acquire(struct lockdep_map *lock, unsigned int subclass,
 	current->lockdep_recursion = 0;
 	raw_local_irq_restore(flags);
 }
-
 EXPORT_SYMBOL_GPL(lock_acquire);
 
 void lock_release(struct lockdep_map *lock, int nested, unsigned long ip)
@@ -3080,8 +3075,8 @@ print_freed_lock_bug(struct task_struct *curr, const void *mem_from,
 	dump_stack();
 }
 
-static inline int not_in_range(const void* mem_from, unsigned long mem_len,
-				const void* lock_from, unsigned long lock_len)
+static inline int not_in_range(const void *mem_from, unsigned long mem_len,
+				const void *lock_from, unsigned long lock_len)
 {
 	return lock_from + lock_len <= mem_from ||
 		mem_from + mem_len <= lock_from;