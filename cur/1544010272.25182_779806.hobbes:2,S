Date: Fri, 12 Dec 2008 18:47:05 +1030
From: Rusty Russell <>
Subject: Re: [PATCH] percpu_counter: Fix __percpu_counter_sum()
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/12/12/50

On Thursday 11 December 2008 09:26:37 Eric Dumazet wrote:
> But then, some (all but x86 ;) ) arches dont have true local_t and we fallback
> to plain atomic_long_t, and this is wrong because it would add a LOCKED
> instruction in fast path.
> 
> I remember Christoph added FAST_CMPXCHG_LOCAL, but no more uses of it in current
> tree.
> 
> Ie : using local_t only if CONFIG_FAST_CMPXCHG_LOCAL, else something like :
> 
> void __percpu_counter_add_irqsafe(struct percpu_counter *fbc, s64 amount, s32 batch)
> {
>         s64 count;
>         s32 *pcount = per_cpu_ptr(fbc->counters, get_cpu());
>         unsigned long flags;
> 
>         local_irq_save(flags);
>         count = *pcount + amount;
This is dumb though.  If local_irq_save(), add, local_irq_restore() is faster
than atomic_long_add on some arch, *that* is what that arch's local_add()
should do!
Open coding it like this is obviously wrong.
Now, archs local.h need attention (x86-32 can be optimized today, for
example), but that's not directly related.
Hope that clarifies,
Rusty.
PS.  Yes, I should produce a documentation patch and fix the x86 version.
Added to TODO list.