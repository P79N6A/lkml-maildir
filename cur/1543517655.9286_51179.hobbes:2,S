Date: 02 Dec 1999 22:24:42 +0100
From: Andi Kleen <>
Subject: Re: using mmap in creating a new 1GB file
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/12/2/106

jmm@raleigh.ibm.com (James Manning) writes:
> I've been trying to figure out the best way to write out a file (known to
> be 1GB in size once finished and non-existant to start) using mmap's... as
> it stands, I mmap() an anon 1GB area, write to that and then spend a
> large chunk of time in a single write() call at the end of the program.
> 
> What I'm hoping for is something that would let me allocate a 1GB file
> on the ext2 filesystem (without any I/O, I don't even care about really
> checking for enough free space), mmap it with PROT_WRITE,MAP_PRIVATE,
> then do the sequential writing to the mmap'd area madvise'd such that
> once I've finished writing to a page the page will get written out to
> the actual file without blocking the process that is writing.  (so I'm
> just trying to get a lot of that drive I/O that is now serially after
> the processing to occur in parallel).
You can use ftruncate(2) to "allocate" the file. Then you mmap it and
put the data in. The process may block when the memory is filled up and
it has to write out old pages in order to allocate new pages. There is
really no way to avoid that eventual blocking because you have finite
main memory (and what should it do instead, crashing?). If you
have enough memory the write out should occur asynchronously in the 
background.
The other possibility to avoid blocking is to use a special thread.
e.g. aio_write will do that for you.
-Andi
-- 
This is like TV. I don't like TV.
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/