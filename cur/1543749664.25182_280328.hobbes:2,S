Date: Mon, 20 Dec 2004 12:54:43 -0800
From: Andrew Morton <>
Subject: Re: [PATCH][1/2] adjust dirty threshold for lowmem-only mappings
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2004/12/20/178

Rik van Riel <riel@redhat.com> wrote:
>
> Simply running "dd if=/dev/zero of=/dev/hd<one you can miss>" will
>  result in OOM kills, with the dirty pagecache completely filling up
>  lowmem.
That surely used to work - I have a feeling that it got broken somehow. 
The below might fix it, but probably not.
The intended behaviour is that the page-allocating process will throttle
and will then pick up those pages from the tail of the LRU which
rotate_reclaimable_page() put there.
We haven't been incrementing local variable total_scanned since the
scan_control stuff went in.  That broke kswapd throttling.
Signed-off-by: Andrew Morton <akpm@osdl.org>
---
 25-akpm/mm/vmscan.c |    1 +
 1 files changed, 1 insertion(+)
diff -puN mm/vmscan.c~vmscan-total_scanned-fix mm/vmscan.c
--- 25/mm/vmscan.c~vmscan-total_scanned-fix	2004-12-20 12:47:25.855643408 -0800
+++ 25-akpm/mm/vmscan.c	2004-12-20 12:47:25.860642648 -0800
@@ -1063,6 +1063,7 @@ scan:
 			shrink_slab(sc.nr_scanned, GFP_KERNEL, lru_pages);
 			sc.nr_reclaimed += reclaim_state->reclaimed_slab;
 			total_reclaimed += sc.nr_reclaimed;
+			total_scanned += sc.nr_scanned;
 			if (zone->all_unreclaimable)
 				continue;
 			if (zone->pages_scanned >= (zone->nr_active +
_
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/