Date: Wed, 16 Mar 2005 13:15:21 -0800
From: Andrew Morton <>
Subject: Re: [patch 0/3] j_state_lock, j_list_lock, remove-bitlocks
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2005/3/16/222

Steven Rostedt <rostedt@goodmis.org> wrote:
>
> /*
>   * Try to acquire jbd_lock_bh_state() against the buffer, when j_list_lock
>  is
>   * held.  For ranking reasons we must trylock.  If we lose, schedule away
>  and
>   * return 0.  j_list_lock is dropped in this case.
>   */
>  static int inverted_lock(journal_t *journal, struct buffer_head *bh)
>  {
>  	if (!jbd_trylock_bh_state(bh)) {
>  		spin_unlock(&journal->j_list_lock);
>  		schedule();
>  		return 0;
>  	}
>  	return 1;
>  }
> 
That's very lame code, that.  The old "I don't know what the heck to do now
so I'll schedule" trick.  Sorry.
>  I guess one way to solve this is to add a wait queue here (before
>  schedule()), and have the one holding the lock to wake up all on the
>  waitqueue when they release it.
yup.  A patch against mainline would be appropriate, please.
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/