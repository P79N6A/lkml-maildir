Date: Mon, 21 Nov 2005 17:41:33 +0100
From: Takashi Iwai <>
Subject: Re: 2.6.15-rc1-mm2 -- Bad page state at free_hot_cold_page (in process 'aplay', page c18eef30)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2005/11/21/143

At Mon, 21 Nov 2005 16:25:58 +0000,
Russell King wrote:
> 
> On Mon, Nov 21, 2005 at 05:17:12PM +0100, Takashi Iwai wrote:
> > Now another question arises:  Which is the recommended method for
> > mmapping RAM pages, vma nopage callback or remap_pfn_range()?
> > 
> > IIRC, in the ealier versions, the former was recommended because
> > remap_page_range() with page-reserve was regarded as a hack.
> > But, looking through these changes, I feel that remap_pfn_range() is
> > better (easier and stabler) than vma nopage...
> 
> And this brings up the question of this age old patch:
> 
> diff -up -x BitKeeper -x ChangeSet -x SCCS -x _xlk -x '*.orig' -x '*.rej' -r orig/arch/i386/kernel/pci-dma.c linux/arch/i386/kernel/pci-dma.c
> --- orig/arch/i386/kernel/pci-dma.c	Mon Apr  4 22:52:57 2005
> +++ linux/arch/i386/kernel/pci-dma.c	Mon Apr  4 22:44:45 2005
> @@ -50,7 +50,7 @@ void *dma_alloc_coherent(struct device *
>  	ret = (void *)__get_free_pages(gfp, order);
>  
>  	if (ret != NULL) {
> -		memset(ret, 0, size);
> +		memset(ret, 0, PAGE_ALIGN(size));
>  		*dma_handle = virt_to_phys(ret);
>  	}
>  	return ret;
> diff -up -x BitKeeper -x ChangeSet -x SCCS -x _xlk -x '*.orig' -x '*.rej' -r orig/include/asm-i386/dma-mapping.h linux/include/asm-i386/dma-mapping.h
> --- orig/include/asm-i386/dma-mapping.h	Mon Apr  4 22:54:41 2005
> +++ linux/include/asm-i386/dma-mapping.h	Mon Apr  4 22:48:11 2005
> @@ -16,6 +16,23 @@ void *dma_alloc_coherent(struct device *
>  void dma_free_coherent(struct device *dev, size_t size,
>  			 void *vaddr, dma_addr_t dma_handle);
>  
> +static inline int
> +dma_mmap_coherent(struct device *dev, struct vm_area_struct *vma,
> +		  void *vaddr, dma_addr_t handle, size_t size)
> +{
> +	unsigned long offset = vma->vm_pgoff, usize;
> +
> +	size = PAGE_ALIGN(size) >> PAGE_SHIFT;
> +	usize = (vma->vm_end - vma->vm_start) >> PAGE_SHIFT;
> +
> +	if (offset >= size || usize > (size - offset))
> +		return -ENXIO;
> +
> +	return remap_page_range(vma, vma->vm_start,
> +				__pa(vaddr) + (offset << PAGE_SHIFT),
> +				usize << PAGE_SHIFT, vma->vm_page_prot);
> +}
> +
>  static inline dma_addr_t
>  dma_map_single(struct device *dev, void *ptr, size_t size,
>  	       enum dma_data_direction direction)
> 
> which provides the dma mmap API which presently is ARM-only on to x86.
Yes, that's nice.  It would be nice if dma_mmap_coherent() is
implemented on all architectures.
> Note: the first part of this patch should probably be applied anyway
> if you're mmaping dma_alloc_coherent pages to userspace to ensure that
> information is not leaked from kernel context.
This reminds me another thing:  x86 dma_alloc_coherent() doesn't trim
the pages between PAGE_ALIGN(size) and (1 << order).  Some archs seem
doing this right.
Takashi
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/