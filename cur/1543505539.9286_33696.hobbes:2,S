Date: 12 Aug 1999 00:28:03 -0400
From: Nat Lanza <>
Subject: Re: Handling large rsizes/wsizes under NFS (and NFSv3)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/8/13/115

Trond Myklebust <trond.myklebust@fys.uio.no> writes:
>   Ideally, it seems to me the large rsize stuff belongs in
> mm/filemap. It should be possible for the NFS layer (and possibly
> NCPFS?) to specify that it would prefer to read in, say, 8 pages at a
> time, and expect the readahead code to allocate and ship them to
> nfs_read in one go.
I'd also love to see this for the NASD filesystem code I'm working on; 
it'd be nice to be able to do aggressive readahead and large read
requests without much extra pain.
>   The common problem in both these cases is that I wishes to treat
> collections of pages as one large object. I'd would like to build a
> temporary chain of pages, send off a read or write request, and then
> destroy the chain. I was therefore thinking of adding support for such
> a linked list of pages directly into the page struct (like what we
> already have for the inode memory mapping).
Again, I'd also like this -- I'd love to see interfaces that worked on 
this level, like "stick this set of pages into the page cache", "read
these bytes from this file into these pages", and so forth. When
you're trying to do 64K-1MB or so IO requests, dealing only with
individual pages gets annoying.
--nat
-- 
nat lanza --------------------- research programmer, parallel data lab, cmu scs
magus@cs.cmu.edu -------------------------------- 
http://www.cs.cmu.edu/~magus/
there are no whole truths; all truths are half-truths -- alfred north whitehead
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/