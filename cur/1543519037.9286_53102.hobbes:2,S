Date: Mon, 13 Dec 1999 16:50:12 MET-1
From: "Petr Vandrovec Ing. VTEI" <>
Subject: Deadlock detected on CPU #1 (2.3.32-pre3)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/12/13/76

Hi,
  I 'fixed' pre3 patch so that pgd_quick is handled same way as pmd_quick
is (ie. per-cpu thing; I have < 1GB so this probably does not matter
anyway). It worked fine for some time, but then I got error CPU #1 
deadlock detected... in (almost) same place as I reported last week, 
but with different call trace. Code is looping again in irq_enter() !
Call trace:
  handle_IRQ_event+43/129
  do_IRQ+216/454
  ret_from_intr+0/27
  io_virt_debug+1/51 (it is probably place where IRQ came)
  fbcon_cfb16_putcs+412/1062
  0xc020dad2 (probably fb_info for putcs; points to .data)
  fbcon_putcs+182/206
  do_con_write+1824/1981
  con_write+22/43
  opost_block+343/355
  ide_spin_wait_hwgroup+158/291 (probably garbage on stack)
  set_cursor+110/127 (probably garbage on stack)
  write_chan+641/953
  tty_write+744/1022
  write_chan+0/953 (address of proc...)
  sys_write+269/306
  system_call+52
I do not see anything wrong with it; except that other CPU probably
holds global_irq_lock indefinitely... Is there some patch which allow
me to get also call trace from non-deadlocked CPU when deadlock occur?
  Hardware is dual PIII/450, IDE (18GB UDMA2), AHA1542 (driver not loaded), 
2x bttv (bt848+bt878), matroxfb + matroxfb_dh (G400 dualhead), ess-solo1, 
tulip 10Mbps, 256MB RAM.
                                        Thanks,
                                                Petr Vandrovec
                                                vandrove@vc.cvut.cz
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/