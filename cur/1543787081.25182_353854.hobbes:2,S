Date: Tue, 27 Sep 2005 13:05:02 -0700
From: Rohit Seth <>
Subject: Re: 2.6.14-rc2-mm1
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2005/9/27/200

On Tue, 2005-09-27 at 11:57 -0700, Martin J. Bligh wrote:
> > Seems like from the log messages that quite a few pages are hanging
> in the cpu's cold pcp list even with the low memory conditions.  Below
> is the patch to reduce the higher bound in cold pcp list (...this got
> increased with my previous change).  
> 
> > 
> > I think we should also drain the CPU's hot and cold pcps for the
> GFP_KERNEL page requests (in the event the higher order request is not
> able to get serviced otherwise).  This will still only drains the
> current CPUs pcps in an MP environment (leaving the other CPUs with
> their lists intact).  I will send this patch later today.
> 
> > 
> >       [PATCH]: Reduce the high mark in cpu's cold pcp list. 
> > 
> >       Signed-off-by: Rohit Seth <rohit.seth@intel.com> 
> > 
> > 
> > --- linux-2.6.13.old/mm/page_alloc.c  2005-09-26 10:57:07.000000000
> -0700 
> > +++ linux-2.6.13.work/mm/page_alloc.c 2005-09-26 10:47:57.000000000
> -0700 
> > @@ -1749,7 +1749,7 @@ 
> >       pcp = &p->pcp[1];               /* cold*/ 
> >       pcp->count = 0; 
> >       pcp->low = 0; 
> > -     pcp->high = 2 * batch; 
> > +     pcp->high = batch / 2; 
> >       pcp->batch = max(1UL, batch/2); 
> >       INIT_LIST_HEAD(&pcp->list); 
> >  } 
> > -
> 
> I don't understand. How can you set the high watermark at half the
> batch size? Makes no sense to me.
> 
The batch size for the cold pcp list is getting initialized to batch/2
in the code snip above.  So, this change is setting the high water mark
for cold list to same as pcp's batch number.
> And can you give a stricter definiton of what you mean by "low memory 
> conditions"? I agree we ought to empty the lists before going OOM or 
> anything, but not at the slightest feather of pressure ... answer lies
> somewhere inbetween ... but where?
> 
In the specific case of dump information that Mattia sent earlier, there
is only 4M of free mem available at the time the order 1 request is
failing.  
In general, I think if a specific higher order ( > 0) request fails that
has GFP_KERNEL set then at least we should drain the pcps.
-rohit
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/