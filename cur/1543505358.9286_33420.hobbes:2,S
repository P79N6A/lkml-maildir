Date: Wed, 11 Aug 1999 04:11:34 +0200 (CEST)
From: Trond Myklebust <>
Subject: Handling large rsizes/wsizes under NFS (and NFSv3)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/8/11/63

Linus,
  I'm starting to rethink the design of the NFSv3 patches in view of
simplifying a few things. I think that most of the 'cluster' stuff can
fairly easily be thrown out, so that we are left with only 1 structure
for the write requests, but I'm having problems fitting in the support
for large rsizes and wsizes without a small change to the page struct.
  Ideally, it seems to me the large rsize stuff belongs in
mm/filemap. It should be possible for the NFS layer (and possibly
NCPFS?) to specify that it would prefer to read in, say, 8 pages at a
time, and expect the readahead code to allocate and ship them to
nfs_read in one go.
  For writebacks, the problem is different. There you only want to
fill single a page at a time, gathering pages as they are filled and
then sending them off in one large request.
  The common problem in both these cases is that I wishes to treat
collections of pages as one large object. I'd would like to build a
temporary chain of pages, send off a read or write request, and then
destroy the chain. I was therefore thinking of adding support for such
a linked list of pages directly into the page struct (like what we
already have for the inode memory mapping).
  Would such an approach be acceptable to you, or do you have any
alternatives that you would prefer to see implemented?
Cheers,
  Trond
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/