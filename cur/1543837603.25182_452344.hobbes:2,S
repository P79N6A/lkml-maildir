Date: Thu, 10 Aug 2006 18:03:34 +0200
From: Haavard Skinnemoen <>
Subject: [PATCH 2/14] Generic ioremap_page_range: flush_cache_vmap
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2006/8/10/246

The existing implementation of ioremap_page_range(), which was taken
from i386, does this:
	flush_cache_all();
	/* modify page tables */
	flush_tlb_all();
I think this is a bit defensive, so this patch changes the generic
implementation to do:
	/* modify page tables */
	flush_cache_vmap(start, end);
instead, which is similar to what vmalloc() does. This should still
be correct because we never modify existing PTEs. According to
James Bottomley:
The problem the flush_tlb_all() is trying to solve is to avoid stale tlb
entries in the ioremap area.  We're just being conservative by flushing
on both map and unmap.  Technically what vmalloc/vfree does (only flush
the tlb on unmap) is just fine because it means that the only tlb
entries in the remap area must belong to in-use mappings.
Signed-off-by: Haavard Skinnemoen <hskinnemoen@atmel.com>
---
 lib/ioremap.c |    4 +---
 1 files changed, 1 insertions(+), 3 deletions(-)
diff --git a/lib/ioremap.c b/lib/ioremap.c
index 6419101..d2cb1eb 100644
--- a/lib/ioremap.c
+++ b/lib/ioremap.c
@@ -75,8 +75,6 @@ int ioremap_page_range(unsigned long add
 
 	BUG_ON(addr >= end);
 
-	flush_cache_all();
-
 	start = addr;
 	phys_addr -= addr;
 	pgd = pgd_offset_k(addr);
@@ -87,7 +85,7 @@ int ioremap_page_range(unsigned long add
 			break;
 	} while (pgd++, addr = next, addr != end);
 
-	flush_tlb_all();
+	flush_cache_vmap(start, end);
 
 	return err;
 }
-- 
1.4.0
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/