Date: Thu, 15 Jan 2009 17:01:32 -0800 (PST)
From: Linus Torvalds <>
Subject: Re: [GIT PULL] adaptive spinning mutexes
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2009/1/15/732

On Thu, 15 Jan 2009, Paul E. McKenney wrote:
> On Thu, Jan 15, 2009 at 10:16:53AM -0800, Linus Torvalds wrote:
> > 
> > IOW, if you do pre-allocation instead of holding a lock over the 
> > allocation, you win. So yes, spin-mutexes makes it easier to write the 
> > code, but it also makes it easier to just plain be lazy.
> 
> In infrequently invoked code such as some error handling, lazy/simple
> can be a big win.
Sure. I don't disagree at all. On such code we don't even care about 
locking. If it _really_ is fundamentally very rarely invoked.
But if we're talking things like core filesystem locks, it's _really_ 
irritating when one of those (supposedly rare) allocation delays or the 
need to do IO then blocks all those (supposedly common) nice cached cases.
So I don't dispute at all that "mutex with spinning" performs better than 
a mutex, but I _do_ claim that it has some potentially huge downsides 
compared to a real spinlock. It may perform as well as a spinlock in the 
nice common case, but then when you hit the non-common case you see the 
difference between well-written code and badly written code.
And sadly, while allocations _usually_ are nice and immediate, and while 
our caches _usually_ mean that we don't need to do IO, bad behavior when 
we do need to do IO is what really kills interactive feel. Suddenly 
everything else is hurting too, because they wanted that lock - even if 
they didn't need to do IO or allocate anything.
			Linus