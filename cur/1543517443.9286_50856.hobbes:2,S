Date: Tue, 30 Nov 1999 22:50:21 +0100 (CET)
From: Ingo Molnar <>
Subject: Re: [patch] new spinlock variant, spinlock-2.3.30-A4
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/11/30/133

On Tue, 30 Nov 1999, Davide Libenzi wrote:
> >               movb $1, 3(%%esi)             # spin_lock
> >               movl 4(%%esi), %%edx
> >               addl (%%esi), %%edx
> >               cmpl $0x01000000, %%edx
> >               je slow_path
> 
> This can lead to some dead loops, due to the fact that an atomic ( locked )
> test and set is not used.
> The lock acquire is based on the assumption that only one CPU execute the
> lock code.
The spinlock is correct with an arbitrary number of CPUs.
> In theory if there are more than one CPUs executing the code, they can
> spend a lot of loops without getting the N bytes at zero. This
> probability is higher greater is the number of CPUs. Using a test and
> set instruction, even if N CPUs execute the same code at the same
> time, only one gets the lock value.
yes, true. Keep in mind that this only affects the slow path. The above
spinlock would be implemented as a function anyway (we do not want to
inline it), and in that case the slow path can eg. use queued spinlocks
(spinlock chains through on-stack variables) or exponential backoff, or
whatever technique.
-- mingo
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/