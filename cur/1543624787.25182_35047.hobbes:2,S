Date: Fri, 15 Mar 2002 16:38:34 -0800 (PST)
From: Balbir Singh <>
Subject: Re: [PATCH] mempool_resize and sanity checks
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2002/3/15/128

For some reason, it seems that the diffs did not
make it. Resending them
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In mempool_resize(), I plan to replace the calls
to spin_unlock_irqrestore() -> pool_free -> spin_lock_
irqsave with the new sequence. The newer code
has fewer calls to spin_lock_irqsave and spin_unlock_
restore(). I think the new code should execute faster.
I have tested this code on a UP, if somebody could
test the patch on an SMP box and let me know if it
works, I would be thankful. I also have a sample test
case that uses mempool_resize().
I have also added the BUG_ON sanity checks in
mempool_create().
New Code
if (new_min_nr < pool->min_nr) {
        pool->min_nr = new_min_nr;
        /*      
         * Free possible excess elements.
         */      
        INIT_LIST_HEAD(&tmp_pool_to_free);
        while (pool->curr_nr > pool->min_nr) {
                tmp = pool->elements.next;
                if (tmp == &pool->elements)
                        BUG();  
                list_del(tmp);
                list_add(tmp, &tmp_pool_to_free);
                pool->curr_nr--;
        }       
        spin_unlock_irqrestore(&pool->lock, flags);
        list_for_each(tmp, &tmp_pool_to_free) {
                element = tmp;
                pool->free(element, pool->pool_data);
        }       
        return; 
}       
Original Code
if (new_min_nr < pool->min_nr) {
        pool->min_nr = new_min_nr;
        /*
         * Free possible excess elements.
         */
        while (pool->curr_nr > pool->min_nr) {
                tmp = pool->elements.next;
                if (tmp == &pool->elements)
                        BUG();
                list_del(tmp);
                element = tmp;
                pool->curr_nr--;
                spin_unlock_irqrestore(&pool->lock,
flags);
                pool->free(element, pool->pool_data);
                spin_lock_irqsave(&pool->lock, flags);
        }
        spin_unlock_irqrestore(&pool->lock, flags);
        return;
}
Diffs are attached.
Balbir
__________________________________________________
Do You Yahoo!?
Yahoo! Sports - live college hoops coverage
http://sports.yahoo.com/
--- mempool.c	Tue Mar 12 19:21:33 2002
+++ mempool.c.new	Tue Mar  5 10:37:19 2002
@@ -34,6 +34,9 @@
 	mempool_t *pool;
 	int i;
 
+	BUG_ON(!alloc_fn);
+	BUG_ON(!free_fn);
+
 	pool = kmalloc(sizeof(*pool), GFP_KERNEL);
 	if (!pool)
 		return NULL;
@@ -97,6 +100,7 @@
 	void *element;
 	unsigned long flags;
 	struct list_head *tmp;
+	struct list_head tmp_pool_to_free;
 
 	if (new_min_nr <= 0)
 		BUG();
@@ -107,20 +111,21 @@
 		/*
 		 * Free possible excess elements.
 		 */
+		INIT_LIST_HEAD(&tmp_pool_to_free);
 		while (pool->curr_nr > pool->min_nr) {
 			tmp = pool->elements.next;
 			if (tmp == &pool->elements)
 				BUG();
 			list_del(tmp);
-			element = tmp;
+			list_add(tmp, &tmp_pool_to_free);
 			pool->curr_nr--;
-			spin_unlock_irqrestore(&pool->lock, flags);
+		}
+		spin_unlock_irqrestore(&pool->lock, flags);
 
+		list_for_each(tmp, &tmp_pool_to_free) {
+			element = tmp;
 			pool->free(element, pool->pool_data);
-
-			spin_lock_irqsave(&pool->lock, flags);
 		}
-		spin_unlock_irqrestore(&pool->lock, flags);
 		return;
 	}
 	delta = new_min_nr - pool->min_nr;