Date: Fri, 15 Sep 2000 09:38:36 -0400
From:  devnull@spaans ...
Subject: Re: [2.4][2.2] Bug: accept discards socket options/O_NONBLOCK
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/9/15/111

   Date: 	Fri, 15 Sep 2000 15:01:25 +0200
   From: Matthias Andree <matthias.andree@stud.uni-dortmund.de>
   BUG DESCRIPTION:
     (This is for IPv4, someone would have to check IPv6 as well).
     The socket flag O_NONBLOCK is _NOT_ properly inherited through an
     accept(2) call, in spite of what socket(7) documents. This is a bug.
     accept(2) must copy the file descriptor's flag of the socket.
Yes, it's true that BSD apparently has this behaviour.  The problem is
that there are existing Linux programs that are fairly widely deployed
that would break if we made this change now.  And even if we did make
the change, the existing deployed 2.2 kernels, which represents a huge
installed base, would still be around for a long time.
BSD'er's can kvetch about our not following "the BSD sockets interface".
I'd be a lot more sympathetic if the CSRG had bothered to actually write
it down as a formal specification, and if the CSRG themselves didn't
make random, not-always-backwards-compatible changes to the interfaces
from 4.3, 4.3Reno, 4.3Tahoe, and 4.4.  Oh, well.
My suggestion is to document that if you want a well-written, portable
program, you must set the file descriptor flags after an accept(2) call.
It's not ideal, but it's the best way to make sure your application
program will run on the widest possible array of systems.  No, this is
not ideal.  But it's life.
							- Ted
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
Please read the FAQ at 
http://www.tux.org/lkml/