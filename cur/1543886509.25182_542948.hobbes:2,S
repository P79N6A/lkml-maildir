Date: Fri, 11 May 2007 00:31:03 +0530 (IST)
From: Satyam Sharma <>
Subject: [PATCH -mm 1/2] Kill old write_trylock_irqsave()
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2007/5/10/455

Kill the old write_trylock_irqsave() implementation, as it is slower -- we can
do better with the new version. Also the older patch is more invasive and
inconsistent in style with the spin_trylock_irqsave() of mainline and -mm.
Signed-off-by: Satyam Sharma <ssatyam@cse.iitk.ac.in>
Cc: Sripathi Kodi <sripathik@in.ibm.com>
Cc: Ingo Molnar <mingo@elte.hu>
---
  include/linux/spinlock.h         |    2 --
  include/linux/spinlock_api_smp.h |    1 -
  include/linux/spinlock_api_up.h  |    2 --
  kernel/spinlock.c                |   14 --------------
  4 files changed, 19 deletions(-)
---
diff -ruNp a/include/linux/spinlock_api_smp.h b/include/linux/spinlock_api_smp.h
--- a/include/linux/spinlock_api_smp.h	2007-05-10 23:26:09.000000000 +0530
+++ b/include/linux/spinlock_api_smp.h	2007-05-10 23:34:25.000000000 +0530
@@ -41,7 +41,6 @@ unsigned long __lockfunc _write_lock_irq
  int __lockfunc _spin_trylock(spinlock_t *lock);
  int __lockfunc _read_trylock(rwlock_t *lock);
  int __lockfunc _write_trylock(rwlock_t *lock);
-int __lockfunc _write_trylock_irqsave(rwlock_t *lock, unsigned long flags);
  int __lockfunc _spin_trylock_bh(spinlock_t *lock);
  void __lockfunc _spin_unlock(spinlock_t *lock)		__releases(lock);
  void __lockfunc _read_unlock(rwlock_t *lock)		__releases(lock);
diff -ruNp a/include/linux/spinlock_api_up.h b/include/linux/spinlock_api_up.h
--- a/include/linux/spinlock_api_up.h	2007-05-10 23:26:09.000000000 +0530
+++ b/include/linux/spinlock_api_up.h	2007-05-10 23:34:11.000000000 +0530
@@ -64,8 +64,6 @@
  #define _spin_trylock(lock)			({ __LOCK(lock); 1; })
  #define _read_trylock(lock)			({ __LOCK(lock); 1; })
  #define _write_trylock(lock)			({ __LOCK(lock); 1; })
-#define _write_trylock_irqsave(lock, flags) \
-				({ __LOCK_IRQSAVE(lock, flags); 1; })
  #define _spin_trylock_bh(lock)			({ __LOCK_BH(lock); 1; })
  #define _spin_unlock(lock)			__UNLOCK(lock)
  #define _read_unlock(lock)			__UNLOCK(lock)
diff -ruNp a/include/linux/spinlock.h b/include/linux/spinlock.h
--- a/include/linux/spinlock.h	2007-05-10 23:26:09.000000000 +0530
+++ b/include/linux/spinlock.h	2007-05-10 23:33:41.000000000 +0530
@@ -171,8 +171,6 @@ do {								\
  #define spin_trylock(lock)		__cond_lock(lock, _spin_trylock(lock))
  #define read_trylock(lock)		__cond_lock(lock, _read_trylock(lock))
  #define write_trylock(lock)		__cond_lock(lock, _write_trylock(lock))
-#define write_trylock_irqsave(lock, flags) \
-		__cond_lock(lock, _write_trylock_irqsave(lock, flags))
  #define spin_lock(lock)			_spin_lock(lock)
diff -ruNp a/kernel/spinlock.c b/kernel/spinlock.c
--- a/kernel/spinlock.c	2007-05-10 23:26:09.000000000 +0530
+++ b/kernel/spinlock.c	2007-05-10 23:35:08.000000000 +0530
@@ -60,20 +60,6 @@ int __lockfunc _write_trylock(rwlock_t *
  }
  EXPORT_SYMBOL(_write_trylock);
-int __lockfunc _write_trylock_irqsave(rwlock_t *lock, unsigned long flags)
-{
-	int ret;
-
-	local_irq_save(flags);
-	ret = _write_trylock(lock);
-	if (ret)
-		return ret;
-
-	local_irq_restore(flags);
-	return 0;
-}
-EXPORT_SYMBOL(_write_trylock_irqsave);
-
  /*
   * If lockdep is enabled then we use the non-preemption spin-ops
   * even on CONFIG_PREEMPT, because lockdep assumes that interrupts are
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/