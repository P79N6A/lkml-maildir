Date: Thu, 20 Oct 2005 23:50:47 +0200
From: Ingo Molnar <>
Subject: Re: [PATCH] i386 spinlocks should use the full 32 bits, not only 8 bits
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2005/10/20/140

* Arjan van de Ven <arjan@infradead.org> wrote:
> > Is that intentional though?  With <randon .config> my mm/swapfile.i has an
> > unreferenced
> > 
> > static inline void __raw_spin_unlock(raw_spinlock_t *lock)
> > {
> > 	__asm__ __volatile__(
> > 		"movb $1,%0" :"=m" (lock->slock) : : "memory" 
> > 	);
> > }
> > 
> > which either a) shouldn't be there or b) should be referenced.
> > 
> > Ingo, can you confirm that x86's spin_unlock is never inlined?  If so,
> > what's my __raw_spin_unlock() doing there?
__raw_spin_unlock is currently only inlined in the kernel/spinlock.c 
code.
> I would really want this one inlined!  A movb is a much shorter code 
> sequence than a call (esp if you factor in argument setup). 
> De-inlining to save space is nice and all, but it can go too far....
yeah, it makes sense to inline the single-instruction unlock operations: 
nondebug spin_unlock(), read_unlock() and write_unlock(). This gives a 
0.2% code-size reduction:
    text    data     bss     dec     hex filename
 4072031  858208  387196 5317435  51233b vmlinux-smp-uninlined
 4060671  858212  387196 5306079  50f6df vmlinux-smp-inlined
patch against -rc5. Boot-tested on a 4-way x86 SMP box.
	Ingo
Signed-off-by: Ingo Molnar <mingo@elte.hu>
 include/linux/spinlock.h |   15 ++++++++++++---
 1 files changed, 12 insertions(+), 3 deletions(-)
Index: linux/include/linux/spinlock.h
===================================================================
--- linux.orig/include/linux/spinlock.h
+++ linux/include/linux/spinlock.h
@@ -171,9 +171,18 @@ extern int __lockfunc generic__raw_read_
 #define write_lock_irq(lock)		_write_lock_irq(lock)
 #define write_lock_bh(lock)		_write_lock_bh(lock)
 
-#define spin_unlock(lock)		_spin_unlock(lock)
-#define write_unlock(lock)		_write_unlock(lock)
-#define read_unlock(lock)		_read_unlock(lock)
+/*
+ * We inline the unlock functions in the nondebug case:
+ */
+#ifdef CONFIG_DEBUG_SPINLOCK
+# define spin_unlock(lock)		_spin_unlock(lock)
+# define read_unlock(lock)		_read_unlock(lock)
+# define write_unlock(lock)		_write_unlock(lock)
+#else
+# define spin_unlock(lock)		__raw_spin_unlock(&(lock)->raw_lock)
+# define read_unlock(lock)		__raw_read_unlock(&(lock)->raw_lock)
+# define write_unlock(lock)		__raw_write_unlock(&(lock)->raw_lock)
+#endif
 
 #define spin_unlock_irqrestore(lock, flags) \
 					_spin_unlock_irqrestore(lock, flags)
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/