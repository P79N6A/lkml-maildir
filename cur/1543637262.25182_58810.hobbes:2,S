Date: Wed, 24 Jul 2002 01:00:00 -0700
From: Andrew Morton <>
Subject: Re: [patch] irqlock patch -G3. [was Re: odd memory corruptionin2.5.27?]
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2002/7/24/40

Ingo Molnar wrote:
> 
> On Tue, 23 Jul 2002, Andrew Morton wrote:
> 
> > Robert and George's patch doesn't seem to be optimal though - if we're
> > not going to preempt at spin_unlock() time, we need to preempt at
> > local_irq_restore() time.  It'll be untrivial to fix all this, but this
> > very subtle change to the locking semantics with CONFIG_PREEMPT is quite
> > nasty.
> 
> this is precisely the reason why we cannot pretend these bugs do not exist
> and just work this around in preempt_schedule().
But there is no bug in slab.  The bug is that spin_unlock() is
scheduling inside local_irq_disable().
> Code that relies on
> cli/sti for atomicity should be pretty rare and limited, there's 1 known
> case so far where it leads to bugs.
Are you implying that all code which does spin_unlock() inside
local_irq_disable() needs to be converted to use _raw_spin_unlock()?
If so then, umm, ugh.  I hope that the debug check is working
for CONFIG_PREEMPT=n.
BTW, what is the situation with spin_unlock_irq[restore]()?  Seems
that these will schedule inside local_irq_disable() quite a lot?
-
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/