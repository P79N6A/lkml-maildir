Date: Wed, 22 Nov 2006 14:38:35 +0000
From: Andy Whitcroft <>
Subject: [PATCH] numa node ids are int, page_to_nid and zone_to_nid should return int
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2006/11/22/112

numa node ids are int, page_to_nid and zone_to_nid should return int
NUMA node ids are passed as either int or unsigned int almost exclusivly
page_to_nid and zone_to_nid both return unsigned long.  This is a
throw back to when page_to_nid was a #define and was thus exposing
the real type of the page flags field.
In addition to fixing up the definitions of page_to_nid and zone_to_nid
I audited the users of these functions identifying the following
incorrect uses:
1) mm/page_alloc.c show_node() -- printk dumping the node id,
2) include/asm-ia64/pgalloc.h pgtable_quicklist_free() -- comparison
   against numa_node_id() which returns an int from cpu_to_node(), and
3) mm/mpolicy.c check_pte_range -- used as an index in node_isset which
   uses bit_set which in generic code takes an int.
Against 2.6.19-rc5-mm2.
Signed-off-by: Andy Whitcroft <apw@shadowen.org>
---
diff --git a/include/asm-ia64/pgalloc.h b/include/asm-ia64/pgalloc.h
index 9cb68e9..393e04c 100644
--- a/include/asm-ia64/pgalloc.h
+++ b/include/asm-ia64/pgalloc.h
@@ -60,7 +60,7 @@ static inline void *pgtable_quicklist_al
 static inline void pgtable_quicklist_free(void *pgtable_entry)
 {
 #ifdef CONFIG_NUMA
-	unsigned long nid = page_to_nid(virt_to_page(pgtable_entry));
+	int nid = page_to_nid(virt_to_page(pgtable_entry));
 
 	if (unlikely(nid != numa_node_id())) {
 		free_page((unsigned long)pgtable_entry);
diff --git a/include/linux/mm.h b/include/linux/mm.h
index d42985a..869042c 100644
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@ -455,7 +455,7 @@ static inline int page_zone_id(struct pa
 	return (page->flags >> ZONEID_PGSHIFT) & ZONEID_MASK;
 }
 
-static inline unsigned long zone_to_nid(struct zone *zone)
+static inline int zone_to_nid(struct zone *zone)
 {
 #ifdef CONFIG_NUMA
 	return zone->node;
@@ -465,9 +465,9 @@ static inline unsigned long zone_to_nid(
 }
 
 #ifdef NODE_NOT_IN_PAGE_FLAGS
-extern unsigned long page_to_nid(struct page *page);
+extern int page_to_nid(struct page *page);
 #else
-static inline unsigned long page_to_nid(struct page *page)
+static inline int page_to_nid(struct page *page)
 {
 	return (page->flags >> NODES_PGSHIFT) & NODES_MASK;
 }
diff --git a/mm/mempolicy.c b/mm/mempolicy.c
index b3dfecd..f7c352f 100644
--- a/mm/mempolicy.c
+++ b/mm/mempolicy.c
@@ -221,7 +221,7 @@ static int check_pte_range(struct vm_are
 	orig_pte = pte = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);
 	do {
 		struct page *page;
-		unsigned int nid;
+		int nid;
 
 		if (!pte_present(*pte))
 			continue;
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 19ab611..a795f85 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -1566,7 +1566,7 @@ unsigned int nr_free_pagecache_pages(voi
 static inline void show_node(struct zone *zone)
 {
 	if (NUMA_BUILD)
-		printk("Node %ld ", zone_to_nid(zone));
+		printk("Node %d ", zone_to_nid(zone));
 }
 
 /*
diff --git a/mm/sparse.c b/mm/sparse.c
index 158d6a2..ac26eb0 100644
--- a/mm/sparse.c
+++ b/mm/sparse.c
@@ -36,7 +36,7 @@ static u8 section_to_node_table[NR_MEM_S
 static u16 section_to_node_table[NR_MEM_SECTIONS] __cacheline_aligned;
 #endif
 
-unsigned long page_to_nid(struct page *page)
+int page_to_nid(struct page *page)
 {
 	return section_to_node_table[page_to_section(page)];
 }
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/