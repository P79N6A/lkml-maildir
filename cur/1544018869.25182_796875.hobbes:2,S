Date: Mon, 26 Jan 2009 14:07:03 +0100
From: Ingo Molnar <>
Subject: Re: [PATCH 1/2] x86: optimize a bit __raw_read_trylock
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2009/1/26/84

* Frederic Weisbecker <fweisbec@gmail.com> wrote:
> The current version of __raw_read_trylock starts with decrementing the lock
> and read its new value as a separate operation after that.
> 
> That makes 3 dereferences (read, write (after sub), read) whereas
> a single atomic_dec_return does only two pointers dereferences (read, write).
> 
> Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
> ---
>  arch/x86/include/asm/spinlock.h |    3 +--
>  1 files changed, 1 insertions(+), 2 deletions(-)
> 
> diff --git a/arch/x86/include/asm/spinlock.h b/arch/x86/include/asm/spinlock.h
> index 2bd6b11..139b424 100644
> --- a/arch/x86/include/asm/spinlock.h
> +++ b/arch/x86/include/asm/spinlock.h
> @@ -267,8 +267,7 @@ static inline int __raw_read_trylock(raw_rwlock_t *lock)
>  {
>  	atomic_t *count = (atomic_t *)lock;
> 
> -	atomic_dec(count);
> -	if (atomic_read(count) >= 0)
> +	if (atomic_dec_return(count) >= 0)
>  		return 1;
>  	atomic_inc(count);
>  	return 0;
nice one ... applied it to tip/x86/asm, thanks Frederic!
	Ingo