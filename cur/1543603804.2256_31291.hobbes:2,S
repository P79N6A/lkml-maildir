Date: 06 Oct 2001 23:24:02 -0400
From: Thomas Hood <>
Subject: Re: Question about rtc_lock
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2001/10/6/122

On Sat, 2001-10-06 at 11:24, Jonathan Lundell wrote:
> rtc_interrupt(), you mean.
Right.
> Even if there weren't current interrupt code doing CMOS accesses, it 
> would seem prudent to assume that there might be eventually, the 
> RTC/NVRAM being a multi-purpose shared resource.
I'm not concerned about an irq handler (present or future)
interfering with us as we write to the CMOS RAM.  What I'm
concerned about is getting a rtc interrupt while we hold rtc_lock,
with deadlock being the result (since rtc_interrupt will spin on
the lock).
Either (1) we need to change these spinlocks to _irq, or (2) we
need to know that this bit of code runs only with irqs disabled.
My question is: Is it (1) or (2)?
Or is it (3) Thomas Hood is failing to understand something here?
Assuming the answer is (1), I append a patch that changes the
spinlock calls to _irqsave versions.
Cheers,
Thomas
The patch:
--- linux-2.4.10-ac5-fix/arch/i386/kernel/bootflag.c_PREV	Fri Oct  5 23:20:43 2001
+++ linux-2.4.10-ac5-fix/arch/i386/kernel/bootflag.c	Sat Oct  6 23:15:33 2001
@@ -81,26 +81,30 @@
 
 static void __init sbf_write(u8 v)
 {
+	unsigned long flags;
+
 	if(sbf_port != -1)
 	{
 		v &= ~(1<<7);
 		if(!parity(v))
 			v|=1<<7;
 			
-		spin_lock(&rtc_lock);
+		spin_lock_irqsave(&rtc_lock, flags);
 		CMOS_WRITE(v, sbf_port);
-		spin_unlock(&rtc_lock);
+		spin_unlock_irqrestore(&rtc_lock, flags);
 	}
 }
 
 static u8 __init sbf_read(void)
 {
 	u8 v;
+	unsigned long flags;
+
 	if(sbf_port == -1)
 		return 0;
-	spin_lock(&rtc_lock);
+	spin_lock_irqsave(&rtc_lock, flags);
 	v = CMOS_READ(sbf_port);
-	spin_unlock(&rtc_lock);
+	spin_unlock_irqrestore(&rtc_lock, flags);
 	return v;
 }
 
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/