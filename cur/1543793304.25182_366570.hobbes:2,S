Date: Sun, 13 Nov 2005 12:19:20 +0100
From: "Miro Dietiker, MD Systems" <>
Subject: AW: Locking md device and system for several seconds
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2005/11/13/33

:-)
>Can you check which IO scheduler the drives are using, try different
>schedulers, and see if it makes a different.
there was [anticipatory] selected.
ORIGINAL:
tiger:~#  grep . /sys/block/*/queue/scheduler
/sys/block/fd0/queue/scheduler:noop [anticipatory] deadline cfq
/sys/block/hdd/queue/scheduler:noop [anticipatory] deadline cfq
/sys/block/sda/queue/scheduler:noop [anticipatory] deadline cfq
/sys/block/sdb/queue/scheduler:noop [anticipatory] deadline cfq
NEW:
tiger:~#  grep . /sys/block/*/queue/scheduler
/sys/block/fd0/queue/scheduler:noop anticipatory deadline [cfq]
/sys/block/hdd/queue/scheduler:noop anticipatory deadline [cfq]
/sys/block/sda/queue/scheduler:noop anticipatory deadline [cfq]
/sys/block/sdb/queue/scheduler:noop anticipatory deadline [cfq]
System seems to work, but I need some testing time to check that
behaviour. (Any suggestion of a testing tool to generate disk
traffic and reporting response-times and throughput?)
Which is the right way / position on bootup to set this field
permanent to this value and what exactly did I change with this
modification? (Performance issues?)
I'm using debian..
I also need to check this on the other (identical) machines.
Thanks! Miro Dietiker
-----UrsprÃ¼ngliche Nachricht-----
Von: Neil Brown [mailto:neilb@suse.de] 
Gesendet: Sonntag, 13. November 2005 11:41
An: Miro Dietiker, MD Systems
Cc: linux-kernel@vger.kernel.org
Betreff: Re: Locking md device and system for several seconds
On Sunday November 13, info@md-systems.ch wrote:
> Hi!
> 
> I'm using kernel 2.6.14.2 with md (RAID1 static) as bootable.
> 
> While md synching (initial creation or after marked one as failed,
> removed and re-added) there are some locking problems with the
> complete system/kernel.
Can you check which IO scheduler the drives are using, try different
schedulers, and see if it makes a different.
     grep . /sys/block/*/queue/scheduler
will show you (the one in [brackets] is active). 
Then just echo a new value out to each file.
I've had one report that [anticipatory] causes this problem and [cfq]
removes it.  Could you confirm that?
Thanks,
NeilBrown
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/