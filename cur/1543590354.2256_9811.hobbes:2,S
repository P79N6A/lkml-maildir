Date: Tue, 8 May 2001 16:00:56 -0400
From: Pete Wyckoff <>
Subject: Re: [RFC] Direct Sockets Support??
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2001/5/8/127

alan@lxorguk.ukuu.org.uk said:
> > A couple of concerns I have:
> >  * How to pin or pagelock the application buffer without
> > making a kernel transition.
> 
> You need to pin them in advance. And pinning pages is _expensive_ so you dont
> want to keep pinning/unpinning pages
I can't convince myself why this has to be so expensive.  The
current implementation does this for mlock:
    1.  Split vma if only a subset of the pages are being locked.
    2.  Mark bit in vma.
    3.  Make sure the pages are in core.
That third step has the potential of being the most expensive,
as changing the page tables requires invalidating the TLBs on all
processors.  Currently make_pages_present() does the work for 3.
But in the case of an application which fits in main memory, and
has been running for a while (so all pages are present and
dirty), all you'd really have to do is verify the page tables are
in the proper state and skip the TLB flush, right?
Then 3 turns into a single spin_lock pair for the page_table_lock, 
and walking down the page table.
The VMA splitting can be nasty, as it might require a couple of
slab allocations, and doing an AVL insertion.  (More nastiness in
the case of shared memory or file mapping, too.)  But nothing
like playing with TLBs.
Any reason why make_pages_present() is not the really oversized
hammer it seems to be?
		-- Pete
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/