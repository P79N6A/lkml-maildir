Date: Mon, 22 Jul 2002 20:28:21 +0200 (CEST)
From: Ingo Molnar <>
Subject: [patch] scheduler bits for 2.5.27, -C0
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2002/7/22/265

updated scheduler changes/fixes, against 2.5.27-BK + cli-sti-cleanup-B2 +
remove-irqlock-E0:
   
http://redhat.com/~mingo/O
(1)-scheduler/sched-2.5.27-C0
Bugfixes:
 - introduce new type of context-switch locking, this is a must-have for
   ia64 and sparc64.
 - load_balance() bug noticed by Scott Rhine and myself: scan the
   whole list to find imbalance number of tasks, not just the tail
   of the list.
 - sched_yield() fix: use current->array not rq->active.
Features:
 - SCHED_BATCH feature.
 - ->first_time_slice to limit the number of timeslices 'won' via child
   exit - this is the logical equivalent of the child-timeslice
   distribution change in Andrea's tree.
 - sched_yield() cleanup and simplification: yielding puts the task
   into the expired queue. This eliminates spurious yields in which
   the same task repeatedly calls into yield() without achieving
   anything. It's also the most logical thing to do - the yielder
   has asked for other tasks to be scheduled first.
Cleanups, smaller changes:
 - simpler locking in schedule_tail().
 - load_balance() cleanup: split up into find_busiest_queue(),
   pull_task() and load_balance() functions.
 - idle_tick() cleanups: use a parameter already existing in the
   calling function.
 - scheduler_tick() cleanups: use more intuitive variable names.
 - remove obsolete comments.
 - clear ->first_time_slice when a new timeslice is calculated.
 - move the sched initialization code to the end of sched.c.
 - no need for nr_uninterruptible to be signed.
	Ingo
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/