Date: Mon, 31 Jan 2000 12:48:31 -0500
From: Larry Woodman <>
Subject: Re: Eliminating bounce buffers
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/1/31/134

"Stephen C. Tweedie" wrote:
> Hi,
>
> On Fri, 28 Jan 2000 11:29:29 -0500, Larry Woodman
> <woodman@missioncriticallinux.com> said:
>
> > I have a patch for 2.3.40 which eliminates the whole idea of bounce
> > buffers and prepare_highmem_swapout()/replace_with_highmem() for big
> > memory Intel systems.  The way it works is rather than copying high
> > memory pages to and from low memory pages before scheduling IO, I map
> > highmem pages into virtual addresses up in the vmalloc address space
> > (via get_vm_area) and put this virtual address in the b_data field of
> > the buffer_head for the duration of the IO operation.
>
> ...
>
> > This seems to be cleaner than doing IO to lower physical address pages
> > and copying to and from highmem pages, or am I missing something
> > here???
>
> Yes.  With more than 4G of memory, you still need bounce buffers unless
> your device drivers are *all* capable of supporting 64-bit addressing
> (either via PCI-64 or through dual address cycles).
>
> For addresses below 4G, your method may make sense.  I'd want to be
> really sure that all devices will support those high addresses before
> enabling it by default, though.
>
> --Stephen
Yes, I totally agree that after we pass 4GB of physical memory we still
need
to copy to pages which are less than 4GB before doing IO.  Do you think its
worth having yet another zone for this???
Larry
begin:vcard 
n:Woodman;Larry
x-mozilla-html:TRUE
org:Mission Critical Linux
adr:;;;;;;
version:2.1
email;internet:woodman@missioncriticallinux.com
title:Director Of Engineering
x-mozilla-cpt:;-8928
fn:Larry Woodman
end:vcard