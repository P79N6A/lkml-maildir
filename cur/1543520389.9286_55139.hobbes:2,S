Date: Fri, 24 Dec 1999 10:53:11 -0500
From: Mark Lord <>
Subject: Re: Fix for ide problems in 2.2.14pre15
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/12/24/36

Petri Kaukasoina wrote:
> 
> On Tue, Dec 21, 1999 at 05:01:37PM -0500, Mark Lord wrote:
> > Does this one-liner make any difference?
> 
> Unfortunately no,
> 
> ide-2.2.14pre15.try1:  no difference
> ide-2.2.14pre15.try2:  no difference
> both at the same time: no difference
Okay, this is ugly, but it's the same as we had in 2.2.13.
Does the attached patch help?
It should, cuz there's nuthin else left to try!
-- 
Mark Lord
Real-Time Remedies Inc.
mlord@pobox.com--- linux-2.2.14pre15ac+/drivers/block/ide.c.orig	Sun Dec 19 17:11:35 1999
+++ linux-2.2.14pre15ac+/drivers/block/ide.c	Fri Dec 24 10:49:37 1999
@@ -1243,7 +1243,7 @@
  * the driver.  This makes the driver much more friendlier to shared IRQs
  * than previous designs, while remaining 100% (?) SMP safe and capable.
  */
-static void ide_do_request (ide_hwgroup_t *hwgroup)
+static void ide_do_request (ide_hwgroup_t *hwgroup, int masked_irq)
 {
 	struct blk_dev_struct *bdev;
 	ide_drive_t	*drive;
@@ -1303,11 +1303,15 @@
 		if (bdev->current_request == &bdev->plug)	/* FIXME: paranoia */
 			printk("%s: Huh? nuking plugged queue\n", drive->name);
 		bdev->current_request = hwgroup->rq = drive->queue;
+		if (hwif->irq != masked_irq)
+			disable_irq_nosync(hwif->irq);
 		spin_unlock(&io_request_lock);
 		if (!hwif->serialized)	/* play it safe with buggy hardware */
 			ide__sti();
 		startstop = start_request(drive);
 		spin_lock_irq(&io_request_lock);
+		if (hwif->irq != masked_irq)
+			enable_irq(hwif->irq);
 		if (startstop == ide_stopped)
 			hwgroup->busy = 0;
 	}
@@ -1325,69 +1329,69 @@
 
 void do_ide0_request (void)
 {
-	ide_do_request (ide_hwifs[0].hwgroup);
+	ide_do_request (ide_hwifs[0].hwgroup, 0);
 }
 
 #if MAX_HWIFS > 1
 void do_ide1_request (void)
 {
-	ide_do_request (ide_hwifs[1].hwgroup);
+	ide_do_request (ide_hwifs[1].hwgroup, 0);
 }
 #endif /* MAX_HWIFS > 1 */
 
 #if MAX_HWIFS > 2
 void do_ide2_request (void)
 {
-	ide_do_request (ide_hwifs[2].hwgroup);
+	ide_do_request (ide_hwifs[2].hwgroup, 0);
 }
 #endif /* MAX_HWIFS > 2 */
 
 #if MAX_HWIFS > 3
 void do_ide3_request (void)
 {
-	ide_do_request (ide_hwifs[3].hwgroup);
+	ide_do_request (ide_hwifs[3].hwgroup, 0);
 }
 #endif /* MAX_HWIFS > 3 */
 
 #if MAX_HWIFS > 4
 void do_ide4_request (void)
 {
-	ide_do_request (ide_hwifs[4].hwgroup);
+	ide_do_request (ide_hwifs[4].hwgroup, 0);
 }
 #endif /* MAX_HWIFS > 4 */
 
 #if MAX_HWIFS > 5
 void do_ide5_request (void)
 {
-	ide_do_request (ide_hwifs[5].hwgroup);
+	ide_do_request (ide_hwifs[5].hwgroup, 0);
 }
 #endif /* MAX_HWIFS > 5 */
 
 #if MAX_HWIFS > 6
 void do_ide6_request (void)
 {
-	ide_do_request (ide_hwifs[6].hwgroup);
+	ide_do_request (ide_hwifs[6].hwgroup, 0);
 }
 #endif /* MAX_HWIFS > 6 */
 
 #if MAX_HWIFS > 7
 void do_ide7_request (void)
 {
-	ide_do_request (ide_hwifs[7].hwgroup);
+	ide_do_request (ide_hwifs[7].hwgroup, 0);
 }
 #endif /* MAX_HWIFS > 7 */
 
 #if MAX_HWIFS > 8
 void do_ide8_request (void)
 {
-	ide_do_request (ide_hwifs[8].hwgroup);
+	ide_do_request (ide_hwifs[8].hwgroup, 0);
 }
 #endif /* MAX_HWIFS > 8 */
 
 #if MAX_HWIFS > 9
 void do_ide9_request (void)
 {
-	ide_do_request (ide_hwifs[9].hwgroup);
+	ide_do_request (ide_hwifs[9].hwgroup, 0);
 }
 #endif /* MAX_HWIFS > 9 */
 
@@ -1458,7 +1462,7 @@
 				hwgroup->busy = 0;
 		}
 	}
-	ide_do_request(hwgroup);
+	ide_do_request(hwgroup, 0);
 	spin_unlock_irqrestore(&io_request_lock, flags);
 }
 
@@ -1605,7 +1609,7 @@
 	if (startstop == ide_stopped) {
 		if (hwgroup->handler == NULL) {	/* paranoia */
 			hwgroup->busy = 0;
-			ide_do_request(hwgroup);
+			ide_do_request(hwgroup, hwif->irq);
 		} else {
 			printk("%s: ide_intr: huh? expected NULL handler on exit\n", drive->name);
 		}
@@ -1710,7 +1714,7 @@
 		rq->next = cur_rq->next;
 		cur_rq->next = rq;
 	}
-	ide_do_request(hwgroup);
+	ide_do_request(hwgroup, 0);
 	spin_unlock_irqrestore(&io_request_lock, flags);
 	if (action == ide_wait) {
 		down(&sem);			/* wait for it to be serviced */