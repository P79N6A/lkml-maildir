Date: Sun, 19 Sep 2004 16:07:38 +0200
From: Dominik Brodowski <>
Subject: boot_cpu_data vs current_cpu_data in voluntary-preempt-2.6.9-rc2-mm1-S1
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2004/9/19/52

Ingo,
Your voluntary-preempt-2.6.9-rc2-mm1-S1 patch contains this change
@@ -34,7 +34,7 @@ inline void __const_udelay(unsigned long
 	xloops *= 4;
 	__asm__("mull %0"
 		:"=d" (xloops), "=&a" (d0)
-		:"1" (xloops),"0" (current_cpu_data.loops_per_jiffy *
(HZ/4)));
+		:"1" (xloops),"0" (boot_cpu_data.loops_per_jiffy * (HZ/4)));
         __delay(++xloops);
 }
for both x86 and x86_64. And it's wrong. It assumes loops_per_jiffy being
consistent on all CPUs. There _are_ asymetric multiprocessor systems out
there, and some SMP systems can become asymetric as soon as
frequency scaling is enabled. Using boot_cpu_data's loops_per_jiffy instead
of current_cpu_data's loops_per_jiffy causes delays being too short or too
long. So please drop this change.
Thanks,
	Dominik
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/