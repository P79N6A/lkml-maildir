Date: Thu, 20 Jul 2000 10:53:21 -0400 (EDT)
From: "Richard B. Johnson" <>
Subject: Re: An important fact about real time computing
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/7/20/51

On Thu, 20 Jul 2000 yodaiken@fsmlabs.com wrote:
> On Thu, Jul 20, 2000 at 12:01:30PM +0200, David Balazic wrote:
> > yodaiken@fsmlabs.com wrote:
> > > 
> > > On Wed, Jul 19, 2000 at 03:47:01PM -0400, David Mansfield wrote:
> > > > David Balazic wrote:
> > > > >
> > > > > The first sentence my professor maid on the real time computing
> > > > > course was :
> > > > >
> > > > > "A common misconception : Real-time computing is fast computing."
> > > 
> > > This is the standard lecture, but don't take it too far.  You can control
> > > a robot with deterministic latecnies under 50 usecs, but not with
> > > deterministic latencies of 10 minutes.
> > 
> > Yes , but not every process has usec requirements.
> > Think house heating control etc ...
> 
> So deterministic response is necessary for all hard RT, but the range
> of hard RT problems that can be solved is a function of worst case
> latencies.
> 
Early on when you wanted to make a digital controller, you'd
use a dedicated uP that executed a loop, keyed to some timer.
Before that, you'd use analog circuits which usually worked
better than their digital counterparts.
This would provide, not only a deterministic response to external
events, but also a deterministic stimulus of the controlled
functions or processes.
If you needed to servo, i.e., minimize error coefficients, it
became necessary to not only have a deterministic response, but
also to sample external data at precise intervals. This happens
because these sampled data inputs create poles in the overall
system's transfer function. The precise location of these poles
are a necessary condition for both stability and the minimization
of controlled system errors.
As systems became more complex, the trend was to model the controlled
system in software using pure mathematics. The required response
of the model's many nodes were compared with the controlled item's
actual response on a continuous basis. The mathematical model runs
as a continuous function, emulating the physical model. Control
stimulus is applied to the physical module to keep it in track with
the mathematical module. This provides for the control of very complex
machines such as unstable aircraft. For this to work, the sample
interval for the physical model, external to the computer, and the
mathematical model within, has to be precise. 
This leads to the requirement of a "Real-time Operating System".
Real-time does not mean "fast". Real-time means "fast enough", but
"precise".
Many systems can be controlled using a relatively slow sample and
control rate. A power generation plant comes to mind. A one-second
sample rate may be sufficient because it takes a long time for
things to change and a long time to change things. It may take
15 minutes to get a 40-ton turbo-generator rotor up to speed.
The sampling of the speed at precise intervals, over some previous
history, allows mathematics to predict the time-interval at which
the speed will be within specification. The servo model allows
the system dynamics to be controlled so that the machine will
settle at its final speed with little or no overshoot. If the
sampling interval is not precise, the prediction will be in error.
Since the sampled data system emulates a low-pass filter, the
sample time error is the major contributor to the error budget
in such a commonplace system. It has the linear relationship of
TC=RC.
So, if the rotor of our prototypical system has to maintain a speed
within 0.001 percent, then the one-second intervals at which the data
are acquired must be maintained within 0.001 percent. 
Many Operating Systems will provide an "average" sample rate
exceeding this. However, you can't average these external stimuli.
If you try, you end up with another pole, plus its attendant
phase-shift, in the system's feedback loop. This will require that
the loop-gain be reduced (increasing error), by the same amount
that the phase-margin has been reduced. The result being that the
system error increases by the filter coefficient (in the same
dimension).
A Real-time Operating  System will guarantee that something programmed
to occur will,  in fact,  happen within a specified time. That's all
it means.
Cheers,
Dick Johnson
Penguin : Linux version 2.2.15 on an i686 machine (797.90 BogoMips).
"Memory is like gasoline. You use it up when you are running. Of
course you get it all back when you reboot..."; Actual explanation
obtained from the Micro$oft help desk.
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/