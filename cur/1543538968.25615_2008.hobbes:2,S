Date: Fri, 14 Jul 2000 21:54:35 +0200 (CEST)
From: Andrea Arcangeli <>
Subject: Re: 2.4.0test3-pre6 hogging mem for cache
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/7/14/140

On Fri, 14 Jul 2000, Andrea Arcangeli wrote:
>If somebody developed the code for page->pte reverse lookup I'd love if we
>could synchronize since that is something completly indipendent from its
Last snapshot I see from DaveM implements it with an anon_area structure
that basically only contains an address_space structure. This anon_area is
allocated dynamically per each new anonymous page with the slab. That
looks rather slow. Then it chains the vmas that are mapping such anon
page into the address_space->i_mmap plus it sets page->index to the
offset of the page in the vma, so later (when we want to do the
reverse lookup) we walk the page->mapping->i_mmap chain of vmas, and for
each one we get the vma->vm_mm (MM) and plus the page->index information
we can reach all the ptes that are mapping to the page by walking the
pgd/pmd of each MM. This way doesn't look very light but it definitely
works.
I was wondering if it was possible to use something of more dedicated for
that reverse lookup purpose that would possibly avoid (at least sometime)
a new slab allocation per each anon page allocated. As secondary issue I'd
also like to not have to walk pgd/pmd but it would be nice to just get the
pte_t * pointer with only a pointer dereference given the 'struct page'
but maybe I'm asking too much ... ;).
Andrea
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/