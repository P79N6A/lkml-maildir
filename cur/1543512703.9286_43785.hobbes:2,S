Date: Tue, 12 Oct 1999 23:06:05 +0200
From: Martin Dalecki <>
Subject: PATCH - assembler glitches
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/10/12/117

The attached patch is sweepping out obvious errors in IA32 assembler
code.
Just apply it.
--Marcin Daleckidiff -ur linux/arch/i386/boot/bootsect.S linux-2.3.21/arch/i386/boot/bootsect.S
--- linux/arch/i386/boot/bootsect.S	Tue Oct 12 22:46:57 1999
+++ linux-2.3.21/arch/i386/boot/bootsect.S	Tue Oct 12 19:51:33 1999
@@ -401,7 +401,7 @@
 	pushw	%dx
 	movw	$0x3f2, %dx
 	xorb	%al, %al
-	outw	%al, %dx
+	outb	%al, %dx
 	popw	%dx
 	ret
 
diff -ur linux/arch/i386/kernel/entry.S linux-2.3.21/arch/i386/kernel/entry.S
--- linux/arch/i386/kernel/entry.S	Tue Oct 12 22:46:49 1999
+++ linux-2.3.21/arch/i386/kernel/entry.S	Tue Oct 12 22:40:12 1999
@@ -92,8 +92,8 @@
 	pushl %ecx; \
 	pushl %ebx; \
 	movl $(__KERNEL_DS),%edx; \
-	movl %dx,%ds; \
-	movl %dx,%es;
+	movw %dx,%ds; \
+	movw %dx,%es;
 
 #define RESTORE_ALL	\
 	popl %ebx;	\
@@ -285,15 +285,15 @@
 	pushl %ecx
 	pushl %ebx
 	cld
-	movl %es,%cx
+	movw %es,%cx
 	xchgl %eax, ORIG_EAX(%esp)	# orig_eax (get the error code. )
 	movl %esp,%edx
 	xchgl %ecx, ES(%esp)		# get the address and save es.
 	pushl %eax			# push the error code
 	pushl %edx
 	movl $(__KERNEL_DS),%edx
-	movl %dx,%ds
-	movl %dx,%es
+	movw %dx,%ds
+	movw %dx,%es
 	GET_CURRENT(%ebx)
 	call *%ecx
 	addl $8,%esp
diff -ur linux/arch/i386/kernel/head.S linux-2.3.21/arch/i386/kernel/head.S
--- linux/arch/i386/kernel/head.S	Tue Oct 12 22:46:49 1999
+++ linux-2.3.21/arch/i386/kernel/head.S	Tue Oct 12 22:31:17 1999
@@ -46,10 +46,10 @@
  */
 	cld
 	movl $(__KERNEL_DS),%eax
-	movl %ax,%ds
-	movl %ax,%es
-	movl %ax,%fs
-	movl %ax,%gs
+	movw %ax,%ds
+	movw %ax,%es
+	movw %ax,%fs
+	movw %ax,%gs
 #ifdef __SMP__
 	orw %bx,%bx
 	jz 1f
@@ -230,13 +230,13 @@
 	lidt idt_descr
 	ljmp $(__KERNEL_CS),$1f
 1:	movl $(__KERNEL_DS),%eax	# reload all the segment registers
-	movl %ax,%ds		# after changing gdt.
-	movl %ax,%es
-	movl %ax,%fs
-	movl %ax,%gs
+	movw %ax,%ds		# after changing gdt.
+	movw %ax,%es
+	movw %ax,%fs
+	movw %ax,%gs
 #ifdef __SMP__
 	movl $(__KERNEL_DS), %eax
-	mov  %ax,%ss		# Reload the stack pointer (segment only)
+	movw  %ax,%ss		# Reload the stack pointer (segment only)
 #else
 	lss stack_start,%esp	# Load processor stack
 #endif
@@ -322,8 +322,8 @@
 	pushl %es
 	pushl %ds
 	movl $(__KERNEL_DS),%eax
-	movl %ax,%ds
-	movl %ax,%es
+	movw %ax,%ds
+	movw %ax,%es
 	pushl $int_msg
 	call SYMBOL_NAME(printk)
 	popl %eax
diff -ur linux/arch/i386/kernel/process.c linux-2.3.21/arch/i386/kernel/process.c
--- linux/arch/i386/kernel/process.c	Wed Aug 18 20:11:15 1999
+++ linux-2.3.21/arch/i386/kernel/process.c	Tue Oct 12 22:01:51 1999
@@ -2,6 +2,10 @@
  *  linux/arch/i386/kernel/process.c
  *
  *  Copyright (C) 1995  Linus Torvalds
+ *
+ * Tue Oct 12 1999 Marcin Dalecki <dalecki@cs.net.pl>:
+ * - Fixed obvious assembler glitches.
+ *
  */
 
 /*
@@ -291,11 +295,11 @@
 	   the values are consistent for real mode operation already. */
 
 	__asm__ __volatile__ ("movl $0x0010,%%eax\n"
-				"\tmovl %%ax,%%ds\n"
-				"\tmovl %%ax,%%es\n"
-				"\tmovl %%ax,%%fs\n"
-				"\tmovl %%ax,%%gs\n"
-				"\tmovl %%ax,%%ss" : : : "eax");
+				"\tmovw %%ax,%%ds\n"
+				"\tmovw %%ax,%%es\n"
+				"\tmovw %%ax,%%fs\n"
+				"\tmovw %%ax,%%gs\n"
+				"\tmovw %%ax,%%ss" : : : "eax");
 
 	/* Jump to the 16-bit code that we copied earlier.  It disables paging
 	   and the cache, switches to real mode, and jumps to the BIOS reset
@@ -424,7 +428,7 @@
 void forget_segments(void)
 {
 	/* forget local segments */
-	__asm__ __volatile__("movl %w0,%%fs ; movl %w0,%%gs"
+	__asm__ __volatile__("movw %w0,%%fs ; movw %w0,%%gs"
 		: /* no outputs */
 		: "r" (0));
 
diff -ur linux/arch/i386/kernel/signal.c linux-2.3.21/arch/i386/kernel/signal.c
--- linux/arch/i386/kernel/signal.c	Thu Jul 22 18:47:55 1999
+++ linux-2.3.21/arch/i386/kernel/signal.c	Tue Oct 12 22:10:45 1999
@@ -339,9 +339,9 @@
 	int tmp, err = 0;
 
 	tmp = 0;
-	__asm__("movl %%gs,%w0" : "=r"(tmp): "0"(tmp));
+	__asm__ __volatile__ ("movw %%gs,%w0" : "=r"(tmp): "0"(tmp));
 	err |= __put_user(tmp, (unsigned int *)&sc->gs);
-	__asm__("movl %%fs,%w0" : "=r"(tmp): "0"(tmp));
+	__asm__ __volatile__ ("movw %%fs,%w0" : "=r"(tmp): "0"(tmp));
 	err |= __put_user(tmp, (unsigned int *)&sc->fs);
 
 	err |= __put_user(regs->xes, (unsigned int *)&sc->es);
diff -ur linux/arch/i386/kernel/traps.c linux-2.3.21/arch/i386/kernel/traps.c
--- linux/arch/i386/kernel/traps.c	Tue Oct 12 22:46:49 1999
+++ linux-2.3.21/arch/i386/kernel/traps.c	Tue Oct 12 22:26:54 1999
@@ -2,6 +2,10 @@
  *  linux/arch/i386/traps.c
  *
  *  Copyright (C) 1991, 1992  Linus Torvalds
+ *
+ * Tue Oct 12 1999 Marcin Dalecki <dalecki@cs.net.pl>:
+ * - Fixed obvious assembler glitches.
+ *
  */
 
 /*
@@ -660,7 +664,7 @@
 		((limit) & 0x0ffff); }
 
 #define _set_tssldt_desc(n,addr,limit,type) \
-__asm__ __volatile__ ("movw %3,0(%2)\n\t" \
+__asm__ __volatile__ ("movw %w3,0(%2)\n\t" \
 	"movw %%ax,2(%2)\n\t" \
 	"rorl $16,%%eax\n\t" \
 	"movb %%al,4(%2)\n\t" \
diff -ur linux/arch/i386/kernel/vm86.c linux-2.3.21/arch/i386/kernel/vm86.c
--- linux/arch/i386/kernel/vm86.c	Tue Jul 20 00:23:49 1999
+++ linux-2.3.21/arch/i386/kernel/vm86.c	Tue Oct 12 22:20:16 1999
@@ -2,6 +2,10 @@
  *  linux/kernel/vm86.c
  *
  *  Copyright (C) 1994  Linus Torvalds
+ *
+ * Tue Oct 12 1999 Marcin Dalecki <dalecki@cs.net.pl>:
+ * - Fixed obvious assembler glitches.
+ *
  */
 #include <linux/errno.h>
 #include <linux/sched.h>
@@ -260,7 +264,7 @@
 		mark_screen_rdonly(tsk);
 	unlock_kernel();
 	__asm__ __volatile__(
-		"xorl %%eax,%%eax; movl %%ax,%%fs; movl %%ax,%%gs\n\t"
+		"xorl %%eax,%%eax; movw %%ax,%%fs; movw %%ax,%%gs\n\t"
 		"movl %0,%%esp\n\t"
 		"jmp ret_from_sys_call"
 		: /* no outputs */
diff -ur linux/include/asm-i386/hw_irq.h linux-2.3.21/include/asm-i386/hw_irq.h
--- linux/include/asm-i386/hw_irq.h	Tue Oct 12 22:46:53 1999
+++ linux-2.3.21/include/asm-i386/hw_irq.h	Tue Oct 12 22:26:56 1999
@@ -124,8 +124,8 @@
 	"pushl %ecx\n\t" \
 	"pushl %ebx\n\t" \
 	"movl $" STR(__KERNEL_DS) ",%edx\n\t" \
-	"movl %dx,%ds\n\t" \
-	"movl %dx,%es\n\t"
+	"movw %dx,%ds\n\t" \
+	"movw %dx,%es\n\t"
 
 #define IRQ_NAME2(nr) nr##_interrupt(void)
 #define IRQ_NAME(nr) IRQ_NAME2(IRQ##nr)
diff -ur linux/include/asm-i386/processor.h linux-2.3.21/include/asm-i386/processor.h
--- linux/include/asm-i386/processor.h	Tue Oct 12 22:46:53 1999
+++ linux-2.3.21/include/asm-i386/processor.h	Tue Oct 12 22:01:50 1999
@@ -2,6 +2,10 @@
  * include/asm-i386/processor.h
  *
  * Copyright (C) 1994 Linus Torvalds
+ *
+ * Tue Oct 12 1999 Marcin Dalecki <dalecki@cs.net.pl>:
+ * - Fixed obvious assembler glitches.
+ *
  */
 
 #ifndef __ASM_I386_PROCESSOR_H
@@ -158,7 +162,7 @@
 		"orl %0,%%eax\n\t"
 		"movl %%eax,%%cr4\n"
 		: : "irg" (mask)
-		:"ax");
+		:"eax");
 }
 
 static inline void clear_in_cr4 (unsigned long mask)
@@ -168,7 +172,7 @@
 		"andl %0,%%eax\n\t"
 		"movl %%eax,%%cr4\n"
 		: : "irg" (~mask)
-		:"ax");
+		:"eax");
 }
 
 /*
@@ -344,7 +348,7 @@
 }
 
 #define start_thread(regs, new_eip, new_esp) do {		\
-	__asm__("movl %w0,%%fs ; movl %w0,%%gs": :"r" (0));	\
+	__asm__ __volatile__ ("movw %w0,%%fs ; movw %w0,%%gs": :"r" (0));	\
 	set_fs(USER_DS);					\
 	regs->xds = __USER_DS;					\
 	regs->xes = __USER_DS;					\