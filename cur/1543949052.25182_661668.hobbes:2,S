Date: Fri, 29 Feb 2008 18:42:14 +0100
From: Peter Zijlstra <>
Subject: Re: [RFC/PATCH] RLIMIT_ARG_MAX
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/2/29/237

On Fri, 2008-02-29 at 09:29 -0800, Linus Torvalds wrote:
> 
> On Fri, 29 Feb 2008, Peter Zijlstra wrote:
> >
> > > ... and what's the point? We've never had it before, nobody has ever cared, 
> > > and the whole notion is just stupid. Why would we want to limit it? The 
> > > only thing that the kernel *cares* about is the stack size - any other 
> > > size limits are always going to be arbitrary.
> > 
> > Well, don't think of limiting it, but querying the limit.
> > 
> > Programs like xargs would need to know how much to stuff into argv
> > before starting a new invocation.
> 
> But they already can't really do that. 
I think they used to use sysconf(_SC_ARG_MAX) to do that.
> More importantly, isn't it better to just use the whole stack size then 
Well, we ran into trouble of freshly spawned tasks faulting on the first
stack grow. The /4 thing was to avoid that situation.
> (or just return "stack size / 4" or whatever)?
I'm all for that, trouble is that the POSIX folks specified that the
sysconf() value must be consistent during the lifetime of a process.
Which isn't true, because we can change rlimit_stack after asking. And
the linux implementation doesn't even seem to bother asking the kernel -
so there just isn't much we _can_ do here.
My suggestion was a kernel version check along with sysconf or
rlimit_stack. But I guess that made the userspace people puke :-)