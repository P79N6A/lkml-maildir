Date: Tue, 09 Dec 2008 16:11:56 +0100
From: Peter Zijlstra <>
Subject: Re: [PATCH 1/1] sched: CPU remove deadlock fix
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/12/9/131

On Tue, 2008-12-09 at 15:59 +0100, Peter Zijlstra wrote:
> On Tue, 2008-12-09 at 15:52 +0100, Peter Zijlstra wrote:
> > On Tue, 2008-12-09 at 08:47 -0600, Brian King wrote:
> > > This patch fixes a possible deadlock scenario in the CPU remove path.
> > > migration_call grabs rq->lock, then wakes up everything on rq->migration_queue
> > > with the lock held. Then one of the tasks on the migration queue ends up
> > > calling tg_shares_up which then also tries to acquire the same rq->lock.
> > 
> > Looks ok, does lockdep agree?
> 
> On second thought, I'm not seeing it at all..
> 
> why doesn't every wakeup deadlock?
because I'm blind...
void __wake_up(wait_queue_head_t *q, unsigned int mode,
			int nr_exclusive, void *key)
{
	unsigned long flags;
	spin_lock_irqsave(&q->lock, flags);
	__wake_up_common(q, mode, nr_exclusive, 0, key);
	spin_unlock_irqrestore(&q->lock, flags);
}
that's q->lock, not rq->lock...
> > > Signed-off-by: Brian King <brking@linux.vnet.ibm.com>
> > > ---
> > > 
> > >  kernel/sched.c |    2 ++
> > >  1 file changed, 2 insertions(+)
> > > 
> > > diff -puN kernel/sched.c~sched_cpu_down_deadlock_fix kernel/sched.c
> > > --- linux-2.6/kernel/sched.c~sched_cpu_down_deadlock_fix	2008-12-09 08:42:09.000000000 -0600
> > > +++ linux-2.6-bjking1/kernel/sched.c	2008-12-09 08:42:09.000000000 -0600
> > > @@ -6587,7 +6587,9 @@ migration_call(struct notifier_block *nf
> > >  			req = list_entry(rq->migration_queue.next,
> > >  					 struct migration_req, list);
> > >  			list_del_init(&req->list);
> > > +			spin_unlock_irq(&rq->lock);
> > >  			complete(&req->done);
> > > +			spin_lock_irq(&rq->lock);
> > >  		}
> > >  		spin_unlock_irq(&rq->lock);
> > >  		break;
> > > _