Date: Tue, 04 Apr 2006 16:55:52 +0900 (JST)
From: Atsushi Nemoto <>
Subject: Re: [PATCH] crypto: fix unaligned access in khazad module
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2006/4/4/30

On Tue, 4 Apr 2006 09:11:22 +1000, Herbert Xu <herbert@gondor.apana.org.au> wrote:
> > -	K2 = be64_to_cpu(key[0]);
> > -	K1 = be64_to_cpu(key[1]);
> > +	K2 = be64_to_cpu(get_unaligned(&key[0]));
> > +	K1 = be64_to_cpu(get_unaligned(&key[1]));
> 
> Would it be possible to turn these into two 32-bit aligned reads instead?
Done now.  I've missed your comment on 10 Mar, sorry for duplication.
On 64-bit platform, reading 64-bit keys (which is supposed to be
32-bit aligned) at a time will result in unaligned access.
Signed-off-by: Atsushi Nemoto <anemo@mba.ocn.ne.jp>
diff --git a/crypto/khazad.c b/crypto/khazad.c
index 807f2bf..5b8dc9a 100644
--- a/crypto/khazad.c
+++ b/crypto/khazad.c
@@ -758,7 +758,7 @@ static int khazad_setkey(void *ctx_arg, 
                        unsigned int key_len, u32 *flags)
 {
 	struct khazad_ctx *ctx = ctx_arg;
-	const __be64 *key = (const __be64 *)in_key;
+	const __be32 *key = (const __be32 *)in_key;
 	int r;
 	const u64 *S = T7;
 	u64 K2, K1;
@@ -769,8 +769,9 @@ static int khazad_setkey(void *ctx_arg, 
 		return -EINVAL;
 	}
 
-	K2 = be64_to_cpu(key[0]);
-	K1 = be64_to_cpu(key[1]);
+	/* key is supposed to be 32-bit aligned */
+	K2 = ((u64)be32_to_cpu(key[0]) << 32) | be32_to_cpu(key[1]);
+	K1 = ((u64)be32_to_cpu(key[2]) << 32) | be32_to_cpu(key[3]);
 
 	/* setup the encrypt key */
 	for (r = 0; r <= KHAZAD_ROUNDS; r++) {
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/