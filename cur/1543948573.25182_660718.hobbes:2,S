Date: Thu, 28 Feb 2008 00:11:48 +0100
From: Karsten Wiese <>
Subject: Re: [BUG] using smp_processor_id() in preemptible as suspending
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/2/27/424

Am Mittwoch, 27. Februar 2008 schrieb Dave Young:
> On Wed, Feb 27, 2008 at 3:45 AM, Paul E. McKenney
> <paulmck@linux.vnet.ibm.com> wrote:
> > On Tue, Feb 26, 2008 at 08:33:54AM -0800, Andrew Morton wrote:
> >  > On Tue, 26 Feb 2008 16:24:11 +0800 Dave Young <hidave.darkstar@gmail.com> wrote:
> >  >
> >  > > I don't know whom I should mail to, could you cc the proper guy? Thanks.
> >
> >  Hello, Dave,
> >
> >  Would you be willing to try out the following (untested, might not even
> >  compile) patch show at the very end of this message?  This assumes that
> >  you were running with CONFIG_PREEMPT_RCU, which seems most likely based
> >  on looking at your oops.
> 
> Built ok, but can't even resume now. (dark screen with cursor blinking
> on top-left of minitor)
Dave, can you give this untested patch a try?
thanks,
      Karsten
---
diff --git a/kernel/rcupreempt.c b/kernel/rcupreempt.c
index c7c5209..5a7f8fc 100644
--- a/kernel/rcupreempt.c
+++ b/kernel/rcupreempt.c
@@ -878,18 +878,20 @@ void rcu_offline_cpu(int cpu)
 	 * Otherwise rcu_barrier() will fail
 	 */
 
-	spin_lock_irqsave(&rdp->lock, flags);
+	local_irq_save(flags);
+
+	spin_lock(&rdp->lock);
 	rcu_offline_cpu_enqueue(rdp->donelist, rdp->donetail, list, tail);
 	for (i = GP_STAGES - 1; i >= 0; i--)
 		rcu_offline_cpu_enqueue(rdp->waitlist[i], rdp->waittail[i],
 						list, tail);
 	rcu_offline_cpu_enqueue(rdp->nextlist, rdp->nexttail, list, tail);
-	spin_unlock_irqrestore(&rdp->lock, flags);
+	spin_unlock(&rdp->lock);
 	rdp->waitlistcount = 0;
 
 	/* Disengage the newly dead CPU from the grace-period computation. */
 
-	spin_lock_irqsave(&rcu_ctrlblk.fliplock, flags);
+	spin_lock(&rcu_ctrlblk.fliplock);
 	rcu_check_mb(cpu);
 	if (per_cpu(rcu_flip_flag, cpu) == rcu_flipped) {
 		smp_mb();  /* Subsequent counter accesses must see new value */
@@ -906,7 +908,7 @@ void rcu_offline_cpu(int cpu)
 
 	cpu_clear(cpu, rcu_cpu_online_map);
 
-	spin_unlock_irqrestore(&rcu_ctrlblk.fliplock, flags);
+	spin_unlock(&rcu_ctrlblk.fliplock);
 
 	/*
 	 * Place the removed callbacks on the current CPU's queue.
@@ -919,11 +921,13 @@ void rcu_offline_cpu(int cpu)
 	 */
 
 	rdp = RCU_DATA_ME();
-	spin_lock_irqsave(&rdp->lock, flags);
+	spin_lock(&rdp->lock);
 	*rdp->nexttail = list;
 	if (list)
 		rdp->nexttail = tail;
-	spin_unlock_irqrestore(&rdp->lock, flags);
+	spin_unlock(&rdp->lock);
+
+	local_irq_restore(flags);
 }
 
 void __devinit rcu_online_cpu(int cpu)