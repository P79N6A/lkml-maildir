Date: Thu, 01 Jan 2009 18:14:40 -0600
From: Jayson King <>
Subject: Re: [patch] Re: problem with "sched: revert back to per-rq vruntime"?
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2009/1/1/103

Mike Galbraith wrote:
> Would perhaps be prettier to have the load already in place at call
> time, but methinks the enqueue/dequeue accounting logic is nice as is,
> so complete the unlikely case handling in an unlikely block.
> 
> Impact: bug fixlet.
>
> Account for tasks which have not yet been enqueued in calc_delta_weight().
>
> Signed-off-by: Mike Galbraith <efault@gmx.de>
>
> diff --git a/kernel/sched_fair.c b/kernel/sched_fair.c
> index 5ad4440..4685f28 100644
> --- a/kernel/sched_fair.c
> +++ b/kernel/sched_fair.c
> @@ -392,8 +392,16 @@ static inline unsigned long
>  calc_delta_weight(unsigned long delta, struct sched_entity *se)
>  {
>  	for_each_sched_entity(se) {
> -		delta = calc_delta_mine(delta,
> -				se->load.weight, &cfs_rq_of(se)->load);
> +		struct load_weight *load = &cfs_rq_of(se)->load;
> +
> +		if (unlikely(!se->on_rq)) {
> +			struct load_weight tmp;
> +
> +			tmp.weight = load->weight + se->load.weight;
> +			tmp.inv_weight = 0;
> +			load = &tmp;
> +		}
> +		delta = calc_delta_mine(delta, se->load.weight, load);
>  	}
> 
>  	return delta;
>
> 
Still works OK for me. You may add, if you like:
Tested-By: Jayson King <dev@jaysonking.com>
Jayson