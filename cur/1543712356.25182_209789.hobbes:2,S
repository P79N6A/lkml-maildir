Date: Sat, 27 Mar 2004 20:58:13 -0600
From: Eric <>
Subject: Re: 2.6.x strangeness with large buffer usage via network transfer/disk and SEGV processes
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2004/3/27/123

On Saturday 27 March 2004 5:07 pm, Shawn Starr wrote:
> I don't get something maybe someone can explain why this is happening:
>
> 1) When using a large amount of buffers via sending say a 800MB file from
> one PC to another, the Linux system will segfault processes but not preform
> an OOM. Even though the system itself has not touched swap memory. Why is
> the kernel killing/or why are the processes dying with Segfault?
>
> I see this happening when I extract a Linux source tarball and have certain
> processes running, while tar extracts the process will just receive a
> segmentation fault w/o core.
>
> When using a virtual OS emulator, the emulator will just die.
>
> I don't remember this behaviour in 2.4 at all and I don't think this is
> correct. I have PREEMPT enabled as well.
>
> Is this a problem or is this correct behavour?
>
Crashes a correct behavior?
 You must  be used to windows where crashes are sometimes the correct behavior 
hehe.
Sorry, I had to say it. 
Otherwise I don't have a serious answer to your problem ;)
> Thanks
>
> Shawn S.
-------------------------
Eric Bambach
Eric at cisu dot net
-------------------------
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/