Date: Thu, 13 Feb 2003 13:13:44 -0800
From: Andrew Morton <>
Subject: Re: 2.5.60 and current bk oops in file_ra_state_init
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2003/2/13/159

Patrick Mansfield <patmans@us.ibm.com> wrote:
>
> Hi -
> 
> Using the scsi-misc-2.5 (2.5.60 plus a few changes), or the current
> bk (as of this morning) I'm hitting an oops in file_ra_state_init.
Oh lovely.  Looks like the blockdev/gendisk refcounting has gone wrong and a
request queue was freed under your app's feet.
> I was trying to run a bunch of raw IO's (/dev/raw/rawN) at once to several
> (well 25) disks, trying to maximize IO's/second by repeatedly reading the
> same block of a disk, and got the following oops. I hit this both on a
> netfinity and NUMAQ box.
Was this test frequently opening and closing device nodes, or does it just
open them once and hold them?
Can you please prepare a testcase which I can use to reproduce this?
Be aware that there are some fairly significant problems with direct I/O at
present - direct-io can cause multiple outstanding requests against the same
sector, and that makes the IO scheduler keel over.  But it would be strange
for that to be related to this failure.
BTW, you don't need to use the raw driver any more.  Just open /dev/sda1 with
O_DIRECT.  In fact, I'd be interested in seeing if this change makes the oops
go away.
Thanks.
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/