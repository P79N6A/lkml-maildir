Date: Fri, 15 Dec 2006 09:03:16 +0100
From: Ingo Molnar <>
Subject: Re: [BUG -rt] scheduling in atomic.
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2006/12/15/19

* Steven Rostedt <rostedt@goodmis.org> wrote:
> Ingo,
> 
> I've hit this. I compiled the kernel as CONFIG_PREEMPT, and turned off
> IRQ's as threads.
> 
> BUG: scheduling while atomic: swapper/0x00000001/1, CPU#3
> int filevec_add_drain_all(void)
> {
> 	return schedule_on_each_cpu(filevec_add_drain_per_cpu, NULL);
> }
> 
> 
> And schedule_on_each_cpu is easily schedulable.
> 
> So it seems that it schedules while holding a spin lock.
hm, indeed. I've Cc:-ed Pete who wrote the file-lock scalability 
patchset. My quick impression is that taking the workqueue_mutex in 
schedule_on_each_cpu() is unwarranted - i.e. the patch below should fix 
it.
	Ingo
Index: linux/kernel/workqueue.c
===================================================================
--- linux.orig/kernel/workqueue.c
+++ linux/kernel/workqueue.c
@@ -564,15 +564,15 @@ int schedule_on_each_cpu(void (*func)(vo
 	if (!works)
 		return -ENOMEM;
 
-	mutex_lock(&workqueue_mutex);
 	for_each_online_cpu(cpu) {
 		INIT_WORK(per_cpu_ptr(works, cpu), func, info);
 		__queue_work(per_cpu_ptr(keventd_wq->cpu_wq, cpu),
 				per_cpu_ptr(works, cpu));
 	}
-	mutex_unlock(&workqueue_mutex);
 	flush_workqueue(keventd_wq);
+
 	free_percpu(works);
+
 	return 0;
 }
 
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/