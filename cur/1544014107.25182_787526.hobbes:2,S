Date: Tue, 6 Jan 2009 15:32:15 +0100
From: Andi Kleen <>
Subject: Re: [PATCH] [3/5] Mark complex bitops.h inlines as __always_inline
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2009/1/6/157

> Your patch is wrong because it prevents a good compiler from doing the 
> right inlining decisions.
One or two instruction bitops should be always inlined, not inlining them
always generates much worse code than inlining them. That's easy
to prove just based on code size: the call overhead is larger 
than the inlined code.
This patch just makes sure they get always inlined by marking
those explicitely. There's no reason ever to not inline
those, so giving the compiler a choice doesn't make sense.
Even on a compiler with perfect inlining algorithm (which 
no compiler has) that's true and stating that explicitely 
is correct.
Also to handle inlines in all cases that have code that collapses at compile
time (e.g. __builtin_constant_p tests and similar) correctly the compiler
needs the new "early inlining + optimization" pass that was 
added with gcc 4.4 only. But 4.4 is not even out yet, so obviously
most people don't use it.
That is why *_user() for example always needs to be marked
__always_inline. This patch just extends it a bit more to
more functions with the same problem.
-Andi
-- 
ak@linux.intel.com