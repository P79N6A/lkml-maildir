Date: Tue, 10 Jul 2007 14:59:54 -0400 (EDT)
From: Alan Stern <>
Subject: Efficient use of low-precision kernel timers
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2007/7/10/371

Thomas:
Here's a question for you or anyone else who can help.
I've got a low-precision kernel timer, with a delay measured in seconds
(and rounded off to a second boundary).  Under some circumstances the
timer might be cancelled and restarted many times in quick succession
(a few thousand times perhaps).  Alternatively the timer could simply
be allowed to expire and then restarted, with the callback routine
doing a rather small amount of work.
Which is the most efficient?  Or to put it another way, how many times 
can I cancel and restart a low-precision timer before it uses up as 
much CPU time as allowing the timer to expire once?
Is there a reasonable way to answer this?  I can't think of any good 
tests.  Or is the difference in overhead so small as to be meaningless?
Alan Stern
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/