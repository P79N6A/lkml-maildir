Date: Fri, 07 Mar 2008 09:06:35 -0500
From: Gregory Haskins <>
Subject: [PATCH] RT: fix spinlock preemption feature when PREEMPT_RT is enabled
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/3/7/193

kernel/spinlock.c implements two versions of spinlock wrappers around
the arch-specific implementations:
1) A simple passthrough which implies disabled preemption while spinning
2) A "preemptible waiter" version which uses trylock.
Currently, PREEMPT && SMP will turn on the preemptible feature, and
lockdep or PREEMPT_RT will disable it.  Disabling the feature for
lockdep makes perfect sense, but PREEMPT_RT is counter-intuitive.  My
guess is that this was inadvertent, so this patch once again enables
the feature for PREEMPT_RT.
(Since PREEMPT is set for PREEMPT_RT, we simply get rid of the extra
condition).
I have tested the PREEMPT_RT kernel with this patch and all seems well.
Therefore, if there *is* an issue with running preemptible versions of
these spinlocks under PREEMPT_RT, it is not immediately apparent why. 
Signed-off-by: Gregory Haskins <ghaskins@novell.com>
---
 kernel/spinlock.c |    2 +-
 1 files changed, 1 insertions(+), 1 deletions(-)
diff --git a/kernel/spinlock.c b/kernel/spinlock.c
index c9bcf1b..b0e7f02 100644
--- a/kernel/spinlock.c
+++ b/kernel/spinlock.c
@@ -117,7 +117,7 @@ EXPORT_SYMBOL(__write_trylock_irqsave);
  * not re-enabled during lock-acquire (which the preempt-spin-ops do):
  */
 #if !defined(CONFIG_PREEMPT) || !defined(CONFIG_SMP) || \
-	defined(CONFIG_DEBUG_LOCK_ALLOC) || defined(CONFIG_PREEMPT_RT)
+	defined(CONFIG_DEBUG_LOCK_ALLOC)
 
 void __lockfunc __read_lock(raw_rwlock_t *lock)
 {