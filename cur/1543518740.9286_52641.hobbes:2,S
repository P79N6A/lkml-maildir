Date: Fri, 10 Dec 1999 19:23:43 +0100 (CET)
From: Ingo Molnar <>
Subject: [patch] zone-2.3.32-A0, small cleanup
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/12/10/125

On Thu, 9 Dec 1999, Linus Torvalds wrote:
> Actually, I'd like to get rid of the PG_DMA flag now - it's encoded in
> the page zone, and it's much better there.
yep, the attached patch does this. It's against pre2-2.3.32 and compiles /
boots / works just fine on x86. Other architectures basically just have to
delete their references to PG_DMA.
-- mingo
--- linux/mm/bootmem.c.orig	Fri Dec 10 09:58:13 1999
+++ linux/mm/bootmem.c	Fri Dec 10 09:58:21 1999
@@ -235,8 +235,6 @@
 			count++;
 			ClearPageReserved(page);
 			set_page_count(page, 1);
-			if ((i+(bdata->node_boot_start >> PAGE_SHIFT)) >= (virt_to_phys((char *)MAX_DMA_ADDRESS) >> PAGE_SHIFT))
-				clear_bit(PG_DMA, &page->flags);
 			__free_page(page);
 		}
 	}
--- linux/mm/page_alloc.c.orig	Fri Dec 10 09:58:38 1999
+++ linux/mm/page_alloc.c	Fri Dec 10 09:58:41 1999
@@ -557,7 +557,6 @@
 	 */
 	for (p = lmem_map; p < lmem_map + totalpages; p++) {
 		set_page_count(p, 0);
-		p->flags = (1 << PG_DMA);
 		SetPageReserved(p);
 		init_waitqueue_head(&p->wait);
 		memlist_init(&p->list);
--- linux/include/linux/mm.h.orig	Fri Dec 10 09:59:19 1999
+++ linux/include/linux/mm.h	Fri Dec 10 10:07:22 1999
@@ -154,8 +154,10 @@
 #define PG_error		 1
 #define PG_referenced		 2
 #define PG_uptodate		 3
+#define PG__unused_00		 4
 #define PG_decr_after		 5
-#define PG_DMA			 7
+#define PG_unused_01		 6
+#define PG__unused_02		 7
 #define PG_slab			 8
 #define PG_swap_cache		 9
 #define PG_skip			10
@@ -181,7 +183,7 @@
 #define ClearPageError(page)	clear_bit(PG_error, &(page)->flags)
 #define PageReferenced(page)	test_bit(PG_referenced, &(page)->flags)
 #define PageDecrAfter(page)	test_bit(PG_decr_after, &(page)->flags)
-#define PageDMA(page)		test_bit(PG_DMA, &(page)->flags)
+#define PageDMA(page)		(contig_page_data.node_zones + ZONE_DMA == (page)->zone)
 #define PageSlab(page)		test_bit(PG_slab, &(page)->flags)
 #define PageSwapCache(page)	test_bit(PG_swap_cache, &(page)->flags)
 #define PageReserved(page)	test_bit(PG_reserved, &(page)->flags)
@@ -218,8 +220,8 @@
  * PG_reserved is set for a page which must never be accessed (which
  * may not even be present).
  *
- * PG_DMA is set for those pages which lie in the range of
- * physical addresses capable of carrying DMA transfers.
+ * PG_DMA has been removed, page->zone now tells exactly wether the
+ * page is suited to do DMAing into.
  *
  * Multiple processes may "see" the same page. E.g. for untouched
  * mappings of /dev/null, all processes see the same page full of