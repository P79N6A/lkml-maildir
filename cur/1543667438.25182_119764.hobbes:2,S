Date: Sun, 23 Mar 2003 16:51:37 -0500
From: Brian Gerst <>
Subject: Re: [PATCH] slab.c cleanup
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2003/3/23/201

Manfred Spraul wrote:
> Brian Gerst wrote:
> 
>>
>> Perhaps, but it currently is already allocating 128 bytes for smaller 
>> caches, because the cache is created with SLAB_HWCACHE_ALIGN.  So we 
>> ended up with redundantly sized caches.
>>
> 
> linux/mm/slab.c:
> 
>>     if (flags & SLAB_HWCACHE_ALIGN) {
>>         /* Need to adjust size so that objs are cache aligned. */
>>         /* Small obj size, can get at least two per cache line. */
>>         while (size < align/2)
>>             align /= 2;
>>         size = (size+align-1)&(~(align-1));
>>     }
>> 
>>
> HWALIGN is just a hint, the implementation ignores it if it results in 
> unreasonable wasting of memory.
I think I see what was causing be to believe it was always rounding up 
to the cache size.  The while test should be while (size <= align/2). 
On my machine (athlon, 64 byte cache), the size-32 cache was rounded up 
to 64 bytes because of this.
size-128            1416   1470    128   49   49    1 :  248  124
size-64              351    413     64    7    7    1 :  248  124
size-32              649    649     64   11   11    1 :  248  124
                                    ^^^^
--
				Brian Gerst
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/