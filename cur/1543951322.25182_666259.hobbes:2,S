Date: Tue, 11 Mar 2008 15:34:03 +0100
From: Peter Zijlstra <>
Subject: Re: [RFC PATCH] Implement slub fastpath with sequence number
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/3/11/207

On Tue, 2008-03-11 at 05:31 -0400, Mathieu Desnoyers wrote:
> Here is a new version that works. tested on x86. tweaked the bitmasks
> into unions to remove operations from the critical path, but I tried to
> keep that clean. It applies on vm.git HEAD.
> 
> It allows the cmpxchg_local to detect object re-use by keeping a counter in the
> freeoffset MSBs.
> 
> Whenever an object is freed in the cpu slab cache, the counter is incremented.
> Whenever the alloc/free slow paths are modifying the offset or freebase, the
> sequence counter is also incremented. It is used to make sure we know if
> freebase has been modified in an interrupt nested over the fast path.
Is it (remotely) possible that the version will wrap giving the false
impression that nothing has changed and thus falsely proceed with a
wrong object?
I would really prefer if we defer all this fast path fiddling until we
have the cpu_ops in place, this all just makes the code utterly
unreadable.