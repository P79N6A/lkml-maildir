Date: Thu, 06 Dec 2007 10:28:02 -0500
From: Gregory Haskins <>
Subject: [PATCH 2/2] Subject: SCHED - Clean up some old cpuset logic
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2007/12/6/160

We had support for overlapping cpuset based rto logic in early prototypes that
is no longer used, so clean it up.
Signed-off-by: Gregory Haskins <ghaskins@novell.com>
---
 kernel/sched_rt.c |   32 --------------------------------
 1 files changed, 0 insertions(+), 32 deletions(-)
diff --git a/kernel/sched_rt.c b/kernel/sched_rt.c
index 53cd9e8..65cbb78 100644
--- a/kernel/sched_rt.c
+++ b/kernel/sched_rt.c
@@ -586,37 +586,6 @@ static int pull_rt_task(struct rq *this_rq)
 			continue;
 
 		src_rq = cpu_rq(cpu);
-		if (unlikely(src_rq->rt.rt_nr_running <= 1)) {
-			/*
-			 * It is possible that overlapping cpusets
-			 * will miss clearing a non overloaded runqueue.
-			 * Clear it now.
-			 */
-			if (double_lock_balance(this_rq, src_rq)) {
-				/* unlocked our runqueue lock */
-				struct task_struct *old_next = next;
-
-				next = pick_next_task_rt(this_rq);
-				if (next != old_next)
-					ret = 1;
-			}
-			if (likely(src_rq->rt.rt_nr_running <= 1)) {
-				/*
-				 * Small chance that this_rq->curr changed
-				 * but it's really harmless here.
-				 */
-				rt_clear_overload(this_rq);
-			} else {
-				/*
-				 * Heh, the src_rq is now overloaded, since
-				 * we already have the src_rq lock, go straight
-				 * to pulling tasks from it.
-				 */
-				goto try_pulling;
-			}
-			spin_unlock(&src_rq->lock);
-			continue;
-		}
 
 		/*
 		 * We can potentially drop this_rq's lock in
@@ -641,7 +610,6 @@ static int pull_rt_task(struct rq *this_rq)
 			continue;
 		}
 
- try_pulling:
 		p = pick_next_highest_task_rt(src_rq, this_cpu);
 
 		/*