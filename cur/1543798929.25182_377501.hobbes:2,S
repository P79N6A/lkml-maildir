Date: Mon, 19 Dec 2005 09:43:05 +0200 (EET)
From: Pekka J Enberg <>
Subject: Re: [PATCH] micro optimization of cache_estimate in slab.c
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2005/12/19/13

On Sun, 18 Dec 2005, Steven Rostedt wrote:
> Index: linux-2.6.15-rc5/mm/slab.c
> ===================================================================
> --- linux-2.6.15-rc5.orig/mm/slab.c	2005-12-16 16:24:09.000000000 -0500
> +++ linux-2.6.15-rc5/mm/slab.c	2005-12-18 13:30:13.000000000 -0500
> @@ -708,7 +708,14 @@
>  		base = sizeof(struct slab);
>  		extra = sizeof(kmem_bufctl_t);
>  	}
> -	i = 0;
> +	/*
> +	 * Divide the amount we have, by the amount we need for
> +	 * each object.  Since the size is already calculated
> +	 * to be no less than the alignment, this result will
> +	 * not be any greater than 1 that we need, and this will
> +	 * be subtracted after the while loop.
> +	 */
> +	i = (wastage - base)/(size + extra);
>  	while (i*size + ALIGN(base+i*extra, align) <= wastage)
>  		i++;
>  	if (i > 0)
Thanks. Looks much better but I am still wondering if we could get rid of 
the loop altogether. Hmm.
			Pekka
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/