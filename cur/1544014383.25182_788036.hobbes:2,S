Date: Wed, 7 Jan 2009 08:40:13 +0100
From: Nick Piggin <>
Subject: Re: [PATCH] configure HAVE_UNSTABLE_SCHED_CLOCK for SGI_SN systems
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2009/1/7/36

On Wed, Jan 07, 2009 at 08:28:09AM +0100, Peter Zijlstra wrote:
> On Wed, 2009-01-07 at 04:00 +0100, Nick Piggin wrote:
> > On Wed, Jan 07, 2009 at 12:16:03AM +0100, Peter Zijlstra wrote:
> > > > 
> > > > But doesn't scheduler tick advance the rq->clock?  Why do the others
> > > > need to fiddle with a remote runqueue's clock?  When that cpu starts
> > > > taking ticks again, it will update it's rq->clock field and start the
> > > > processes.  I guess I am a lot underinformed about the new scheduler
> > > > design.
> > > 
> > > We try to do better than tick based time accounting these days.
> > 
> > But if you contain the drift to within one tick, it shouldn't be much
> > problem to just truncate negative deltas I would have thought? The
> > time between events on different CPUs is pretty fuzzy at the ns level
> > anyway, I think ;)
> 
> That's basically what the HAVE_UNSTABLE_SCHED_CLOCK code does. It takes
> a tick timestamp and tries to improve on that by using strict per cpu
> sched_clock() deltas.
> 
> What we do to obtain remote time, is basically calculate local time and
> pull remote time fwd if that was behind.
> 
> While doing that, it filters out any backward motion and large fwd leaps
> so as to stay no worse than a jiffie clock.
OK, that's good. I guess the optimisations to remove that code should
have been called HAVE_STABLE_SCHED_CLOCK and have archs turn it on on
a case by case basis. 