Date: Thu, 01 Jul 1999 02:13:09 +0000
From: Gerard Saraber <>
Subject: lock_kernel question
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/6/30/197

Hi!
"inspired" by the recent pcweek labs linux vs. nt benchmark I decided to
take a look at what the new scalable networking in linux 2.3.5 (my
current kernel) looks like.
So looking at the code I've seen a lot of unlock_kernel() at the
beginning of functions and a lot of lock_kernel() at the end of those
functions..
So am i correct in assuming that the kernel gets locked with every
syscall, and unlocked when it exits? and ofcourse unlocked a couple of
times in between to make it more scalable?
My second question, lock_kernel() locks the _entire_ kernel right?
wouldn't it be more logical/more scalable if there were locks around the
subsystems? the way i understand multi-threading is that you serialize
access to hardware so you don't confuse the hardware-device right? and
you also serialize access to global data so two threads don't mess up
eachothers data .. 
So wouldn't it be much better(tm) to put separate locks around each
resource? imho, you can access the scsi and network cards completely
independent/concurrent..
so would it be possible to remove all the lock_kernel()s as soon as a
syscall hits and just put the lock_kernel()s around critical resources?
am I missing or oversimplifying things? 
ps. please cc. gsaraber@toledolink.com , thank you.
Thanks,
Gerard Saraber
gsaraber@toledolink.com
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/