Date: Tue, 22 Jan 2008 09:52:13 +0100
From: Miklos Szeredi <>
Subject: Re: [PATCH -v7 2/2] Update ctime and mtime for memory-mapped files
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/1/22/44

> > >
> > >  /*
> > > + * Scan the PTEs for pages belonging to the VMA and mark them read-only.
> > > + * It will force a pagefault on the next write access.
> > > + */
> > > +static void vma_wrprotect(struct vm_area_struct *vma)
> > > +{
> > > +     unsigned long addr;
> > > +
> > > +     for (addr = vma->vm_start; addr < vma->vm_end; addr += PAGE_SIZE) {
> > > +             spinlock_t *ptl;
> > > +             pgd_t *pgd = pgd_offset(vma->vm_mm, addr);
> > > +             pud_t *pud = pud_offset(pgd, addr);
> > > +             pmd_t *pmd = pmd_offset(pud, addr);
> > > +             pte_t *pte = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);
> >
> > This is extremely expensive over bigger areas, especially sparsely mapped
> > ones (it does all the lookups for all four levels over and over and over
> > again for eachg page).
> >
> > I think Peter Zijlstra posted a version that uses the regular kind of
> > nested loop (with inline functions to keep the thing nice and clean),
> > which gets rid of that.
> 
> Thanks for your feedback, Linus!
> 
> I will use Peter Zijlstra's version of such an operation in my next
> patch series.
But note, that those functions iterate over all the vmas for the given
page range, not just the one msync was performed on.  This might get
even more expensive, if the file is mapped lots of times.
The old version, that Linus was referring to, needs some modification
as well, because it doesn't write protect the ptes, just marks them
clean.
Miklos