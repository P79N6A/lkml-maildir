Date: 1 Jul 1999 04:41:00 GMT
From: (Linus Torvalds)
Subject: Re: lock_kernel question
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/6/30/230

In article <377ACEB5.97D3BC69@toledolink.com>,
Gerard Saraber  <gsaraber@toledolink.com> wrote:
>
>"inspired" by the recent pcweek labs linux vs. nt benchmark I decided to
>take a look at what the new scalable networking in linux 2.3.5 (my
>current kernel) looks like.
Don't.
2.3.5 is not really a very good example of how to get rid of some of the
kernel locks.
Look at 2.3.9 instead, where we finally got far enough that we were able
to get rid of a lot of "legacy" locks, and it's starting to look like a
real design.
>So looking at the code I've seen a lot of unlock_kernel() at the
>beginning of functions and a lot of lock_kernel() at the end of those
>functions..
>So am i correct in assuming that the kernel gets locked with every
>syscall, and unlocked when it exits? and ofcourse unlocked a couple of
>times in between to make it more scalable?
No.
The way it is _supposed_ to work is that a system call does not get the
kernel lock until it absolutely has to due to old code.
The reason you see the ugly in-between state is simply because a lot of
development was going on in partial areas, and much of it was cleaned up
"inside out" - so in many cases the inner routines were SMP-safe before
the outer ones were. So the outer ones needed to aquire the kernel lock,
but the inner ones decided that they can drop it.
That kind of code is never "production-quality" - it's only a result of
incomplete work-in-progress stuff. That's why I'd suggest you not look
at 2.3.5 too much, and instead get 2.3.9 that has a lot less of that,
and a lot more of the real code..
		Linus
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/