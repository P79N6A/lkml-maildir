Date: Wed, 27 Feb 2008 15:43:41 -0800
From: Andrew Morton <>
Subject: Re: [PATCH] Prevent the loop in timespec_add_ns() to be optimised away
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/2/27/452

On Fri, 22 Feb 2008 22:40:45 +0100
Segher Boessenkool <segher@kernel.crashing.org> wrote:
> ...since some architectures don't support __udivdi3() (and
> we don't want to use that, anyway).
> 
> Signed-off-by: Segher Boessenkool <segher@kernel.crashing.org>
> ---
>  include/linux/time.h |    4 ++++
>  1 files changed, 4 insertions(+), 0 deletions(-)
> 
> diff --git a/include/linux/time.h b/include/linux/time.h
> index 2091a19..d32ef0a 100644
> --- a/include/linux/time.h
> +++ b/include/linux/time.h
> @@ -174,6 +174,10 @@ static inline void timespec_add_ns(struct timespec *a, u64 ns)
>  {
>  	ns += a->tv_nsec;
>  	while(unlikely(ns >= NSEC_PER_SEC)) {
> +		/* The following asm() prevents the compiler from
> +		 * optimising this loop into a modulo operation.  */
> +		asm("" : "+r"(ns));
> +
>  		ns -= NSEC_PER_SEC;
>  		a->tv_sec++;
>  	}
It's pretty sad that we need to turn this into a loop just because of the
__udivdi3() thing.
otoh, it's rarely occurring, and it could be that the number of times it
loops is usually 1 (if it wasn't zero), so perhaps a loop is faster than a
divide anyway.
This code is probably too large to be inlined.
I queued this patch as needed-in-2.6.25, to-be-merged-via-Thomas.