Date: Fri, 25 Aug 2000 13:28:25 -0400
From: "Chris Swiedler" <>
Subject: [RFC] Implementing temporal affinity
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/8/25/119

Dmitris Michailidis recently mentioned a desire to have the kernel implement
temporal affinity, where a process which is briefly interrupted has a better
chance of being scheduled. The idea would be that if the interrupting
process ran briefly enough, the CPU cache would still contain
instructions/data from the previous process.
I'm wondering if we could implement this by generalizing the SMP
processor-affinity goodness() calculation. Right now, we give a "largish
advantage" to the process whose last_processor == this_cpu. Every time we
schedule a process onto a CPU, we set last_processor to that CPU. But if we
only set last_processor after the process has run on that CPU for a certain
number of cycles, then processes which didn't run for at least that long
wouldn't "own" the CPU, and wouldn't get the scheduling advantage.
Looking at the code, however, I don't see how we can tell how long a process
has been on a CPU. We could add a field to task_struct which indicates this.
Also this would require that we remove the #ifdef __SMP__ for the processor
and last_processor fields in the task_queue. So we'd be increasing the size
of the task_struct by 3 ints for UP, which by itself may make the idea not
worthwhile...
Any opinions?
Chris Swiedler
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
Please read the FAQ at 
http://www.tux.org/lkml/