Date: Wed, 22 Mar 2000 09:51:10 +0000
From: Jon Milton <>
Subject: Re: Overcomittable memory
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2000/3/22/93

David Whysong wrote:
> 
> 
> No, the bug is that you tried to use more memory than your computer has.
> 
I agree, there's nothing an OS can do to fix an under resourced system,
so it's very questionable whether it's ok to kill processes on OOM.
Any mission critical application should be designed to cope with limited
resources, those that aren't are just inherently unsafe. 
If all apps were good like that then there would be no issue, but
back in the real world ...... it happens. (A user may for example
open multiple netscape sessions to maximise link utilisation)
There does not seem to be a solution that meets all needs. On the
one hand a sys admin running a critical web server would probably
want to trust Apache or whatever to use the available resources
effectively, but trap any failure with full debug. ie killing
processes on OOM is bad.
On the other hand, your single user linux on the desktop
scenario, probably would not object to killing on OOM
and possibly not even notice. The loss of performance
when the apps start to swap is usually noticable, and
cause individuals to moderate usage. Killing on OOM would
be a failsafe.
I think what's needed is a "kill on OOM" daemon that's more
programmable. Default on, but with facillity to disable.
Even better, make certain users untouchable, so that apps
which really are mission critical carry on running, possible
at the expense of the dross.
Jon
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/