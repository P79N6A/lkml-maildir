Date: Sat, 21 Sep 2002 10:11:30 -0700
From: "Martin J. Bligh" <>
Subject: Re: [Lse-tech] [PATCH 1/2] node affine NUMA scheduler
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2002/9/21/60

> From the below, I'd suggest you're getting pages off the wrong 
> nodes: do_anonymous_page is page zeroing, and rmqueue the buddy
> allocator. Are you sure the current->node thing is getting set
> correctly? I'll try backing out your alloc_pages tweaking, and
> see what happens.
OK, well removing that part of the patch gets us back from 28s to 
about 21s (compared to 20s virgin), total user time compared to 
virgin is up from 59s to 62s, user from 191 to 195. So it's still 
a net loss, but not by nearly as much. Are you determining target 
node on fork or exec ? I forget ...
Profile is more comparible. Nothing sticks out any more, but maybe
it just needs some tuning for balance intervals or something. 
153385 total                                      0.1544
 91219 default_idle                            
  7475 do_anonymous_page                       
  4564 page_remove_rmap                        
  4167 handle_mm_fault                         
  3467 .text.lock.namei                        
  2520 page_add_rmap                           
  2112 rmqueue                                 
  1905 .text.lock.dec_and_lock                 
  1849 zap_pte_range                           
  1668 vm_enough_memory                        
  1612 __free_pages_ok                         
  1504 file_read_actor                         
  1484 find_get_page                           
  1381 __generic_copy_from_user                
  1207 do_no_page                              
  1066 schedule                                
  1050 get_empty_filp                          
  1034 link_path_walk                          
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/