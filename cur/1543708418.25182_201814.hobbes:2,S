Date: 25 Feb 2004 09:34:21 -0800
From: Roland Dreier <>
Subject: Re: PATCH - InfiniBand Access Layer (IBAL)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2004/2/25/140

    Timothy> On the other hand, if something else is better or
    Timothy> adequate, like PCI Express (wasn't that based in
    Timothy> infiniband?), then there's no point.
PCI Express is not an InfiniBand replacement.  While it is true (I
think this is what you meant) that the PCI Express electrical
signaling is based on InfiniBand (they both use multiple lanes of 2.5
Gb/sec high-speed serial), the upper layers of the two standards are
quite different.  PCI Express and InfiniBand are really quite
complementary.  In fact (just to plug my employer :) we have
demonstrated an Infiniband host adapter that has two 4X IB (10 Gb/sec
ports) and plugs into an 8X PCI Express slot:
  
http://www.topspin.com/news/pressrelease/pr_021704b.html
PCI Express (once products ship) will be essentially a faster PCI-X
replacement.  You will get a system with PCI Express slots and plug
PCI Express adapter cards into them.  There is something called PCI
Express "Advanced Switching" but that is quite a long way away from
being something you could build a cluster with.
InfiniBand on the other hand has evolved into a cluster interconnect.
In the beginning it was pitched as a PCI replacement but that was
given up long ago.  However, it evolved into an excellent cluster
interconnect.  Right now you can buy 10 Gb/sec host adapters and a
variety of switches (up to 96 ports).  There are a number of quite
large IB clusters already built and in production already.
Best,
  Roland
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/