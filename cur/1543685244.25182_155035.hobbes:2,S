Date: Wed, 6 Aug 2003 12:01:42 -0700
From: Mike Fedyk <>
Subject: Re: Interactivity improvements
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2003/8/6/226

On Wed, Aug 06, 2003 at 02:48:11PM -0400, Timothy Miller wrote:
> The idea I'm proposing, however poorly formed, is that if we allow some 
> "excessive" oscillation early on in the life of a process, we may be 
> able to more quickly get processes to NEAR its correct priority, OR get 
> its CPU time over the course of three times being run for the 
> underdamped case to be about the same as it would be if we knew in 
> advance what the priority should be.  But in the underdamped case, the 
> priority would continue to oscillate up and down around the correct 
> level, because we are intentionally overshooting the mark each time we 
> adjust priority.
> 
> This may not be related, but something that pops into my mind is a 
> numerical method called Newton's Method.  It's a way to solve for roots 
> of an equation, and it involved derivatives, and I don't quite remember 
> how it works.  But in any event, the results are less accurate than, 
> say, bisection, but you get to the answer MUCH more quickly.
Sounds interesting.
Much like a decaying average, or average over the entire lifetime of the
process which can be weighed into the short term interactivity calculations
also.
I think Con is working on something like this already, except that it's
taking the short term into account more than the long term.
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/