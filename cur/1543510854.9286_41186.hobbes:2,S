Date: Mon, 27 Sep 1999 23:19:19 -0400 (EDT)
From: Chuck Lever <>
Subject: Re: Solaris 100K TCP connections, good example?  was:[Fwd: [Fwd: Re: TCP
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/1999/9/27/204

On Tue, 28 Sep 1999, Alan Cox wrote:
> > Solaris 2.6 and above can handle 100,000 connections if the
> > server has plenty of memory and is properly configured.
> 
> 100,000 connections with an 8K window (minimum to be sane and all the clients
> being awkward- which is a requirement for a non lab assumption) 
> 
> 	100000 * 8192 (ignoring OS socket buffer overhead)
> 
> is about 800Mb of memory for network buffers.
> 
> So a 2Gig Linux box should be just fine.
maybe.  every socket has an inode and probably a dentry associated with
it, true?
in that case, every filesystem iget operation has to wade through 100K+
inodes to find an inode (imagine the length of the hash lists in a 256
bucket hash table!). every d_lookup has to do the same. each inode is as
large as the largest filesystem-specific inode struct, even though most
sockets won't use any of that. all the inodes associated with sockets can
never be flushed while they have a positive reference count, which doesn't
go to zero until the socket closes (bad for high-latency connections or if
SO_LINGER is set). in current kernels, the VM system can't even ask for
inode memory back after it's been allocated to the inode cache.
think 2G of RAM is enough?  :)  maybe for the buffers alone...
	- Chuck Lever
--
corporate:	<chuckl@netscape.com>
personal:	<chucklever@netscape.net> or <cel@monkey.org>
The Linux Scalability project:
	
http://www.citi.umich.edu/projects/linux-scalability/
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.rutgers.edu
Please read the FAQ at 
http://www.tux.org/lkml/