Date: Wed, 16 Jan 2008 10:14:00 +0200
From: Mika Penttil√§ <>
Subject: Re: [patch 2/4] x86: PAT followup - Remove KERNPG_TABLE from pte entry
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/1/16/41

venkatesh.pallipadi@intel.com kirjoitti:
> KERNPG_TABLE was a bug in earlier patch. Remove it from pte.
> pte_val() check is redundant as this routine is called immediately after a
> ptepage is allocated afresh.
>
> Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
> Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
>
> Index: linux-2.6.git/arch/x86/mm/init_64.c
> ===================================================================
> --- linux-2.6.git.orig/arch/x86/mm/init_64.c	2008-01-15 11:02:23.000000000 -0800
> +++ linux-2.6.git/arch/x86/mm/init_64.c	2008-01-15 11:06:37.000000000 -0800
> @@ -541,9 +541,6 @@
>  		if (address >= end)
>  			break;
> 
> -		if (pte_val(*pte))
> -			continue;
> -
>  		/* Nothing to map. Map the null page */
>  		if (!(address & (~PAGE_MASK)) &&
>  		    (address + PAGE_SIZE <= end) &&
> @@ -561,9 +558,9 @@
>  		}
> 
>  		if (exec)
> -			entry = _PAGE_NX|_KERNPG_TABLE|_PAGE_GLOBAL|address;
> +			entry = _PAGE_NX|_PAGE_GLOBAL|address;
>  		else
> -			entry = _KERNPG_TABLE|_PAGE_GLOBAL|address;
> +			entry = _PAGE_GLOBAL|address;
>  		entry &= __supported_pte_mask;
>  		set_pte(pte, __pte(entry));
>  	}
>
> 
Hmm then what's the point of mapping not present 4k pages for valid mem 
here?
--Mika