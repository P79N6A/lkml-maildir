Date: Fri, 01 Feb 2008 09:37:31 -0800
From: Jeremy Fitzhardinge <>
Subject: Re: [PATCH] [12/12] GBPAGES: Switch direct mapping setup over to set_pte
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2008/2/1/340

Andi Kleen wrote:
> [Actually not needed for gbpages, but an indepedent, but related cleanup]
>
> Use set_pte() for setting up the 2MB pages in the direct mapping similar 
> to what the earlier GBPAGES patches did for the 1GB PUDs.
>
> Signed-off-by: Andi Kleen <ak@suse.de>
>
> ---
>  arch/x86/mm/init_64.c |    6 ++----
>  1 file changed, 2 insertions(+), 4 deletions(-)
>
> Index: linux/arch/x86/mm/init_64.c
> ===================================================================
> --- linux.orig/arch/x86/mm/init_64.c
> +++ linux/arch/x86/mm/init_64.c
> @@ -289,7 +289,6 @@ phys_pmd_init(pmd_t *pmd_page, unsigned 
>  	int i = pmd_index(address);
> 
>  	for (; i < PTRS_PER_PMD; i++, address += PMD_SIZE) {
> -		unsigned long entry;
>  		pmd_t *pmd = pmd_page + pmd_index(address);
> 
>  		if (address >= end) {
> @@ -303,9 +302,8 @@ phys_pmd_init(pmd_t *pmd_page, unsigned 
>  		if (pmd_val(*pmd))
>  			continue;
> 
> -		entry = __PAGE_KERNEL_LARGE|_PAGE_GLOBAL|address;
> -		entry &= __supported_pte_mask;
> -		set_pmd(pmd, __pmd(entry));
> +		set_pte((pte_t *)pmd,
> +			pfn_pte(address >> PAGE_SHIFT, PAGE_KERNEL_LARGE));
> 
Why?  64-bit Xen will need this to be set_pmd if its an update to L2 of 
the table.
    J