Date: Tue, 08 Jan 2002 14:31:50 -0800
From: Andrew Morton <>
Subject: Re: [2.4.17/18pre] VM and swap - it's really unusable
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2002/1/8/284

Robert Love wrote:
> 
> On Tue, 2002-01-08 at 16:24, Rik van Riel wrote:
> 
> > So what exactly _is_ the difference between an explicit
> > preemption point and a place where we need to explicitly
> > drop a spinlock ?
> 
> In that case nothing, except that when we drop the lock and check it is
> the earliest place where preemption is allowed.  In the normal scenario,
> however, we have a check for reschedule on return from interrupt (e.g.
> the timer) and thus preempt in the same manner as with user space and
> that is the key.
One could do:
static inline void spin_unlock(spinlock_t *lock)
{
        __asm__ __volatile__(
                spin_unlock_string
        );
	if (--current->lock_depth == 0 &&
		current->need_resched &&
		current->state == TASK_RUNNING)
		schedule();
}
But I have generally avoided "global" solutions like this, in favour
of nailing the _specific_ code which is causing the problem.  Which
is a lot more work, but more useful.
The scheduling points in bread() and submit_bh() in the mini-ll patch
go against this (masochistic) philosophy.
> > > Future work would be to look into long-held locks and see what we can
> > > do.
> >
> > One thing we could do is download Andrew Morton's patch ;)
> 
> That is certainly one option, and Andrew's patch is very good.
> Nonetheless, I think we need a more general framework that tackles the
> problem itself.  Preemptible kernel does this, yields results now, and
> allows for greater return later on.
We need something which makes 2.4.x not suck.
-
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/