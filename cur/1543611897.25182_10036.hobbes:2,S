Date: Tue, 4 Dec 2001 14:20:47 +0100
From: (Erik Tews)
Subject: Re: tuning ext2 or ReiserFS to avoid fragmentation with large files?
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2001/12/4/24

On Mon, Dec 03, 2001 at 02:13:22PM +0100, Roy Sigurd Karlsbakk wrote:
> hi all
> 
> I've got this server with lots of ~3GB files and every now and then we
> need to add some more or delete some old ones. All files are potentially
> read concurrently, so to reduce disk seeks, I've increased the readahead
> settings in kernel (/proc/sys/vm/(min|max)-readahead).
> 
> Then... A friend of mine told me I could tune the fs (or vfs) to allocate
> n kB each time a file is created, and by setting this to whatever I've set
> (min|max)-readahead to (currently 1048576), I will reduce the negative
> effect of fragmentation to a minimum, since the data blocks will be large,
> and read more-or-less sequencially.
> 
> Can anyone tell me how to tell the fs or the kernel to allocate n pages/kB
> this way? Is it possible? Can I possibly set different sizes per file
> system?
If I remember right xfs has got a online-defragmentation utility. So
have a look at xfs.
I think xfs works different from reiserfs and ext2 when writing files to
disk which helps avoiding fragmentation. This feature is called
allocation groups.
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/