Date: Sun, 29 Aug 2004 09:05:42 -0700
From: William Lee Irwin III <>
Subject: Re: [BENCHMARK] nproc: netlink access to /proc information
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2004/8/29/104

On Sat, 28 Aug 2004 12:56:47 -0700, William Lee Irwin III wrote:
>> These numbers are somewhat at variance with my experience in the area,
>> as I see that the internal algorithms actually dominate the runtime
>> of the /proc/ algorithms. Could you describe the processes used for the
>> benchmarks, e.g. typical /proc/$PID/status and /proc/$PID/maps for them?
On Sat, Aug 28, 2004 at 10:14:35PM +0200, Roger Luethi wrote:
> The status/maps numbers below are not only typical, but identical for
> all tasks. I'm forking off a defined number of children and then query
> their status from the parent.
> Because I was interested in delivery overhead, I built on purpose a
> benchmark without computationally expensive fields. Expensive field
> computation hurts /proc more than nproc because the latter allows you
> to have only the currently needed fields computed.
Okay, these explain some of the difference. I usually see issues with
around 10000 processes with fully populated virtual address spaces and
several hundred vmas each, varying between 200 to 1000, mostly
concentrated at somewhere just above 300.
-- wli
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/