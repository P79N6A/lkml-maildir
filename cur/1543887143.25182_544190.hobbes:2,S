Date: Mon, 14 May 2007 03:04:12 -0700 (PDT)
From: David Miller <>
Subject: Re: [PATCH] improved locking performance in rt_run_flush()
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2007/5/14/91

From: Dave Johnson <djohnson+linux-kernel@sw.starentnetworks.com>
Date: Sat, 12 May 2007 12:36:47 -0400
> 
> While testing adding/deleting large numbers of interfaces, I found
> rt_run_flush() was the #1 cpu user in a kernel profile by far.
> 
> The below patch changes rt_run_flush() to only take each spinlock
> protecting the rt_hash_table once instead of taking a spinlock for
> every hash table bucket (and ending up taking the same small set 
> of locks over and over).
> 
> Deleting 256 interfaces on a 4-way SMP system with 16K buckets reduced
> overall cpu-time more than 50% and reduced wall-time about 33%.  I
> suspect systems with large amounts of memory (and more buckets) will
> see an even greater benefit.
> 
> Note there is a small change in that rt_free() is called while the
> lock is held where before it was called without the lock held.  I
> don't think this should be an issue.
> 
> Signed-off-by: Dave Johnson <djohnson+linux-kernel@sw.starentnetworks.com>
Thanks for this patch.
I'm not ignoring it I'm just trying to brainstorm whether there
is a better way to resolve this inefficiency. :-)
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/