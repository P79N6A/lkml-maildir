Date: Wed, 23 Nov 2005 13:26:47 -0800
From: Andrew Morton <>
Subject: Re: [PATCH]: Free pages from local pcp lists under tight memory conditions
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-Lkml-Link: https://lkml.org/lkml/2005/11/23/355

Rohit Seth <rohit.seth@intel.com> wrote:
>
> > I don't think Martin was able to demonstrate much benefit from the lock
> > contention reduction on 16-way NUMAQ either.
> > 
> > So I dithered for months and it was a marginal merge, so it's appropriate
> > to justify the continued presence of the code.
> > 
> 
> May be the limits on the number of pages hanging on the per_cpu_pagelist
> was (or even now is) too small (for them to give any meaningful gain).
> May be we should have more physical contiguity in each of these pcps to
> give better cache spread.  
Could be.  The initial settings were pretty arbitrary - I assumed that
someone would get in and tune them up, but nothing much happened.  Perhaps
we should expose the thresholds in /proc/sys/vm so they're easier to play
with.
> > We didn't measure for any coloring effects though.  In fact, I didn't know
> > that this feature actually provided any benefit in that area.  
> 
> I thought Nick et.al came up with some of the constant values like batch
> size to tackle the page coloring issue specifically.  In any case, I
> think one of the key difference between 2.4 and 2.6 allocators is the
> pcp list.  And even with the minuscule batch and high watermarks this is
> helping ordinary benchmarks (by reducing the variation from run to run).
OK, useful info, thanks.
-
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  
http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  
http://www.tux.org/lkml/